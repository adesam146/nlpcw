{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Import-and-preprocess-Data\" data-toc-modified-id=\"Import-and-preprocess-Data-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Import and preprocess Data</a></span></li><li><span><a href=\"#Utils-Functions-For-Neural-Network-Classifer\" data-toc-modified-id=\"Utils-Functions-For-Neural-Network-Classifer-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Utils Functions For Neural Network Classifer</a></span></li><li><span><a href=\"#Simple-Neural-Network-Classifier-for-Comparison\" data-toc-modified-id=\"Simple-Neural-Network-Classifier-for-Comparison-0.4\"><span class=\"toc-item-num\">0.4&nbsp;&nbsp;</span>Simple Neural Network Classifier for Comparison</a></span></li></ul></li><li><span><a href=\"#Task-A\" data-toc-modified-id=\"Task-A-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Task A</a></span><ul class=\"toc-item\"><li><span><a href=\"#Neural-Network\" data-toc-modified-id=\"Neural-Network-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Neural Network</a></span></li><li><span><a href=\"#SVMs\" data-toc-modified-id=\"SVMs-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>SVMs</a></span></li></ul></li><li><span><a href=\"#Task-B\" data-toc-modified-id=\"Task-B-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Task B</a></span><ul class=\"toc-item\"><li><span><a href=\"#Neural-Network\" data-toc-modified-id=\"Neural-Network-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Neural Network</a></span></li><li><span><a href=\"#SVMs\" data-toc-modified-id=\"SVMs-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>SVMs</a></span></li></ul></li><li><span><a href=\"#Task-C\" data-toc-modified-id=\"Task-C-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Task C</a></span><ul class=\"toc-item\"><li><span><a href=\"#Neural-Network\" data-toc-modified-id=\"Neural-Network-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Neural Network</a></span></li><li><span><a href=\"#SVMs\" data-toc-modified-id=\"SVMs-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>SVMs</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/adesam146/nlpcw/blob/rest_of_tasks/NLP_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wTfeo8tcxhwC"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePuqIHSPf554"
   },
   "outputs": [],
   "source": [
    "!pip install -U spacy ftfy torchtext\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Srpq8hYt4whg",
    "outputId": "d7028e13-011c-46cb-a4f3-6606a41d7a83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import sampler\n",
    "import spacy\n",
    "from torchtext import data\n",
    "from torchtext import datasets as nlp_dset\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "nlp_spaCy = spacy.load('en')\n",
    "\n",
    "GPU = True\n",
    "device_idx = 0\n",
    "if GPU:\n",
    "    device = torch.device(\"cuda:\"+str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "#Fix all seeds\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtiwRhtm3s87"
   },
   "outputs": [],
   "source": [
    "# REPLACE WITH LOCATION OF FILE\n",
    "# Load datafile\n",
    "train_fp = \"\"\"./offenseval-training-v1.tsv\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "X3kA7Y0BjUnF",
    "outputId": "9917cf21-bffa-4f40-d83b-f3b852de0ce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-01 21:36:19--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
      "--2019-03-01 21:36:19--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1520408563 (1.4G) [application/zip]\n",
      "Saving to: ‘glove.twitter.27B.zip’\n",
      "\n",
      "glove.twitter.27B.z 100%[===================>]   1.42G  5.63MB/s    in 3m 32s  \n",
      "\n",
      "2019-03-01 21:39:50 (6.85 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
      "\n",
      "Archive:  glove.twitter.27B.zip\n",
      "  inflating: glove.twitter.27B.25d.txt  \n",
      "  inflating: glove.twitter.27B.50d.txt  \n",
      "  inflating: glove.twitter.27B.100d.txt  \n",
      "  inflating: glove.twitter.27B.200d.txt  \n"
     ]
    }
   ],
   "source": [
    "# Used two GloVe trained on two different corpuses for comparison:\n",
    "# glove.twitter.27B\n",
    "# TAKES ABOUT FIVE MINUTES TO DOWNLOAD ON COLAB\n",
    "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "!unzip glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9Zt3py7E1ep"
   },
   "source": [
    "## Import and preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WRa2x424R1s"
   },
   "outputs": [],
   "source": [
    "def tokenizer(text): # create a tokenizer function for gloVe\n",
    "    res = [tok.text for tok in nlp_spaCy.tokenizer(text)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z9qQiPkQ3cna"
   },
   "outputs": [],
   "source": [
    "def downsample(train_df):\n",
    "  #ONLY USE THIS IF YOU WANT TO DOWNSAMPLE DATA - everything should work w/o this cell\n",
    "  #Select a subset of the data so that the classes are equally balanced\n",
    "  #Use downsampling for now. \n",
    "\n",
    "  num_NOT = 8840\n",
    "  num_OFF = 4400\n",
    "  # Separate majority and minority classes\n",
    "  df_majority = train_df[train_df[\"subtask_a\"] == 'NOT']\n",
    "  df_minority = train_df[train_df[\"subtask_a\"] == 'OFF']\n",
    "\n",
    "  # Downsample majority class\n",
    "  df_majority_downsampled = resample(df_majority, \n",
    "                                   replace=False,    # sample without replacement\n",
    "                                   n_samples=num_OFF,     # to match minority class\n",
    "                                   random_state=123) # reproducible results\n",
    "\n",
    "  # Combine minority class with downsampled majority class\n",
    "  df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "  # Display new class counts\n",
    "  print(df_downsampled.subtask_a.value_counts())\n",
    "\n",
    "  df_downsampled = df_downsampled.sample(frac=1) #shuffle df\n",
    "\n",
    "  return df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aMY0mUyknLDu"
   },
   "outputs": [],
   "source": [
    "def tweet_preprocess(tweet_text):\n",
    "  \"\"\"Add tweet specific preprocessing steps here\"\"\"\n",
    "  \n",
    "  #Remove 'USER' (but leave '@')\n",
    "  tweet_text = tweet_text.replace(\"@USER\", \"@\") \n",
    "  \n",
    "  return tweet_text\n",
    "\n",
    "def convert_labels_A(labels):\n",
    "    \"\"\"Preproceses and return labels\"\"\"\n",
    "\n",
    "    final_labels = []\n",
    "    for label in labels:\n",
    "        assert label == \"OFF\" or label == \"NOT\", \"Label should not be: {}\".format(label)\n",
    "    \n",
    "        if label == \"OFF\":\n",
    "            res = 1\n",
    "        elif label == \"NOT\":\n",
    "            res = 0        \n",
    "        label = torch.tensor([res])\n",
    "        final_labels.append(label)\n",
    "    return final_labels\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "imjsxr66hDWP"
   },
   "outputs": [],
   "source": [
    "def transfrom_for_scikit(task_header, text_field, label_field, embedding, train):\n",
    "  \"\"\"\n",
    "  task_header is one of subtask_a, subtask_b, subtask_c\n",
    "  \"\"\"\n",
    "  tokenised_train = [example.tweet for example in train]\n",
    "  labels = np.array(\n",
    "      label_field.process(\n",
    "          [getattr(example, task_header) for example in train]\n",
    "      )\n",
    "  )\n",
    "  \n",
    "  word_idxs = text_field.process(tokenised_train)\n",
    "  embeddings = torch.mean(embedding(word_idxs).detach(), dim=1)\n",
    "  \n",
    "  return embeddings.numpy(), labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uuWD9loshx_X"
   },
   "source": [
    "## Utils Functions For Neural Network Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8q-_NUtiT8n"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(task_header, loader, model, conf=False):\n",
    "    \"\"\"\n",
    "    Note at the moment this function assumes the batch size is equal to the \n",
    "    number of data in the loader when calculating the confusion matrix\n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(loader):\n",
    "            x, y = batch.tweet, getattr(batch, task_header)\n",
    "            y = y.view(-1, 1)\n",
    "                \n",
    "            x = x.to(device=device, dtype=torch.long)  # move to  GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            if task_header == 'subtask_c':\n",
    "              pred_prob = F.softmax(model(x), dim=1)\n",
    "              pred_1 = torch.argmax(pred_prob, dim=1).view(-1, 1)\n",
    "            else:\n",
    "              pred_prob = torch.sigmoid(model(x))\n",
    "              pred_1 = (pred_prob > 0.5).type(torch.long)\n",
    "              \n",
    "            num_correct += (pred_1 == y).sum()\n",
    "            num_samples += pred_prob.size(0)\n",
    "            \n",
    "            # move to CPU to prevent memory overflow and calculate metrics\n",
    "            x = x.to(device=\"cpu\", dtype=torch.long)\n",
    "            y = y.to(device=\"cpu\", dtype=torch.long).numpy()\n",
    "            pred_1 = pred_1.to(device=\"cpu\", dtype=torch.long).numpy()\n",
    "            \n",
    "            \n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        if conf:\n",
    "            print(metrics.confusion_matrix(y, pred_1))\n",
    "            print(metrics.classification_report(y, pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oXFOMchMitEY"
   },
   "outputs": [],
   "source": [
    "def check_loss(task_header, loader, model, loss_fn):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    loss = 0\n",
    "    for idx, batch in enumerate(loader):\n",
    "      x, y = batch.tweet, getattr(batch, task_header)\n",
    "      \n",
    "      x = x.to(device=device, dtype=torch.long) \n",
    "      y = y.to(device=device, dtype=torch.long if task_header == 'subtask_c' else torch.float)\n",
    "      \n",
    "      logits = model(x)\n",
    "      \n",
    "      loss += loss_fn(logits, y.view(-1,) if isinstance(loss_fn, nn.CrossEntropyLoss) else y.view(-1, 1))\n",
    "      \n",
    "    return loss/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YurUJzZji6Rq"
   },
   "outputs": [],
   "source": [
    "def train_helper(task_header, model, optimizer, train_loader, \n",
    "               valid_loader, epochs=1, loss_fn=F.binary_cross_entropy_with_logits, print_every=50):\n",
    "    \"\"\"\n",
    "    Train a model\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to GPU\n",
    "    \n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch:\", epoch)\n",
    "            total_loss = 0\n",
    "            for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "                model.train()  # put model to training mode\n",
    "                \n",
    "                inputs, targets = batch.tweet, getattr(batch, task_header)\n",
    "                \n",
    "                x = inputs.to(device=device, dtype=torch.long)  # move to device, e.g. GPU\n",
    "                y = targets.to(device=device, dtype=torch.long if task_header == 'subtask_c' else torch.float) #this should be a float cross entropy\n",
    "                #x = inputs\n",
    "                #y = targets\n",
    "                logits = model(x)\n",
    "                \n",
    "                # When using cross_entropy the targets need to have a shape (N,)\n",
    "                # However, for BCEWithLogits they just need\n",
    "                # to have the same shape as the logits\n",
    "                loss = loss_fn(logits, y.view(-1,) if isinstance(loss_fn, nn.CrossEntropyLoss) else y.view(-1, 1))\n",
    "                # Zero out all of the gradients for the variables which the optimizer\n",
    "                # will update.\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # This is the backwards pass: compute the gradient of the loss with\n",
    "                # respect to each  parameter of the model.\n",
    "                loss.backward()\n",
    "\n",
    "                # Actually update the parameters of the model using the gradients\n",
    "                # computed by the backwards pass.\n",
    "                optimizer.step()\n",
    "\n",
    "                x = x.to(device=\"cpu\", dtype=torch.long)  # move to CPU to prevent memory overflow\n",
    "                y = y.to(device=\"cpu\", dtype=torch.long)\n",
    "\n",
    "                total_loss += loss.detach().item()\n",
    "                \n",
    "                if batch_idx % print_every == 0:\n",
    "                    print('Iteration %d, loss = %.4f' % (batch_idx, loss.item()))\n",
    "            \n",
    "            training_losses.append(total_loss/len(train_iterator))\n",
    "            print()\n",
    "            print(\"Validation Accuracy:\")\n",
    "            check_accuracy(task_header, valid_loader, model, conf=True)\n",
    "            valid_loss = check_loss(task_header, valid_loader, model, loss_fn)\n",
    "            validation_losses.append(valid_loss)\n",
    "            print()\n",
    "        return training_losses, validation_losses\n",
    "    except Exception as e:\n",
    "        #Attempt to prevent GPU memory overflow by transferring model back to cpu\n",
    "        #model = model.to(device=\"cpu\")\n",
    "        raise e    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tl9IC4d1jx-0"
   },
   "source": [
    "## Simple Neural Network Classifier for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yuwrip1gj43k"
   },
   "outputs": [],
   "source": [
    "#embedding (lookup layer) layer\n",
    "class SimpleClassifierGloVe(nn.Module):\n",
    "    \"\"\"Glove w. 2d conv\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab, embedding_dim, window_size, out_channels, dropout, num_classes=2):\n",
    "        \n",
    "        super(SimpleClassifierGloVe, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
    "        self.embedding.weight.data.copy_(vocab.vectors) # copies pre-trained word vectors\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(window_size, embedding_dim))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.fc = nn.Linear(out_channels, 1 if num_classes == 2 else num_classes)\n",
    "\n",
    "        #Kaming normalization\n",
    "        nn.init.kaiming_normal_(self.conv.weight)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x, ):\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "                \n",
    "        #(batch size, max sent length, embedding dim)\n",
    "        \n",
    "        #images have 3 RGB channels \n",
    "        #for the text we add 1 channel\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #(batch size, 1, max sent length, embedding dim)\n",
    "        \n",
    "        feature_maps =  F.relu(self.conv(embedded).squeeze(3))\n",
    "        # (batch size, out_channels, max sent length - window size +1, 1)\n",
    "        # -> (batch size, out_channels, max sent length - window size +1)\n",
    "           \n",
    "        #the max pooling layer\n",
    "        pooled = F.max_pool1d(feature_maps, feature_maps.shape[2]).squeeze(2)\n",
    "        # (batch size, out_channels)      \n",
    "        \n",
    "        return self.fc(self.dropout(pooled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1TwMNFOKRSm"
   },
   "source": [
    "# Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "WO69uqM3LtBS",
    "outputId": "60fcbf22-3b39-486e-9a04-bb9f66b85ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 10592\n",
      "Validation size: 2648\n"
     ]
    }
   ],
   "source": [
    "#Create fields\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
    "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
    "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
    "\n",
    "data_fields = [('id', ID), \n",
    "               ('tweet', TEXT),\n",
    "               ('subtask_a',LABEL),\n",
    "               ('subtask_b',LABEL),\n",
    "               ('subtask_c',LABEL)]\n",
    "\n",
    "\n",
    "train = data.TabularDataset(train_fp, format='TSV', fields = \n",
    "                            data_fields, skip_header=True, filter_pred=None)\n",
    "\n",
    "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
    "\n",
    "print(f'Train size: {len(train)}')\n",
    "print(f'Validation size: {len(valid)}')\n",
    "\n",
    "#Now build vocab (using only the training set)\n",
    "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d') #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
    "\n",
    "LABEL.build_vocab(train.subtask_a)\n",
    "\n",
    "output_dim = len(LABEL.vocab)\n",
    "\n",
    "#Create iterators\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
    "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
    "                        sort_key=lambda x: len(x.tweet), device=device)\n",
    "\n",
    "# For retrieving tweet text later on\n",
    "train_df = pd.read_csv(train_fp, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "KkGDZeI-rccB",
    "outputId": "f1b9d8c1-bfa7-460c-ee05-9aa8fcb77c43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first tweet ['@user', '@user', 'a', 'must', 'read', '!', 'url']\n",
      "first label NOT\n",
      "first tweet id: 29719\n"
     ]
    }
   ],
   "source": [
    "print('first tweet', train[0].tweet)\n",
    "print('first label', train[0].subtask_a)\n",
    "print(\"first tweet id:\", train[0].id)\n",
    "# print(TEXT.vocab.stoi) # word to index\n",
    "# print(LABEL.vocab.stoi) # label to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "Q9_NCwh3C1Z4",
    "outputId": "95480127-073c-4a8e-b5d4-8923bdea6247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 74])\n",
      "torch.Size([128])\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "#check loader\n",
    "for idx, batch in enumerate(train_iterator):\n",
    "    inputs, labels = batch.tweet, batch.subtask_a\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    print(len(train_iterator))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fDY70XMRLQk_"
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6065
    },
    "colab_type": "code",
    "id": "X9LseL5F9n7P",
    "outputId": "44404f41-59c9-4d7c-8184-0c2340a4a49d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Iteration 0, loss = 1.0612\n",
      "Iteration 50, loss = 0.8165\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 1812 / 2648 correct (68.43)\n",
      "[[1751   22]\n",
      " [ 814   61]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.99      0.81      1773\n",
      "           1       0.73      0.07      0.13       875\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      2648\n",
      "   macro avg       0.71      0.53      0.47      2648\n",
      "weighted avg       0.70      0.68      0.58      2648\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "Iteration 0, loss = 0.6553\n",
      "Iteration 50, loss = 0.6840\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 1857 / 2648 correct (70.13)\n",
      "[[1724   49]\n",
      " [ 742  133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.81      1773\n",
      "           1       0.73      0.15      0.25       875\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      2648\n",
      "   macro avg       0.71      0.56      0.53      2648\n",
      "weighted avg       0.71      0.70      0.63      2648\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "Iteration 0, loss = 0.7066\n",
      "Iteration 50, loss = 0.6311\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 1928 / 2648 correct (72.81)\n",
      "[[1687   86]\n",
      " [ 634  241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.82      1773\n",
      "           1       0.74      0.28      0.40       875\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      2648\n",
      "   macro avg       0.73      0.61      0.61      2648\n",
      "weighted avg       0.73      0.73      0.68      2648\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "Iteration 0, loss = 0.5704\n",
      "Iteration 50, loss = 0.4944\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 1984 / 2648 correct (74.92)\n",
      "[[1663  110]\n",
      " [ 554  321]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.83      1773\n",
      "           1       0.74      0.37      0.49       875\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      2648\n",
      "   macro avg       0.75      0.65      0.66      2648\n",
      "weighted avg       0.75      0.75      0.72      2648\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "Iteration 0, loss = 0.5192\n",
      "Iteration 50, loss = 0.5326\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2013 / 2648 correct (76.02)\n",
      "[[1641  132]\n",
      " [ 503  372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84      1773\n",
      "           1       0.74      0.43      0.54       875\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      2648\n",
      "   macro avg       0.75      0.68      0.69      2648\n",
      "weighted avg       0.76      0.76      0.74      2648\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "Iteration 0, loss = 0.4955\n",
      "Iteration 50, loss = 0.4404\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2042 / 2648 correct (77.11)\n",
      "[[1623  150]\n",
      " [ 456  419]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84      1773\n",
      "           1       0.74      0.48      0.58       875\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      2648\n",
      "   macro avg       0.76      0.70      0.71      2648\n",
      "weighted avg       0.77      0.77      0.76      2648\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "Iteration 0, loss = 0.4874\n",
      "Iteration 50, loss = 0.4161\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2047 / 2648 correct (77.30)\n",
      "[[1635  138]\n",
      " [ 463  412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84      1773\n",
      "           1       0.75      0.47      0.58       875\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      2648\n",
      "   macro avg       0.76      0.70      0.71      2648\n",
      "weighted avg       0.77      0.77      0.76      2648\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "Iteration 0, loss = 0.5494\n",
      "Iteration 50, loss = 0.3974\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2063 / 2648 correct (77.91)\n",
      "[[1615  158]\n",
      " [ 427  448]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85      1773\n",
      "           1       0.74      0.51      0.60       875\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      2648\n",
      "   macro avg       0.77      0.71      0.73      2648\n",
      "weighted avg       0.77      0.78      0.77      2648\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "Iteration 0, loss = 0.4724\n",
      "Iteration 50, loss = 0.3745\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2066 / 2648 correct (78.02)\n",
      "[[1588  185]\n",
      " [ 397  478]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85      1773\n",
      "           1       0.72      0.55      0.62       875\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      2648\n",
      "   macro avg       0.76      0.72      0.73      2648\n",
      "weighted avg       0.77      0.78      0.77      2648\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "Iteration 0, loss = 0.3754\n",
      "Iteration 50, loss = 0.3746\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2068 / 2648 correct (78.10)\n",
      "[[1585  188]\n",
      " [ 392  483]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.85      1773\n",
      "           1       0.72      0.55      0.62       875\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      2648\n",
      "   macro avg       0.76      0.72      0.74      2648\n",
      "weighted avg       0.77      0.78      0.77      2648\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "Iteration 0, loss = 0.3969\n",
      "Iteration 50, loss = 0.4227\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2078 / 2648 correct (78.47)\n",
      "[[1611  162]\n",
      " [ 408  467]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85      1773\n",
      "           1       0.74      0.53      0.62       875\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      2648\n",
      "   macro avg       0.77      0.72      0.74      2648\n",
      "weighted avg       0.78      0.78      0.77      2648\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "Iteration 0, loss = 0.3259\n",
      "Iteration 50, loss = 0.4949\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2073 / 2648 correct (78.29)\n",
      "[[1587  186]\n",
      " [ 389  486]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85      1773\n",
      "           1       0.72      0.56      0.63       875\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      2648\n",
      "   macro avg       0.76      0.73      0.74      2648\n",
      "weighted avg       0.78      0.78      0.77      2648\n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "Iteration 0, loss = 0.3428\n",
      "Iteration 50, loss = 0.2852\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2081 / 2648 correct (78.59)\n",
      "[[1587  186]\n",
      " [ 381  494]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85      1773\n",
      "           1       0.73      0.56      0.64       875\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      2648\n",
      "   macro avg       0.77      0.73      0.74      2648\n",
      "weighted avg       0.78      0.79      0.78      2648\n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "Iteration 0, loss = 0.3374\n",
      "Iteration 50, loss = 0.3137\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2079 / 2648 correct (78.51)\n",
      "[[1582  191]\n",
      " [ 378  497]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85      1773\n",
      "           1       0.72      0.57      0.64       875\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      2648\n",
      "   macro avg       0.76      0.73      0.74      2648\n",
      "weighted avg       0.78      0.79      0.78      2648\n",
      "\n",
      "\n",
      "Epoch: 14\n",
      "Iteration 0, loss = 0.2863\n",
      "Iteration 50, loss = 0.3070\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2085 / 2648 correct (78.74)\n",
      "[[1600  173]\n",
      " [ 390  485]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85      1773\n",
      "           1       0.74      0.55      0.63       875\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      2648\n",
      "   macro avg       0.77      0.73      0.74      2648\n",
      "weighted avg       0.78      0.79      0.78      2648\n",
      "\n",
      "\n",
      "Epoch: 15\n",
      "Iteration 0, loss = 0.2511\n",
      "Iteration 50, loss = 0.3355\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2082 / 2648 correct (78.63)\n",
      "[[1589  184]\n",
      " [ 382  493]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85      1773\n",
      "           1       0.73      0.56      0.64       875\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      2648\n",
      "   macro avg       0.77      0.73      0.74      2648\n",
      "weighted avg       0.78      0.79      0.78      2648\n",
      "\n",
      "\n",
      "Epoch: 16\n",
      "Iteration 0, loss = 0.3736\n",
      "Iteration 50, loss = 0.2626\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2083 / 2648 correct (78.66)\n",
      "[[1582  191]\n",
      " [ 374  501]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85      1773\n",
      "           1       0.72      0.57      0.64       875\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      2648\n",
      "   macro avg       0.77      0.73      0.74      2648\n",
      "weighted avg       0.78      0.79      0.78      2648\n",
      "\n",
      "\n",
      "Epoch: 17\n",
      "Iteration 0, loss = 0.2523\n",
      "Iteration 50, loss = 0.2900\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2081 / 2648 correct (78.59)\n",
      "[[1593  180]\n",
      " [ 387  488]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85      1773\n",
      "           1       0.73      0.56      0.63       875\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      2648\n",
      "   macro avg       0.77      0.73      0.74      2648\n",
      "weighted avg       0.78      0.79      0.78      2648\n",
      "\n",
      "\n",
      "Epoch: 18\n",
      "Iteration 0, loss = 0.2629\n",
      "Iteration 50, loss = 0.2978\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2073 / 2648 correct (78.29)\n",
      "[[1568  205]\n",
      " [ 370  505]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85      1773\n",
      "           1       0.71      0.58      0.64       875\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      2648\n",
      "   macro avg       0.76      0.73      0.74      2648\n",
      "weighted avg       0.78      0.78      0.78      2648\n",
      "\n",
      "\n",
      "Epoch: 19\n",
      "Iteration 0, loss = 0.2542\n",
      "Iteration 50, loss = 0.2298\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 2080 / 2648 correct (78.55)\n",
      "[[1583  190]\n",
      " [ 378  497]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85      1773\n",
      "           1       0.72      0.57      0.64       875\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      2648\n",
      "   macro avg       0.77      0.73      0.74      2648\n",
      "weighted avg       0.78      0.79      0.78      2648\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CONV with Glove\n",
    "embedding_dim = 200\n",
    "window_size = 3\n",
    "lr = 0.00025\n",
    "out_channels = 100\n",
    "dropout = 0.5\n",
    "\n",
    "model = SimpleClassifierGloVe(TEXT.vocab,\n",
    "                              embedding_dim,\n",
    "                              window_size,\n",
    "                              out_channels,\n",
    "                              dropout)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "t_losses, v_losses = train_helper('subtask_a',\n",
    "                                  model,\n",
    "                                  optimizer,\n",
    "                                  loss_fn = loss_fn,\n",
    "                                  epochs = 20,\n",
    "                                  train_loader=train_iterator,\n",
    "                                  valid_loader=valid_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "S_q8EEjwwLf3",
    "outputId": "2a21b8c5-1c42-489f-877a-544735b9dd33"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(t_losses, label='Training')\n",
    "ax1.plot(v_losses, label='Validation')\n",
    "\n",
    "ax1.set_title('Losses')\n",
    "ax1.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lvLKpsdyLYLA"
   },
   "source": [
    "## SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1ieRLJXxc4u"
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
    "embedding.weight.data.copy_(TEXT.vocab.vectors) # copies pre-trained word vectors\n",
    "\n",
    "training_embeddings, training_labels = transfrom_for_scikit('subtask_a', TEXT, LABEL, embedding, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "7p1nXF7VxRTe",
    "outputId": "4224e747-8be7-4cb8-d719-51abbc7f8368"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight={1: 2},\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=20,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=20, tol=None, class_weight={1: 2})\n",
    "clf.fit(training_embeddings, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jY98yEhJxoSl"
   },
   "outputs": [],
   "source": [
    "val_embeddings, val_labels = transfrom_for_scikit('subtask_a', TEXT, LABEL, embedding, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "I20xsZIJIzu3",
    "outputId": "b49ba748-b10c-40b7-ac63-9b76565e5796"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1426  347]\n",
      " [ 476  399]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.78      1773\n",
      "           1       0.53      0.46      0.49       875\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      2648\n",
      "   macro avg       0.64      0.63      0.63      2648\n",
      "weighted avg       0.68      0.69      0.68      2648\n",
      "\n",
      "Accuracy: 0.6891993957703928\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(val_embeddings)\n",
    "\n",
    "print(metrics.confusion_matrix(val_labels, preds))\n",
    "print(metrics.classification_report(val_labels, preds))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(val_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VFiG4aRQPpN5"
   },
   "source": [
    "# Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "2YbsX0DyP1B0",
    "outputId": "ab2bc8e9-09df-4ccd-9e31-33839dfdcc60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3520\n",
      "Validation size: 880\n",
      "defaultdict(<function _default_unk_index at 0x7ff06cb16598>, {'TIN': 0, 'UNT': 1})\n"
     ]
    }
   ],
   "source": [
    "#Create fields\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first=True)\n",
    "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
    "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
    "\n",
    "data_fields = [('id', ID), \n",
    "               ('tweet', TEXT),\n",
    "               ('subtask_a', LABEL),\n",
    "               ('subtask_b',LABEL)\n",
    "              ]\n",
    "\n",
    "train = data.TabularDataset(train_fp,\n",
    "                            format='TSV',\n",
    "                            fields=data_fields,\n",
    "                            skip_header=True,\n",
    "                            filter_pred=lambda d: d.subtask_a == 'OFF')\n",
    "\n",
    "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
    "\n",
    "print(f'Train size: {len(train)}')\n",
    "print(f'Validation size: {len(valid)}')\n",
    "\n",
    "#Now build vocab (using only the training set)\n",
    "# This is where tokenization is performed on train\n",
    "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d')\n",
    "\n",
    "LABEL.build_vocab(train.subtask_b)\n",
    "\n",
    "output_dim = len(LABEL.vocab)\n",
    "\n",
    "print(LABEL.vocab.stoi)\n",
    "\n",
    "#Create iterators\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
    "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
    "                        sort_key=lambda x: len(x.tweet), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IiZlui1OMTtv"
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8638
    },
    "colab_type": "code",
    "id": "uww_bdubSnf3",
    "outputId": "afe13d97-3629-46da-a49d-5f93fb9c5455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Iteration 0, loss = 0.4465\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 768 / 880 correct (87.27)\n",
      "[[768   0]\n",
      " [112   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.44      0.50      0.47       880\n",
      "weighted avg       0.76      0.87      0.81       880\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "Iteration 0, loss = 0.4246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracy:\n",
      "Got 768 / 880 correct (87.27)\n",
      "[[768   0]\n",
      " [112   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.44      0.50      0.47       880\n",
      "weighted avg       0.76      0.87      0.81       880\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "Iteration 0, loss = 0.2984\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 768 / 880 correct (87.27)\n",
      "[[768   0]\n",
      " [112   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.44      0.50      0.47       880\n",
      "weighted avg       0.76      0.87      0.81       880\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "Iteration 0, loss = 0.3550\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 768 / 880 correct (87.27)\n",
      "[[768   0]\n",
      " [112   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.44      0.50      0.47       880\n",
      "weighted avg       0.76      0.87      0.81       880\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "Iteration 0, loss = 0.3045\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 768 / 880 correct (87.27)\n",
      "[[768   0]\n",
      " [112   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.44      0.50      0.47       880\n",
      "weighted avg       0.76      0.87      0.81       880\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "Iteration 0, loss = 0.3981\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 768 / 880 correct (87.27)\n",
      "[[768   0]\n",
      " [112   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.44      0.50      0.47       880\n",
      "weighted avg       0.76      0.87      0.81       880\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "Iteration 0, loss = 0.4584\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 768 / 880 correct (87.27)\n",
      "[[768   0]\n",
      " [112   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.44      0.50      0.47       880\n",
      "weighted avg       0.76      0.87      0.81       880\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "Iteration 0, loss = 0.2456\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 768 / 880 correct (87.27)\n",
      "[[768   0]\n",
      " [112   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.44      0.50      0.47       880\n",
      "weighted avg       0.76      0.87      0.81       880\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "Iteration 0, loss = 0.3445\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 768 / 880 correct (87.27)\n",
      "[[768   0]\n",
      " [112   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.44      0.50      0.47       880\n",
      "weighted avg       0.76      0.87      0.81       880\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "Iteration 0, loss = 0.1510\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 768 / 880 correct (87.27)\n",
      "[[768   0]\n",
      " [112   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.44      0.50      0.47       880\n",
      "weighted avg       0.76      0.87      0.81       880\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "Iteration 0, loss = 0.2723\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 768 / 880 correct (87.27)\n",
      "[[768   0]\n",
      " [112   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       0.00      0.00      0.00       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.44      0.50      0.47       880\n",
      "weighted avg       0.76      0.87      0.81       880\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "Iteration 0, loss = 0.2617\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 769 / 880 correct (87.39)\n",
      "[[768   0]\n",
      " [111   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       1.00      0.01      0.02       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.94      0.50      0.48       880\n",
      "weighted avg       0.89      0.87      0.82       880\n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "Iteration 0, loss = 0.3583\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 769 / 880 correct (87.39)\n",
      "[[768   0]\n",
      " [111   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       1.00      0.01      0.02       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.94      0.50      0.48       880\n",
      "weighted avg       0.89      0.87      0.82       880\n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "Iteration 0, loss = 0.3315\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 770 / 880 correct (87.50)\n",
      "[[768   0]\n",
      " [110   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       768\n",
      "           1       1.00      0.02      0.04       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.94      0.51      0.48       880\n",
      "weighted avg       0.89      0.88      0.82       880\n",
      "\n",
      "\n",
      "Epoch: 14\n",
      "Iteration 0, loss = 0.3320\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 771 / 880 correct (87.61)\n",
      "[[768   0]\n",
      " [109   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       768\n",
      "           1       1.00      0.03      0.05       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.94      0.51      0.49       880\n",
      "weighted avg       0.89      0.88      0.82       880\n",
      "\n",
      "\n",
      "Epoch: 15\n",
      "Iteration 0, loss = 0.2468\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 771 / 880 correct (87.61)\n",
      "[[768   0]\n",
      " [109   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       768\n",
      "           1       1.00      0.03      0.05       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.94      0.51      0.49       880\n",
      "weighted avg       0.89      0.88      0.82       880\n",
      "\n",
      "\n",
      "Epoch: 16\n",
      "Iteration 0, loss = 0.1786\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 773 / 880 correct (87.84)\n",
      "[[768   0]\n",
      " [107   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       768\n",
      "           1       1.00      0.04      0.09       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.94      0.52      0.51       880\n",
      "weighted avg       0.89      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 17\n",
      "Iteration 0, loss = 0.2153\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 773 / 880 correct (87.84)\n",
      "[[768   0]\n",
      " [107   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       768\n",
      "           1       1.00      0.04      0.09       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.94      0.52      0.51       880\n",
      "weighted avg       0.89      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 18\n",
      "Iteration 0, loss = 0.2380\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 773 / 880 correct (87.84)\n",
      "[[768   0]\n",
      " [107   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       768\n",
      "           1       1.00      0.04      0.09       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.94      0.52      0.51       880\n",
      "weighted avg       0.89      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 19\n",
      "Iteration 0, loss = 0.1373\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 774 / 880 correct (87.95)\n",
      "[[768   0]\n",
      " [106   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       768\n",
      "           1       1.00      0.05      0.10       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.94      0.53      0.52       880\n",
      "weighted avg       0.89      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 20\n",
      "Iteration 0, loss = 0.1931\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 774 / 880 correct (87.95)\n",
      "[[768   0]\n",
      " [106   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       768\n",
      "           1       1.00      0.05      0.10       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.94      0.53      0.52       880\n",
      "weighted avg       0.89      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 21\n",
      "Iteration 0, loss = 0.2730\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 773 / 880 correct (87.84)\n",
      "[[767   1]\n",
      " [106   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       768\n",
      "           1       0.86      0.05      0.10       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.87      0.53      0.52       880\n",
      "weighted avg       0.88      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 22\n",
      "Iteration 0, loss = 0.2286\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 772 / 880 correct (87.73)\n",
      "[[766   2]\n",
      " [106   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       768\n",
      "           1       0.75      0.05      0.10       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.81      0.53      0.52       880\n",
      "weighted avg       0.86      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 23\n",
      "Iteration 0, loss = 0.1643\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 772 / 880 correct (87.73)\n",
      "[[766   2]\n",
      " [106   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       768\n",
      "           1       0.75      0.05      0.10       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.81      0.53      0.52       880\n",
      "weighted avg       0.86      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 24\n",
      "Iteration 0, loss = 0.2447\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 772 / 880 correct (87.73)\n",
      "[[766   2]\n",
      " [106   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       768\n",
      "           1       0.75      0.05      0.10       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.81      0.53      0.52       880\n",
      "weighted avg       0.86      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 25\n",
      "Iteration 0, loss = 0.1753\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 771 / 880 correct (87.61)\n",
      "[[765   3]\n",
      " [106   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       768\n",
      "           1       0.67      0.05      0.10       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.77      0.52      0.52       880\n",
      "weighted avg       0.85      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 26\n",
      "Iteration 0, loss = 0.1270\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 770 / 880 correct (87.50)\n",
      "[[764   4]\n",
      " [106   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       768\n",
      "           1       0.60      0.05      0.10       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.74      0.52      0.52       880\n",
      "weighted avg       0.84      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 27\n",
      "Iteration 0, loss = 0.1361\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 770 / 880 correct (87.50)\n",
      "[[764   4]\n",
      " [106   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       768\n",
      "           1       0.60      0.05      0.10       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.74      0.52      0.52       880\n",
      "weighted avg       0.84      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 28\n",
      "Iteration 0, loss = 0.1748\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 770 / 880 correct (87.50)\n",
      "[[764   4]\n",
      " [106   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       768\n",
      "           1       0.60      0.05      0.10       112\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       880\n",
      "   macro avg       0.74      0.52      0.52       880\n",
      "weighted avg       0.84      0.88      0.83       880\n",
      "\n",
      "\n",
      "Epoch: 29\n",
      "Iteration 0, loss = 0.1217\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 769 / 880 correct (87.39)\n",
      "[[763   5]\n",
      " [106   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       768\n",
      "           1       0.55      0.05      0.10       112\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       880\n",
      "   macro avg       0.71      0.52      0.51       880\n",
      "weighted avg       0.84      0.87      0.83       880\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CONV with Glove\n",
    "embedding_dim = 200\n",
    "window_size = 3\n",
    "lr = 0.00025\n",
    "out_channels = 100\n",
    "dropout = 0.5\n",
    "\n",
    "model = SimpleClassifierGloVe(TEXT.vocab, embedding_dim, window_size, out_channels, dropout)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "t_losses, v_losses = train_helper('subtask_b',\n",
    "                                  model,\n",
    "                                  optimizer,\n",
    "                                  loss_fn = loss_fn,\n",
    "                                  epochs = 30,\n",
    "                                  train_loader=train_iterator,\n",
    "                                  valid_loader=valid_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "AiLub0TBVF_i",
    "outputId": "9b433c4f-e978-42e9-ec70-7212559b2a6b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC58AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(t_losses, label='Training')\n",
    "ax1.plot(v_losses, label='Validation')\n",
    "\n",
    "ax1.set_title('Losses')\n",
    "ax1.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRbbL2s-MGOv"
   },
   "source": [
    "## SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4Q7ir143rdl"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
    "embedding.weight.data.copy_(TEXT.vocab.vectors) # copies pre-trained word vectors\n",
    "\n",
    "training_embeddings, training_labels = transfrom_for_scikit('subtask_b', TEXT, LABEL, embedding, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "_1ONs8nc3-G2",
    "outputId": "f21d9007-65c1-4952-e542-c5b4904f4ebe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight={1: 6.8},\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=20,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=20, tol=None, class_weight={1: 6.8})\n",
    "clf.fit(training_embeddings, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "--Z5tRoD494A"
   },
   "outputs": [],
   "source": [
    "val_embeddings, val_labels = transfrom_for_scikit('subtask_b', TEXT, LABEL, embedding, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "OYC4b0Xj5HUn",
    "outputId": "931a768e-1aa4-4ce0-9409-11a391abb776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[425 343]\n",
      " [ 30  82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.55      0.70       768\n",
      "           1       0.19      0.73      0.31       112\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       880\n",
      "   macro avg       0.56      0.64      0.50       880\n",
      "weighted avg       0.84      0.58      0.65       880\n",
      "\n",
      "Accuracy: 0.5761363636363637\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(val_embeddings)\n",
    "\n",
    "print(metrics.confusion_matrix(val_labels, preds))\n",
    "print(metrics.classification_report(val_labels, preds))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(val_labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzDUdTT8Agxo"
   },
   "source": [
    "# Task C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "Wf47-PIDAlIw",
    "outputId": "27190f48-0944-466f-f2bc-423e0f27728a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3101\n",
      "Validation size: 775\n",
      "defaultdict(<function _default_unk_index at 0x7ff06cb16598>, {'IND': 0, 'GRP': 1, 'OTH': 2})\n"
     ]
    }
   ],
   "source": [
    "#Create fields\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
    "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
    "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
    "\n",
    "data_fields = [('id', ID), \n",
    "               ('tweet', TEXT),\n",
    "               ('subtask_a', LABEL),\n",
    "               ('subtask_b',LABEL),\n",
    "               ('subtask_c', LABEL)\n",
    "              ]\n",
    "\n",
    "train = data.TabularDataset(train_fp,\n",
    "                            format='TSV',\n",
    "                            fields=data_fields,\n",
    "                            skip_header=True,\n",
    "                            filter_pred=lambda d: d.subtask_a == 'OFF' and d.subtask_b == 'TIN')\n",
    "\n",
    "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
    "\n",
    "print(f'Train size: {len(train)}')\n",
    "print(f'Validation size: {len(valid)}')\n",
    "\n",
    "#Now build vocab (using only the training set)\n",
    "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d')\n",
    "\n",
    "LABEL.build_vocab(train.subtask_c)\n",
    "\n",
    "output_dim = len(LABEL.vocab)\n",
    "\n",
    "print(LABEL.vocab.stoi)\n",
    "\n",
    "#Create iterators\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
    "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
    "                        sort_key=lambda x: len(x.tweet), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DhFZzmTiMXSy"
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6401
    },
    "colab_type": "code",
    "id": "UTUbzJZBBBMr",
    "outputId": "58e5b4ab-b8ba-4628-ad98-7a980802dad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Iteration 0, loss = 1.8626\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 395 / 775 correct (50.97)\n",
      "[[305  15 156]\n",
      " [ 40  36 131]\n",
      " [ 24  14  54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72       476\n",
      "           1       0.55      0.17      0.26       207\n",
      "           2       0.16      0.59      0.25        92\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       775\n",
      "   macro avg       0.51      0.47      0.41       775\n",
      "weighted avg       0.67      0.51      0.54       775\n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "Iteration 0, loss = 1.0895\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 519 / 775 correct (66.97)\n",
      "[[369  92  15]\n",
      " [ 52 144  11]\n",
      " [ 37  49   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79       476\n",
      "           1       0.51      0.70      0.59       207\n",
      "           2       0.19      0.07      0.10        92\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       775\n",
      "   macro avg       0.50      0.51      0.49       775\n",
      "weighted avg       0.65      0.67      0.65       775\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "Iteration 0, loss = 0.9512\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 536 / 775 correct (69.16)\n",
      "[[382  67  27]\n",
      " [ 51 137  19]\n",
      " [ 36  39  17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81       476\n",
      "           1       0.56      0.66      0.61       207\n",
      "           2       0.27      0.18      0.22        92\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       775\n",
      "   macro avg       0.55      0.55      0.55       775\n",
      "weighted avg       0.68      0.69      0.69       775\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "Iteration 0, loss = 0.7123\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 514 / 775 correct (66.32)\n",
      "[[352  82  42]\n",
      " [ 39 139  29]\n",
      " [ 32  37  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78       476\n",
      "           1       0.54      0.67      0.60       207\n",
      "           2       0.24      0.25      0.25        92\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       775\n",
      "   macro avg       0.54      0.55      0.54       775\n",
      "weighted avg       0.68      0.66      0.67       775\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "Iteration 0, loss = 0.6989\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 525 / 775 correct (67.74)\n",
      "[[383  69  24]\n",
      " [ 51 128  28]\n",
      " [ 37  41  14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81       476\n",
      "           1       0.54      0.62      0.58       207\n",
      "           2       0.21      0.15      0.18        92\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       775\n",
      "   macro avg       0.52      0.53      0.52       775\n",
      "weighted avg       0.67      0.68      0.67       775\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "Iteration 0, loss = 0.6561\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 516 / 775 correct (66.58)\n",
      "[[356  84  36]\n",
      " [ 38 139  30]\n",
      " [ 32  39  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79       476\n",
      "           1       0.53      0.67      0.59       207\n",
      "           2       0.24      0.23      0.23        92\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       775\n",
      "   macro avg       0.54      0.55      0.54       775\n",
      "weighted avg       0.68      0.67      0.67       775\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "Iteration 0, loss = 0.6369\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 533 / 775 correct (68.77)\n",
      "[[385  75  16]\n",
      " [ 52 133  22]\n",
      " [ 39  38  15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       476\n",
      "           1       0.54      0.64      0.59       207\n",
      "           2       0.28      0.16      0.21        92\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       775\n",
      "   macro avg       0.54      0.54      0.53       775\n",
      "weighted avg       0.67      0.69      0.68       775\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "Iteration 0, loss = 0.5294\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 536 / 775 correct (69.16)\n",
      "[[374  88  14]\n",
      " [ 47 149  11]\n",
      " [ 36  43  13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80       476\n",
      "           1       0.53      0.72      0.61       207\n",
      "           2       0.34      0.14      0.20        92\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       775\n",
      "   macro avg       0.56      0.55      0.54       775\n",
      "weighted avg       0.69      0.69      0.68       775\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "Iteration 0, loss = 0.4385\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 542 / 775 correct (69.94)\n",
      "[[387  77  12]\n",
      " [ 55 141  11]\n",
      " [ 39  39  14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       476\n",
      "           1       0.55      0.68      0.61       207\n",
      "           2       0.38      0.15      0.22        92\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       775\n",
      "   macro avg       0.58      0.55      0.54       775\n",
      "weighted avg       0.69      0.70      0.68       775\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "Iteration 0, loss = 0.5338\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 516 / 775 correct (66.58)\n",
      "[[371  57  48]\n",
      " [ 46 115  46]\n",
      " [ 34  28  30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80       476\n",
      "           1       0.57      0.56      0.57       207\n",
      "           2       0.24      0.33      0.28        92\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       775\n",
      "   macro avg       0.55      0.55      0.55       775\n",
      "weighted avg       0.69      0.67      0.68       775\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "Iteration 0, loss = 0.5551\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 524 / 775 correct (67.61)\n",
      "[[371  72  33]\n",
      " [ 44 133  30]\n",
      " [ 35  37  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80       476\n",
      "           1       0.55      0.64      0.59       207\n",
      "           2       0.24      0.22      0.23        92\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       775\n",
      "   macro avg       0.54      0.55      0.54       775\n",
      "weighted avg       0.68      0.68      0.68       775\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "Iteration 0, loss = 0.5099\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 525 / 775 correct (67.74)\n",
      "[[364  86  26]\n",
      " [ 42 144  21]\n",
      " [ 35  40  17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79       476\n",
      "           1       0.53      0.70      0.60       207\n",
      "           2       0.27      0.18      0.22        92\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       775\n",
      "   macro avg       0.54      0.55      0.54       775\n",
      "weighted avg       0.68      0.68      0.67       775\n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "Iteration 0, loss = 0.5616\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 543 / 775 correct (70.06)\n",
      "[[392  76   8]\n",
      " [ 60 141   6]\n",
      " [ 40  42  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       476\n",
      "           1       0.54      0.68      0.61       207\n",
      "           2       0.42      0.11      0.17        92\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       775\n",
      "   macro avg       0.59      0.54      0.53       775\n",
      "weighted avg       0.68      0.70      0.68       775\n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "Iteration 0, loss = 0.5866\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 531 / 775 correct (68.52)\n",
      "[[370  75  31]\n",
      " [ 46 138  23]\n",
      " [ 33  36  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80       476\n",
      "           1       0.55      0.67      0.61       207\n",
      "           2       0.30      0.25      0.27        92\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       775\n",
      "   macro avg       0.56      0.56      0.56       775\n",
      "weighted avg       0.69      0.69      0.69       775\n",
      "\n",
      "\n",
      "Epoch: 14\n",
      "Iteration 0, loss = 0.4952\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 539 / 775 correct (69.55)\n",
      "[[387  67  22]\n",
      " [ 57 133  17]\n",
      " [ 37  36  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       476\n",
      "           1       0.56      0.64      0.60       207\n",
      "           2       0.33      0.21      0.25        92\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       775\n",
      "   macro avg       0.57      0.55      0.55       775\n",
      "weighted avg       0.68      0.70      0.69       775\n",
      "\n",
      "\n",
      "Epoch: 15\n",
      "Iteration 0, loss = 0.5204\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 539 / 775 correct (69.55)\n",
      "[[381  72  23]\n",
      " [ 55 138  14]\n",
      " [ 34  38  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81       476\n",
      "           1       0.56      0.67      0.61       207\n",
      "           2       0.35      0.22      0.27        92\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       775\n",
      "   macro avg       0.57      0.56      0.56       775\n",
      "weighted avg       0.69      0.70      0.69       775\n",
      "\n",
      "\n",
      "Epoch: 16\n",
      "Iteration 0, loss = 0.5187\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 530 / 775 correct (68.39)\n",
      "[[369  89  18]\n",
      " [ 46 146  15]\n",
      " [ 35  42  15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80       476\n",
      "           1       0.53      0.71      0.60       207\n",
      "           2       0.31      0.16      0.21        92\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       775\n",
      "   macro avg       0.55      0.55      0.54       775\n",
      "weighted avg       0.68      0.68      0.68       775\n",
      "\n",
      "\n",
      "Epoch: 17\n",
      "Iteration 0, loss = 0.4658\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 535 / 775 correct (69.03)\n",
      "[[372  95   9]\n",
      " [ 48 155   4]\n",
      " [ 37  47   8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80       476\n",
      "           1       0.52      0.75      0.62       207\n",
      "           2       0.38      0.09      0.14        92\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       775\n",
      "   macro avg       0.57      0.54      0.52       775\n",
      "weighted avg       0.68      0.69      0.67       775\n",
      "\n",
      "\n",
      "Epoch: 18\n",
      "Iteration 0, loss = 0.5839\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 526 / 775 correct (67.87)\n",
      "[[362  90  24]\n",
      " [ 45 145  17]\n",
      " [ 34  39  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79       476\n",
      "           1       0.53      0.70      0.60       207\n",
      "           2       0.32      0.21      0.25        92\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       775\n",
      "   macro avg       0.56      0.56      0.55       775\n",
      "weighted avg       0.68      0.68      0.68       775\n",
      "\n",
      "\n",
      "Epoch: 19\n",
      "Iteration 0, loss = 0.4829\n",
      "\n",
      "Validation Accuracy:\n",
      "Got 548 / 775 correct (70.71)\n",
      "[[392  77   7]\n",
      " [ 55 145   7]\n",
      " [ 39  42  11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81       476\n",
      "           1       0.55      0.70      0.62       207\n",
      "           2       0.44      0.12      0.19        92\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       775\n",
      "   macro avg       0.60      0.55      0.54       775\n",
      "weighted avg       0.69      0.71      0.69       775\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CONV with Glove\n",
    "embedding_dim = 200\n",
    "window_size = 3\n",
    "lr = 0.001\n",
    "out_channels = 512\n",
    "dropout = 0.5\n",
    "\n",
    "model = SimpleClassifierGloVe(TEXT.vocab,\n",
    "                              embedding_dim,\n",
    "                              window_size,\n",
    "                              out_channels,\n",
    "                              dropout,\n",
    "                              num_classes=3)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr, weight_decay=0.0054326444080709255)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1.6, 3.7, 8.4], device=device))\n",
    "\n",
    "\n",
    "t_losses, v_losses = train_helper('subtask_c',\n",
    "                                  model, optimizer,\n",
    "                                  loss_fn = loss_fn,\n",
    "                                  epochs = 20,\n",
    "                                  train_loader=train_iterator,\n",
    "                                  valid_loader=valid_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "TSbEtokDP1Dy",
    "outputId": "931fb25d-8ae0-4c38-9177-5bb4842c4e74"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJUohchCVJkiRJIXIRliRJkiSF/A8imZoGjjRGKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(t_losses, label='Training')\n",
    "ax1.plot(v_losses, label='Validation')\n",
    "\n",
    "ax1.set_title('Losses')\n",
    "ax1.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QLcc9NICMZdt"
   },
   "source": [
    "## SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zza6aQ1QnMyy"
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
    "embedding.weight.data.copy_(TEXT.vocab.vectors) # copies pre-trained word vectors\n",
    "\n",
    "embeddings, training_labels = transfrom_for_scikit('subtask_c', TEXT, LABEL, embedding, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qW-g6VVXgU-B"
   },
   "outputs": [],
   "source": [
    "val_embeddings, val_labels = transfrom_for_scikit('subtask_c', TEXT, LABEL, embedding, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "ahOuuuoUpZlR",
    "outputId": "464ef6d4-9e75-4500-b8db-30718621c90c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False,\n",
       "       class_weight={0: 1.6, 1: 3.7, 2: 8.4}, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
       "       random_state=42, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None, class_weight={0:1.6, 1:3.7, 2:8.4})\n",
    "\n",
    "clf.fit(embeddings, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "s_x8Fon_pfsY",
    "outputId": "a6057bd9-ea13-48d0-ff04-66d0183c356c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[363  83  30]\n",
      " [ 57 122  28]\n",
      " [ 34  38  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78       476\n",
      "           1       0.50      0.59      0.54       207\n",
      "           2       0.26      0.22      0.24        92\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       775\n",
      "   macro avg       0.52      0.52      0.52       775\n",
      "weighted avg       0.66      0.65      0.65       775\n",
      "\n",
      "Accuracy: 0.6516129032258065\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(val_embeddings)\n",
    "\n",
    "print(metrics.confusion_matrix(val_labels, preds))\n",
    "print(metrics.classification_report(val_labels, preds))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(val_labels, preds))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "xGMVF5KTg-He",
    "t9Zt3py7E1ep",
    "SClCUJp08-zn",
    "u7glEGKc-rNE"
   ],
   "include_colab_link": true,
   "name": "NLP_CW.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
