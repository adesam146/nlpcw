{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#TASK-A\" data-toc-modified-id=\"TASK-A-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>TASK A</a></span></li><li><span><a href=\"#TASK-B\" data-toc-modified-id=\"TASK-B-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>TASK B</a></span></li><li><span><a href=\"#TASK-C\" data-toc-modified-id=\"TASK-C-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>TASK C</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/adesam146/nlpcw/blob/rest_of_tasks/simple_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "xOFNCl_A8xX-",
    "outputId": "07e6ef4a-2f84-4cc5-d28e-ff7aa8b91277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/de/a0d3defd8f338eaf53ef716e40ef6d6c277c35d50e09b586e170169cdf0d/pandas-0.24.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.1MB 4.7MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
      "\u001b[31mpymc3 3.6 has requirement joblib<0.13.0, but you'll have joblib 0.13.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pandas\n",
      "  Found existing installation: pandas 0.22.0\n",
      "    Uninstalling pandas-0.22.0:\n",
      "      Successfully uninstalled pandas-0.22.0\n",
      "Successfully installed pandas-0.24.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pandas"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -U pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Srpq8hYt4whg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "EquNq-KbeEvT",
    "outputId": "bd58e2eb-551f-42d4-e9ee-f2e14b7245e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13240, 5)\n",
      "      id                                              tweet subtask_a  \\\n",
      "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
      "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
      "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
      "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
      "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
      "\n",
      "  subtask_b subtask_c  \n",
      "0       UNT       NaN  \n",
      "1       TIN       IND  \n",
      "2       NaN       NaN  \n",
      "3       UNT       NaN  \n",
      "4       NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./offenseval-training-v1.tsv\", delimiter=\"\\t\")\n",
    "print(train.shape)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "u8yrV9tCWJrT",
    "outputId": "744f24f1-2c93-49f8-9e47-14cc004b34ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           13240\n",
       "tweet        13240\n",
       "subtask_a    13240\n",
       "subtask_b     4400\n",
       "subtask_c     3876\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "af5bww85WJrW",
    "outputId": "a3856070-9669-4e22-c6ce-a8592af9e237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of offensive 4400\n",
      "Number of inoffensive 8840\n"
     ]
    }
   ],
   "source": [
    "total = train['id'].count().item()\n",
    "off_count = train[train['subtask_a'] == \"OFF\"]['id'].count()\n",
    "\n",
    "print(\"Number of offensive\", off_count)\n",
    "print(\"Number of inoffensive\", total - off_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K8qdnuP2C5Zb"
   },
   "source": [
    "## TASK A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxJeNqSbWJrZ"
   },
   "source": [
    "**The above shows that the training dataset is not very balanced (in offensive is about twice as much). How could this be addressed. Get more data? Augment offensive comments by adding neutral words to create more data or concat offensive and inoffensive comments to make new offensive comments?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkVNhZ3hWJra"
   },
   "outputs": [],
   "source": [
    "training_percent = 0.8\n",
    "training_size = int(training_percent * total)\n",
    "validation_size = total - training_size\n",
    "\n",
    "corpus = train['tweet'].to_numpy()\n",
    "labels = train['subtask_a'].to_numpy()\n",
    "labels[labels == 'OFF'] = 1\n",
    "labels[labels == 'NOT'] = 0\n",
    "\n",
    "labels = labels.astype(float)\n",
    "\n",
    "indices = list(range(total))\n",
    "np.random.shuffle(indices)\n",
    "training_sents = corpus[indices[:training_size]]\n",
    "training_labels = labels[indices[:training_size]]\n",
    "\n",
    "validation_sents = corpus[indices[training_size:]]\n",
    "validation_labels = labels[indices[training_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ji6AkNbLWJrf"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_tokenised_corpus(corpus):\n",
    "    \"\"\"\n",
    "    This assumes the corpus can be iterated through and\n",
    "    retains the order in which the sentences appeared in the corpus\n",
    "    \"\"\"\n",
    "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
    "    for sentence in corpus:\n",
    "        tokenized_sentence = []\n",
    "        for token in re.split(r'\\s', sentence.lower()): # simplest split is \n",
    "            if token:\n",
    "              # To avoid the empty string\n",
    "              tokenized_sentence.append(token)\n",
    "        tokenized_corpus.append(tokenized_sentence)\n",
    "    \n",
    "    return tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5NEltnwCkiD"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vec_training = vectorizer.fit_transform(training_sents)\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "vec_training = tf_transformer.fit_transform(vec_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "bld3qbEpCkiR",
    "outputId": "61488dff-4b46-4055-e5a1-2b8728139e0d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight={1.0: 2},\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None, class_weight={1.0: 2})\n",
    "\n",
    "clf.fit(vec_training, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3QbVqHdUCkio"
   },
   "outputs": [],
   "source": [
    "vec_valid = tf_transformer.transform(vectorizer.transform(validation_sents))\n",
    "predictions = clf.predict(vec_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "5pn-eu6JCkiw",
    "outputId": "dd037b0c-fa2d-4f17-b9b7-bc78e607c681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.88      0.80      1761\n",
      "         1.0       0.62      0.38      0.47       887\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      2648\n",
      "   macro avg       0.68      0.63      0.64      2648\n",
      "weighted avg       0.70      0.71      0.69      2648\n",
      "\n",
      "Accuracy: 0.7137462235649547\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(validation_labels, predictions))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9f0yiTlCki6"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "train_pos_sents = []\n",
    "train_pos_labels = []\n",
    "train_neg_sents = []\n",
    "train_neg_labels = []\n",
    "\n",
    "for sent, label in zip(training_sents, training_labels):\n",
    "    if TextBlob(sent).sentiment.polarity > -0.2:\n",
    "        train_pos_sents.append(sent)\n",
    "        train_pos_labels.append(label)\n",
    "    else:\n",
    "        train_neg_sents.append(sent)\n",
    "        train_neg_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wIJFw6tCkjB",
    "outputId": "bb07b64a-4088-4973-eb0b-1fea61b63d81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight={1.0: 2},\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None, class_weight={1.0: 2})\n",
    "clf1.fit(tf_transformer.transform(vectorizer.transform(train_pos_sents)), train_pos_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88Atez8_CkjG",
    "outputId": "e5c1aae3-7184-484c-c319-2188b63050eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight={0.0: 1.15},\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None, class_weight={0.0: 1.15})\n",
    "clf2.fit(tf_transformer.transform(vectorizer.transform(train_neg_sents)), train_neg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxwKzUPkCkjj"
   },
   "outputs": [],
   "source": [
    "valid_pos_sents = []\n",
    "valid_pos_labels = []\n",
    "valid_neg_sents = []\n",
    "valid_neg_labels = []\n",
    "\n",
    "for sent, label in zip(validation_sents, validation_labels):\n",
    "    if TextBlob(sent).sentiment.polarity > -0.2:\n",
    "        valid_pos_sents.append(sent)\n",
    "        valid_pos_labels.append(label)\n",
    "    else:\n",
    "        valid_neg_sents.append(sent)\n",
    "        valid_neg_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QSTPIMEJCkjp"
   },
   "outputs": [],
   "source": [
    "preds1 = clf1.predict(tf_transformer.transform(vectorizer.transform(valid_pos_sents)))\n",
    "preds2 = clf2.predict(tf_transformer.transform(vectorizer.transform(valid_neg_sents)))\n",
    "\n",
    "predictions_joined = np.concatenate((preds1, preds2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZqJFnueCkjx",
    "outputId": "08eff541-428f-4b8d-fa4d-84153022b9db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier for positive sentiments\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.97      0.85      1604\n",
      "         1.0       0.75      0.21      0.32       648\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      2252\n",
      "   macro avg       0.75      0.59      0.59      2252\n",
      "weighted avg       0.75      0.75      0.70      2252\n",
      "\n",
      "Accuracy: 0.7517761989342806\n",
      "\n",
      "Classifier for negative sentiments\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.79      0.67       153\n",
      "         1.0       0.83      0.64      0.72       243\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       396\n",
      "   macro avg       0.71      0.72      0.70       396\n",
      "weighted avg       0.73      0.70      0.70       396\n",
      "\n",
      "Accuracy: 0.6994949494949495\n",
      "\n",
      "Overall classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.87      0.75      1757\n",
      "         1.0       0.36      0.15      0.21       891\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      2648\n",
      "   macro avg       0.51      0.51      0.48      2648\n",
      "weighted avg       0.56      0.62      0.57      2648\n",
      "\n",
      "Accuracy: 0.6238670694864048\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier for positive sentiments\")\n",
    "print(metrics.classification_report(valid_pos_labels, preds1))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(valid_pos_labels, preds1))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Classifier for negative sentiments\")\n",
    "print(metrics.classification_report(valid_neg_labels, preds2))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(valid_neg_labels, preds2))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Overall classifier\")\n",
    "print(metrics.classification_report(validation_labels, predictions_joined))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions_joined))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AIVC7KehDGU0"
   },
   "source": [
    "## TASK B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRM9EYtxDI6I"
   },
   "outputs": [],
   "source": [
    "total_b = train.count()['subtask_b'].item()\n",
    "training_percent = 0.8\n",
    "training_size = int(training_percent * total_b)\n",
    "validation_size = total_b - training_size\n",
    "\n",
    "train_b = train[train.subtask_a == 'OFF']\n",
    "corpus = train_b['tweet'].to_numpy()\n",
    "labels = train_b['subtask_b'].to_numpy()\n",
    "labels[labels == 'TIN'] = 0\n",
    "labels[labels == 'UNT'] = 1\n",
    "labels = labels.astype(float)\n",
    "\n",
    "indices = list(range(total_b))\n",
    "np.random.shuffle(indices)\n",
    "training_sents = corpus[indices[:training_size]]\n",
    "training_labels = labels[indices[:training_size]]\n",
    "\n",
    "validation_sents = corpus[indices[training_size:]]\n",
    "validation_labels = labels[indices[training_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBZsUuEdHrYT"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vec_training = vectorizer.fit_transform(training_sents)\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "vec_training = tf_transformer.fit_transform(vec_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "qK9oyn2XHstx",
    "outputId": "95d7c2ba-9bf2-4675-ce57-f17d08731b9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight={1.0: 6.8},\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None, class_weight={1.0: 6.8})\n",
    "\n",
    "clf.fit(vec_training, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "faReJkFpH1nV"
   },
   "outputs": [],
   "source": [
    "vec_valid = tf_transformer.transform(vectorizer.transform(validation_sents))\n",
    "predictions = clf.predict(vec_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "6JeaeTjOH9E7",
    "outputId": "b8d2d329-51ec-46a4-d6e4-029cef61c944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[638 135]\n",
      " [ 65  42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.83      0.86       773\n",
      "         1.0       0.24      0.39      0.30       107\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       880\n",
      "   macro avg       0.57      0.61      0.58       880\n",
      "weighted avg       0.83      0.77      0.80       880\n",
      "\n",
      "Accuracy: 0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(validation_labels, predictions))\n",
    "print(metrics.classification_report(validation_labels, predictions))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-xcBWhU-23D"
   },
   "source": [
    "## TASK C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "ErRboMty-626",
    "outputId": "adfff039-9441-4bfd-b98b-d30cc5dc28f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset 3876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "total_c = train.count()['subtask_c'].item()\n",
    "training_percent = 0.8\n",
    "training_size = int(training_percent * total_c)\n",
    "validation_size = total_c - training_size\n",
    "\n",
    "train_c = train[train.subtask_a == 'OFF'][train.subtask_b == 'TIN']\n",
    "print(\"Size of dataset\", len(train_c))\n",
    "corpus = train_c['tweet'].to_numpy()\n",
    "labels = train_c['subtask_c'].to_numpy()\n",
    "labels[labels == 'IND'] = 0\n",
    "labels[labels == 'GRP'] = 1\n",
    "labels[labels == 'OTH'] = 2\n",
    "labels = labels.astype(float)\n",
    "\n",
    "indices = list(range(total_c))\n",
    "np.random.shuffle(indices)\n",
    "training_sents = corpus[indices[:training_size]]\n",
    "training_labels = labels[indices[:training_size]]\n",
    "\n",
    "validation_sents = corpus[indices[training_size:]]\n",
    "validation_labels = labels[indices[training_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Oh_HImFrAQlc",
    "outputId": "6a2120a1-77ee-456f-8dbe-c2c9ee106f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3100, 8154)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vec_training = vectorizer.fit_transform(training_sents)\n",
    "\n",
    "print(vec_training.shape)\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "vec_training = tf_transformer.fit_transform(vec_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "BulnlSp8_Wpt",
    "outputId": "815d75ee-e324-466c-dce4-94a520a2b15d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False,\n",
       "       class_weight={0: 1.6, 1: 3.7, 2: 8.4}, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
       "       random_state=42, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None, class_weight={0:1.6, 1:3.7, 2:8.4})\n",
    "\n",
    "clf.fit(vec_training, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qui5ITnTAiD7"
   },
   "outputs": [],
   "source": [
    "vec_valid = tf_transformer.transform(vectorizer.transform(validation_sents))\n",
    "predictions = clf.predict(vec_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "stttDsG4A1qK",
    "outputId": "a98e1f51-9f9e-454d-b5c1-61d25666865d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[399  58  21]\n",
      " [ 91 117  15]\n",
      " [ 50  10  15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.83      0.78       478\n",
      "         1.0       0.63      0.52      0.57       223\n",
      "         2.0       0.29      0.20      0.24        75\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       776\n",
      "   macro avg       0.56      0.52      0.53       776\n",
      "weighted avg       0.67      0.68      0.67       776\n",
      "\n",
      "Accuracy: 0.6842783505154639\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(validation_labels, predictions))\n",
    "print(metrics.classification_report(validation_labels, predictions))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWV6UsjkA4Dc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "NLP_CW.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
