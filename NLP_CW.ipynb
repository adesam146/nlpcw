{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_CW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "xGMVF5KTg-He",
        "t9Zt3py7E1ep",
        "SClCUJp08-zn",
        "u7glEGKc-rNE"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adesam146/nlpcw/blob/rest_of_tasks/NLP_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_i_qSkEMxlkg"
      },
      "cell_type": "markdown",
      "source": [
        "## Check GPU memory"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5-XwNX-831V6",
        "outputId": "31c35359-a798-4dc0-b89b-ca253aaa0849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "cell_type": "code",
      "source": [
        "#Check GPU Memory allocation\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NOXcwqriwFsu",
        "outputId": "1ffa4302-394e-4be6-843f-d19b4c0009d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.9 GB  | Proc size: 143.9 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ecWOCoFgxS_j",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#run this if GPU utilization is not 0%\n",
        "# !kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wTfeo8tcxhwC"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ePuqIHSPf554",
        "outputId": "4829b253-e588-48a1-d61d-b2e932bced25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1180
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U spacy ftfy torchtext\n",
        "!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (2.0.18)\n",
            "Requirement already up-to-date: ftfy in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (5.5.1)\n",
            "Collecting torchtext\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/bc/b28b9efb4653c03e597ed207264eea45862b5260f48e9f010b5068d64db1/torchtext-0.3.1-py3-none-any.whl (62kB)\n",
            "Requirement already satisfied, skipping upgrade: regex==2018.01.10 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (2018.1.10)\n",
            "Requirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3,>=0.2 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (0.2.9)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: ujson>=1.35 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (1.35)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: thinc<6.13.0,>=6.12.1 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (1.16.1)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from ftfy) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: torch in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from torchtext) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from torchtext) (4.31.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.11.29)\n",
            "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
            "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six<2.0.0,>=1.10.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<0.6.0,>=0.5.6 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
            "Installing collected packages: torchtext\n",
            "Successfully installed torchtext-0.3.1\n",
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (2.0.0)\n",
            "\n",
            "    Linking successful\n",
            "    C:\\projects\\nlpcw\\myvenv\\lib\\site-packages\\en_core_web_sm -->\n",
            "    C:\\projects\\nlpcw\\myvenv\\lib\\site-packages\\spacy\\data\\en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "You do not have sufficient privilege to perform this operation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Srpq8hYt4whg",
        "outputId": "188589a1-7e7d-47e7-8c7e-4eeda48d8c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import sampler\n",
        "import spacy\n",
        "import torchvision.datasets as dset\n",
        "from torchtext import data\n",
        "from torchtext import datasets as nlp_dset\n",
        "import random\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "nlp_spaCy = spacy.load('en')\n",
        "\n",
        "GPU = True\n",
        "device_idx = 0\n",
        "if GPU and torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:\"+str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "#Fix all seeds\n",
        "SEED = 0\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qtiwRhtm3s87",
        "outputId": "23853e89-df09-4a87-81ef-a35dfda609dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Load datafiles from own google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_fp = \"\"\"/content/drive/My Drive/colab_data/offenseval-training-v1.tsv\"\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xGMVF5KTg-He"
      },
      "cell_type": "markdown",
      "source": [
        "## ELMO"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wxCJbS2h4jfG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torchvision torch allennlp\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8iTnEx03ZO2q",
        "outputId": "769b64d4-6d52-4e64-b892-5fe0b5d784fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#Use pretrained ELMO weights. \n",
        "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "\n",
        "elmo = Elmo(options_file, weight_file, 2, dropout=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 336/336 [00:00<00:00, 55516.49B/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374434792/374434792 [00:21<00:00, 17177971.67B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3LeaTI5U7x5N",
        "outputId": "f2496a58-adc5-4b05-d7a5-6ad18dd36f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "#Elmo test\n",
        "sentences = [['First', 'sentence', '.'], ['Another', '.'], \n",
        "             [\"Oh\", \"here\", \"we\", \"Go\", \"now\", \"you\", \"fool\", \".\"], \n",
        "             [\"meaninglesswordnotinvocab\"]]\n",
        "             \n",
        "character_ids = batch_to_ids(sentences)\n",
        "\n",
        "embeddings = elmo(character_ids)\n",
        "\n",
        "print(character_ids.shape)\n",
        "embed = embeddings[\"elmo_representations\"]\n",
        "print(len(embed))\n",
        "print(embed[0].shape)\n",
        "print(embed[1].shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 8, 50])\n",
            "2\n",
            "torch.Size([4, 8, 1024])\n",
            "torch.Size([4, 8, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4N-meDamEjF7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ELMO takes a list of parsed sentences as an input\n",
        "# It generates an embedding of length 1024 per word\n",
        "# We then need to find a good method of combining the word vecs to create \n",
        "# a sentence embedding (this article is good: https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a). \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "t9Zt3py7E1ep"
      },
      "cell_type": "markdown",
      "source": [
        "## Import and preprocess Data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z9qQiPkQ3cna",
        "outputId": "f44b5c43-aa55-4de6-ed67-b5ac0e0250ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "cell_type": "code",
      "source": [
        "#ONLY RUN THIS CELL IF YOU WANT TO DOWNSAMPLE DATA - everything should work w/o this cell\n",
        "\n",
        "#Select a subset of the data so that the classes are equally balanced\n",
        "#Use downsampling for now. \n",
        "\n",
        "num_NOT = 8840\n",
        "num_OFF = 4400\n",
        "# Separate majority and minority classes\n",
        "df_majority = train_df[train_df[\"subtask_a\"] == 'NOT']\n",
        "df_minority = train_df[train_df[\"subtask_a\"] == 'OFF']\n",
        "\n",
        "# Downsample majority class\n",
        "df_majority_downsampled = resample(df_majority, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=num_OFF,     # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        " \n",
        "# Combine minority class with downsampled majority class\n",
        "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        " \n",
        "# Display new class counts\n",
        "print(df_downsampled.subtask_a.value_counts())\n",
        "\n",
        "df_downsampled = df_downsampled.sample(frac=1) #shuffle df\n",
        "\n",
        "\n",
        "train_df = df_downsampled"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e721546a3980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_OFF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Separate majority and minority classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_majority\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subtask_a\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NOT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf_minority\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subtask_a\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'OFF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aMY0mUyknLDu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tweet_preprocess(tweet_text):\n",
        "  \"\"\"Add tweet specific preprocessing steps here\"\"\"\n",
        "  \n",
        "  #Remove 'USER' (but leave '@')\n",
        "  tweet_text = tweet_text.replace(\"@USER\", \"@\") \n",
        "  \n",
        "  return tweet_text\n",
        "\n",
        "def convert_labels_A(labels):\n",
        "    \"\"\"Preproceses and return labels\"\"\"\n",
        "\n",
        "    final_labels = []\n",
        "    for label in labels:\n",
        "        assert label == \"OFF\" or label == \"NOT\", \"Label should not be: {}\".format(label)\n",
        "    \n",
        "        if label == \"OFF\":\n",
        "            res = 1\n",
        "        elif label == \"NOT\":\n",
        "            res = 0        \n",
        "        label = torch.tensor([res])\n",
        "        final_labels.append(label)\n",
        "    return final_labels\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "n1TwMNFOKRSm"
      },
      "cell_type": "markdown",
      "source": [
        "## GloVe"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6NVQcb0MKUCh",
        "outputId": "f104c245-3896-4e2a-a15e-5858e579c007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "# Use two GloVe trained on two different corpuses for comparison:\n",
        "    # Glove.6B\n",
        "    # glove.twitter.27B\n",
        "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip glove.twitter.27B.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-24 17:33:18--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
            "--2019-02-24 17:33:18--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: â€˜glove.twitter.27B.zipâ€™\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  17.6MB/s    in 88s     \n",
            "\n",
            "2019-02-24 17:34:47 (16.5 MB/s) - â€˜glove.twitter.27B.zipâ€™ saved [1520408563/1520408563]\n",
            "\n",
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bpNZ2KEwMOyM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenizer(text): # create a tokenizer function for gloVe\n",
        "    res = [tok.text for tok in nlp_spaCy.tokenizer(text)]\n",
        "    return res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WO69uqM3LtBS",
        "outputId": "c4aa414a-7032-4385-9105-e2aacdce05a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a',LABEL),\n",
        "               ('subtask_b',LABEL),\n",
        "               ('subtask_c',LABEL)]\n",
        "\n",
        "\n",
        "train = data.TabularDataset(train_fp, format='TSV', fields = \n",
        "                            data_fields, skip_header=True, filter_pred=None)\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d') #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
        "\n",
        "LABEL.build_vocab(train.subtask_a)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)\n",
        "\n",
        "# For retrieving tweet text later on\n",
        "train_df = pd.read_csv(\"offenseval-training-v1.tsv\", delimiter=\"\\t\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 10592\n",
            "Validation size: 2648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KkGDZeI-rccB",
        "outputId": "6ca23320-0900-4eb4-a22b-5a16c28d83c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "cell_type": "code",
      "source": [
        "print('first tweet', train[0].tweet)\n",
        "print('first label', train[0].subtask_a)\n",
        "print(\"first tweet id:\", train[0].id)\n",
        "# print(TEXT.vocab.stoi) # word to index\n",
        "# print(LABEL.vocab.stoi) # word to index\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first tweet ['@user', 'really', 'another', 'one', 'holy', 'crap', 'wow', 'all', 'brought', 'to', 'you', 'by', 'the', 'liberals', '.']\n",
            "first label OFF\n",
            "first tweet id: 49396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-10f0bedf690c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'first label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtask_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first tweet id:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(TEXT.vocab.stoi) # word to index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(LABEL.vocab.stoi) # word to index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not callable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q9_NCwh3C1Z4",
        "outputId": "c3773c97-f247-4df4-ed4e-209940dd154a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        }
      },
      "cell_type": "code",
      "source": [
        "#check loader\n",
        "for idx, batch in enumerate(train_iterator):\n",
        "    inputs, labels = batch.tweet, batch.subtask_a\n",
        "    print(inputs.shape)\n",
        "    print(labels.shape)\n",
        "    print(len(train_iterator))\n",
        "    break\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-ae464dc26897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtask_a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[1;32m    200\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "k4UHz12y6L7m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "\n",
        "PRINT_EVERY = 50\n",
        "\n",
        "def check_accuracy(task_header, loader, model, conf=False):\n",
        "    \"\"\"\n",
        "    Note at the moment this function assumes the batch size is equal to the \n",
        "    number of data in the loader when calculating the confusion matrix\n",
        "    \"\"\"\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    TP, TN, FP, FN = 0, 0, 0, 0\n",
        "    \n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(loader):\n",
        "            x, y = batch.tweet, getattr(batch, task_header)\n",
        "            y = y.view(-1, 1)\n",
        "                \n",
        "            x = x.to(device=device, dtype=torch.long)  # move to  GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            if task_header == 'subtask_c':\n",
        "              pred_prob = F.softmax(model(x))[:, y]\n",
        "            else:\n",
        "              pred_prob = torch.sigmoid(model(x))\n",
        "            pred_1 = (pred_prob > 0.5).type(torch.long)\n",
        "            num_correct += (pred_1 == y).sum()\n",
        "            num_samples += pred_prob.size(0)\n",
        "            \n",
        "            # move to CPU to prevent memory overflow and calculate metrics\n",
        "            x = x.to(device=\"cpu\", dtype=torch.long)\n",
        "            y = y.to(device=\"cpu\", dtype=torch.long).numpy()\n",
        "            pred_1 = pred_1.to(device=\"cpu\", dtype=torch.long).numpy()\n",
        "            \n",
        "            if conf:\n",
        "                TP, FP, FN, TN = metrics.confusion_matrix(y, pred_1).ravel()\n",
        "            \n",
        "            \n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "        if conf:\n",
        "            print(\"TP = {}, FN = {}, TN = {}, FN = {}\".format(TP, FP, TN, FN))\n",
        "            print(metrics.classification_report(y, pred_1))\n",
        "            \n",
        "def check_loss(task_header, loader, model, loss_fn):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    loss = 0\n",
        "    for idx, batch in enumerate(loader):\n",
        "      x, y = batch.tweet, getattr(batch, task_header)\n",
        "      y = y.view(-1, 1)\n",
        "      \n",
        "      x = x.to(device=device, dtype=torch.long) \n",
        "      y = y.to(device=device, dtype=torch.long)\n",
        "      \n",
        "      output = model(x)\n",
        "      \n",
        "      y = y.type(torch.float)\n",
        "      loss += loss_fn(output, y).item()\n",
        "      \n",
        "    return loss/len(loader)\n",
        "      \n",
        "\n",
        "def train_helper(task_header, model, optimizer, epochs=1, loss_fn = F.binary_cross_entropy_with_logits, \n",
        "               print_every=PRINT_EVERY, train_loader=train_iterator, \n",
        "               valid_loader=valid_iterator):\n",
        "    \"\"\"\n",
        "    Train a model\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to GPU\n",
        "    \n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "    try:\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:\", epoch)\n",
        "            total_loss = 0\n",
        "            for batch_idx, batch in enumerate(train_loader):\n",
        "\n",
        "                model.train()  # put model to training mode\n",
        "                \n",
        "                #Eventually make this more generic so it works for all parts (a, b, c):\n",
        "                inputs, targets = batch.tweet, getattr(batch, task_header)\n",
        "                \n",
        "                x = inputs.to(device=device, dtype=torch.long)  # move to device, e.g. GPU\n",
        "                y = targets.to(device=device, dtype=torch.float) #this should be a float cross entropy\n",
        "                #x = inputs\n",
        "                #y = targets\n",
        "                logits = model(x)\n",
        "                y = y.type(torch.float)\n",
        "                loss = loss_fn(logits.view((-1,)), y)\n",
        "                # Zero out all of the gradients for the variables which the optimizer\n",
        "                # will update.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # This is the backwards pass: compute the gradient of the loss with\n",
        "                # respect to each  parameter of the model.\n",
        "                loss.backward()\n",
        "\n",
        "                # Actually update the parameters of the model using the gradients\n",
        "                # computed by the backwards pass.\n",
        "                optimizer.step()\n",
        "\n",
        "                x = x.to(device=\"cpu\", dtype=torch.long)  # move to CPU to prevent memory overflow\n",
        "                y = y.to(device=\"cpu\", dtype=torch.long)\n",
        "\n",
        "                total_loss += loss.detach().item()\n",
        "                \n",
        "                if batch_idx % print_every == 0:\n",
        "                    print('Iteration %d, loss = %.4f' % (batch_idx, loss.item()))\n",
        "            \n",
        "            training_losses.append(total_loss/len(train_iterator))\n",
        "            print()\n",
        "            print(\"Validation Accuracy:\")\n",
        "            check_accuracy(task_header, valid_loader, model, conf=True)\n",
        "            valid_loss = check_loss(task_header, valid_loader, model, loss_fn)\n",
        "            validation_losses.append(valid_loss)\n",
        "            print()\n",
        "        return training_losses, validation_losses\n",
        "    except Exception as e:\n",
        "        #Attempt to prevent GPU memory overflow by transferring model back to cpu\n",
        "        #model = model.to(device=\"cpu\")\n",
        "        raise e    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeisH53s6cfR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#embedding (lookup layer) layer\n",
        "class SimpleClassifierGloVe(nn.Module):\n",
        "    \"\"\"Glove w. 2d conv\"\"\"\n",
        "    \n",
        "    def __init__(self, vocab, embedding_dim, window_size, out_channels, dropout, num_classes=2):\n",
        "        \n",
        "        super(SimpleClassifierGloVe, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.vocab = vocab\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "        self.embedding.weight.data.copy_(vocab.vectors) # copies pre-trained word vectors\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(window_size, embedding_dim))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(out_channels, 1 if num_classes == 2 else num_classes)\n",
        "\n",
        "        #Kaming normalization\n",
        "        nn.init.kaiming_normal_(self.conv.weight)\n",
        "        nn.init.kaiming_normal_(self.fc.weight)\n",
        "\n",
        "        \n",
        "        \n",
        "    def forward(self, x, ):\n",
        "        \n",
        "        embedded = self.embedding(x)\n",
        "                \n",
        "        #(batch size, max sent length, embedding dim)\n",
        "        \n",
        "        #images have 3 RGB channels \n",
        "        #for the text we add 1 channel\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #(batch size, 1, max sent length, embedding dim)\n",
        "        \n",
        "        feature_maps =  F.relu(self.conv(embedded).squeeze(3))\n",
        "        # (batch size, out_channels, max sent length - window size +1, 1)\n",
        "        # -> (batch size, out_channels, max sent length - window size +1)\n",
        "           \n",
        "        #the max pooling layer\n",
        "        pooled = F.max_pool1d(feature_maps, feature_maps.shape[2]).squeeze(2)\n",
        "        # (batch size, out_channels)      \n",
        "        \n",
        "        # Do batch normalize pooled then at sentiment\n",
        "        \n",
        "        return self.fc( self.dropout(pooled))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "X9LseL5F9n7P",
        "outputId": "7cbd2669-1294-4ee5-c9f8-aeba597e605a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5729
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab, embedding_dim, window_size, out_channels, dropout)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_a', model, optimizer, loss_fn = loss_fn, epochs = 20)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 1.0039\n",
            "Iteration 50, loss = 0.7888\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1412 / 2118 correct (66.67)\n",
            "TP = 1377, FN = 18, TN = 35, FN = 688\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.99      0.80      1395\n",
            "           1       0.66      0.05      0.09       723\n",
            "\n",
            "   micro avg       0.67      0.67      0.67      2118\n",
            "   macro avg       0.66      0.52      0.44      2118\n",
            "weighted avg       0.66      0.67      0.56      2118\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 0.8521\n",
            "Iteration 50, loss = 0.8099\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1448 / 2118 correct (68.37)\n",
            "TP = 1368, FN = 27, TN = 80, FN = 643\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.98      0.80      1395\n",
            "           1       0.75      0.11      0.19       723\n",
            "\n",
            "   micro avg       0.68      0.68      0.68      2118\n",
            "   macro avg       0.71      0.55      0.50      2118\n",
            "weighted avg       0.70      0.68      0.59      2118\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 0.6326\n",
            "Iteration 50, loss = 0.6276\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1486 / 2118 correct (70.16)\n",
            "TP = 1341, FN = 54, TN = 145, FN = 578\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.96      0.81      1395\n",
            "           1       0.73      0.20      0.31       723\n",
            "\n",
            "   micro avg       0.70      0.70      0.70      2118\n",
            "   macro avg       0.71      0.58      0.56      2118\n",
            "weighted avg       0.71      0.70      0.64      2118\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.6160\n",
            "Iteration 50, loss = 0.5473\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1521 / 2118 correct (71.81)\n",
            "TP = 1311, FN = 84, TN = 210, FN = 513\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.94      0.81      1395\n",
            "           1       0.71      0.29      0.41       723\n",
            "\n",
            "   micro avg       0.72      0.72      0.72      2118\n",
            "   macro avg       0.72      0.62      0.61      2118\n",
            "weighted avg       0.72      0.72      0.68      2118\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.5984\n",
            "Iteration 50, loss = 0.6122\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1516 / 2118 correct (71.58)\n",
            "TP = 1333, FN = 62, TN = 183, FN = 540\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.96      0.82      1395\n",
            "           1       0.75      0.25      0.38       723\n",
            "\n",
            "   micro avg       0.72      0.72      0.72      2118\n",
            "   macro avg       0.73      0.60      0.60      2118\n",
            "weighted avg       0.72      0.72      0.67      2118\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.5275\n",
            "Iteration 50, loss = 0.4854\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1559 / 2118 correct (73.61)\n",
            "TP = 1296, FN = 99, TN = 263, FN = 460\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.93      0.82      1395\n",
            "           1       0.73      0.36      0.48       723\n",
            "\n",
            "   micro avg       0.74      0.74      0.74      2118\n",
            "   macro avg       0.73      0.65      0.65      2118\n",
            "weighted avg       0.73      0.74      0.71      2118\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.4735\n",
            "Iteration 50, loss = 0.4386\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1598 / 2118 correct (75.45)\n",
            "TP = 1266, FN = 129, TN = 332, FN = 391\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.91      0.83      1395\n",
            "           1       0.72      0.46      0.56       723\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2118\n",
            "   macro avg       0.74      0.68      0.70      2118\n",
            "weighted avg       0.75      0.75      0.74      2118\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.4096\n",
            "Iteration 50, loss = 0.4268\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1615 / 2118 correct (76.25)\n",
            "TP = 1271, FN = 124, TN = 344, FN = 379\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.91      0.83      1395\n",
            "           1       0.74      0.48      0.58       723\n",
            "\n",
            "   micro avg       0.76      0.76      0.76      2118\n",
            "   macro avg       0.75      0.69      0.71      2118\n",
            "weighted avg       0.76      0.76      0.75      2118\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.3765\n",
            "Iteration 50, loss = 0.4544\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1615 / 2118 correct (76.25)\n",
            "TP = 1270, FN = 125, TN = 345, FN = 378\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.91      0.83      1395\n",
            "           1       0.73      0.48      0.58       723\n",
            "\n",
            "   micro avg       0.76      0.76      0.76      2118\n",
            "   macro avg       0.75      0.69      0.71      2118\n",
            "weighted avg       0.76      0.76      0.75      2118\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.4231\n",
            "Iteration 50, loss = 0.4051\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1621 / 2118 correct (76.53)\n",
            "TP = 1261, FN = 134, TN = 360, FN = 363\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.90      0.84      1395\n",
            "           1       0.73      0.50      0.59       723\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2118\n",
            "   macro avg       0.75      0.70      0.71      2118\n",
            "weighted avg       0.76      0.77      0.75      2118\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.3762\n",
            "Iteration 50, loss = 0.3322\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1627 / 2118 correct (76.82)\n",
            "TP = 1268, FN = 127, TN = 359, FN = 364\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.91      0.84      1395\n",
            "           1       0.74      0.50      0.59       723\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2118\n",
            "   macro avg       0.76      0.70      0.72      2118\n",
            "weighted avg       0.76      0.77      0.75      2118\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.2992\n",
            "Iteration 50, loss = 0.4294\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1639 / 2118 correct (77.38)\n",
            "TP = 1256, FN = 139, TN = 383, FN = 340\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.90      0.84      1395\n",
            "           1       0.73      0.53      0.62       723\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2118\n",
            "   macro avg       0.76      0.72      0.73      2118\n",
            "weighted avg       0.77      0.77      0.76      2118\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.4074\n",
            "Iteration 50, loss = 0.3308\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1636 / 2118 correct (77.24)\n",
            "TP = 1259, FN = 136, TN = 377, FN = 346\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.90      0.84      1395\n",
            "           1       0.73      0.52      0.61       723\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2118\n",
            "   macro avg       0.76      0.71      0.72      2118\n",
            "weighted avg       0.77      0.77      0.76      2118\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.3284\n",
            "Iteration 50, loss = 0.3754\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1647 / 2118 correct (77.76)\n",
            "TP = 1241, FN = 154, TN = 406, FN = 317\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.89      0.84      1395\n",
            "           1       0.72      0.56      0.63       723\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2118\n",
            "   macro avg       0.76      0.73      0.74      2118\n",
            "weighted avg       0.77      0.78      0.77      2118\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.3266\n",
            "Iteration 50, loss = 0.3804\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1643 / 2118 correct (77.57)\n",
            "TP = 1246, FN = 149, TN = 397, FN = 326\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84      1395\n",
            "           1       0.73      0.55      0.63       723\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2118\n",
            "   macro avg       0.76      0.72      0.73      2118\n",
            "weighted avg       0.77      0.78      0.77      2118\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.3300\n",
            "Iteration 50, loss = 0.2883\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1647 / 2118 correct (77.76)\n",
            "TP = 1243, FN = 152, TN = 404, FN = 319\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.89      0.84      1395\n",
            "           1       0.73      0.56      0.63       723\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2118\n",
            "   macro avg       0.76      0.72      0.74      2118\n",
            "weighted avg       0.77      0.78      0.77      2118\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.3321\n",
            "Iteration 50, loss = 0.3248\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1649 / 2118 correct (77.86)\n",
            "TP = 1246, FN = 149, TN = 403, FN = 320\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.89      0.84      1395\n",
            "           1       0.73      0.56      0.63       723\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2118\n",
            "   macro avg       0.76      0.73      0.74      2118\n",
            "weighted avg       0.77      0.78      0.77      2118\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.3405\n",
            "Iteration 50, loss = 0.3579\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1643 / 2118 correct (77.57)\n",
            "TP = 1232, FN = 163, TN = 411, FN = 312\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.84      1395\n",
            "           1       0.72      0.57      0.63       723\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2118\n",
            "   macro avg       0.76      0.73      0.74      2118\n",
            "weighted avg       0.77      0.78      0.77      2118\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.2853\n",
            "Iteration 50, loss = 0.2424\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1644 / 2118 correct (77.62)\n",
            "TP = 1243, FN = 152, TN = 401, FN = 322\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84      1395\n",
            "           1       0.73      0.55      0.63       723\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2118\n",
            "   macro avg       0.76      0.72      0.73      2118\n",
            "weighted avg       0.77      0.78      0.77      2118\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.1877\n",
            "Iteration 50, loss = 0.2638\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1640 / 2118 correct (77.43)\n",
            "TP = 1240, FN = 155, TN = 400, FN = 323\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84      1395\n",
            "           1       0.72      0.55      0.63       723\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2118\n",
            "   macro avg       0.76      0.72      0.73      2118\n",
            "weighted avg       0.77      0.77      0.77      2118\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_q8EEjwwLf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "0c4f7105-ff5e-49af-d48e-0930a38fcfb1"
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "VFiG4aRQPpN5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task B"
      ]
    },
    {
      "metadata": {
        "id": "2YbsX0DyP1B0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d9f8e7ff-ce02-4973-bff8-c75f19a891d3"
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a', LABEL),\n",
        "               ('subtask_b',LABEL)\n",
        "              ]\n",
        "\n",
        "train = data.TabularDataset(train_fp, format='TSV', fields = \n",
        "                            data_fields, skip_header=True, filter_pred=lambda d: d.subtask_a == 'OFF')\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d') #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
        "\n",
        "LABEL.build_vocab(train.subtask_b)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "print(LABEL.vocab.stoi)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 3520\n",
            "Validation size: 880\n",
            "defaultdict(<function _default_unk_index at 0x7f11cf91ebf8>, {'TIN': 0, 'UNT': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uww_bdubSnf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5446
        },
        "outputId": "96fe74a5-5907-436d-c95b-9d3b208f9ee3"
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab, embedding_dim, window_size, out_channels, dropout)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_b', model, optimizer, loss_fn = loss_fn, epochs = 20)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 0.8386\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "TP = 768, FN = 0, TN = 0, FN = 112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 0.3424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "TP = 768, FN = 0, TN = 0, FN = 112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 0.5065\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "TP = 768, FN = 0, TN = 0, FN = 112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.5289\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "TP = 768, FN = 0, TN = 0, FN = 112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.5133\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "TP = 768, FN = 0, TN = 0, FN = 112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.4176\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "TP = 768, FN = 0, TN = 0, FN = 112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.2614\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 768, FN = 0, TN = 1, FN = 111\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.94      0.50      0.48       880\n",
            "weighted avg       0.89      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.4427\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.3749\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.2159\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.2693\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.3732\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.3235\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.3594\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.3735\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.2830\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.2369\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.2017\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.2593\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.2112\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "TP = 767, FN = 1, TN = 2, FN = 110\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AiLub0TBVF_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "7031356f-2986-48fa-c13e-2671b3402b19"
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oD5ziT7HVHHw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}