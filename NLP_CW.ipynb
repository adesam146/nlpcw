{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_CW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "xGMVF5KTg-He",
        "t9Zt3py7E1ep",
        "SClCUJp08-zn",
        "u7glEGKc-rNE"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adesam146/nlpcw/blob/rest_of_tasks/NLP_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_i_qSkEMxlkg"
      },
      "cell_type": "markdown",
      "source": [
        "## Check GPU memory"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5-XwNX-831V6",
        "outputId": "31c35359-a798-4dc0-b89b-ca253aaa0849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "cell_type": "code",
      "source": [
        "#Check GPU Memory allocation\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NOXcwqriwFsu",
        "outputId": "1ffa4302-394e-4be6-843f-d19b4c0009d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.9 GB  | Proc size: 143.9 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ecWOCoFgxS_j",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#run this if GPU utilization is not 0%\n",
        "# !kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wTfeo8tcxhwC"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ePuqIHSPf554",
        "outputId": "c1c194ea-d492-4ea6-b477-0add568029c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U spacy ftfy torchtext\n",
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
            "Requirement already up-to-date: ftfy in /usr/local/lib/python3.6/dist-packages (5.5.1)\n",
            "Requirement already up-to-date: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.16.1)\n",
            "Requirement already satisfied, skipping upgrade: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
            "Requirement already satisfied, skipping upgrade: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.9)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.0.1.post2)\n",
            "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
            "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
            "Requirement already satisfied, skipping upgrade: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.11.29)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Srpq8hYt4whg",
        "outputId": "d48b6c47-aa55-4463-cf8f-06b3ebb3f99a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import sampler\n",
        "import spacy\n",
        "from torchtext import data\n",
        "from torchtext import datasets as nlp_dset\n",
        "import random\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "nlp_spaCy = spacy.load('en')\n",
        "\n",
        "GPU = True\n",
        "device_idx = 0\n",
        "if GPU:\n",
        "    device = torch.device(\"cuda:\"+str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "#Fix all seeds\n",
        "SEED = 0\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qtiwRhtm3s87",
        "outputId": "721b1225-b243-400c-96a8-57c1c67ca0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Load datafiles from own google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_fp = \"\"\"/content/drive/My Drive/colab_data/offenseval-training-v1.tsv\"\"\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xGMVF5KTg-He"
      },
      "cell_type": "markdown",
      "source": [
        "## ELMO"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wxCJbS2h4jfG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torchvision torch allennlp\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8iTnEx03ZO2q",
        "outputId": "769b64d4-6d52-4e64-b892-5fe0b5d784fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#Use pretrained ELMO weights. \n",
        "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "\n",
        "elmo = Elmo(options_file, weight_file, 2, dropout=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 336/336 [00:00<00:00, 55516.49B/s]\n",
            "100%|██████████| 374434792/374434792 [00:21<00:00, 17177971.67B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3LeaTI5U7x5N",
        "outputId": "f2496a58-adc5-4b05-d7a5-6ad18dd36f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "#Elmo test\n",
        "sentences = [['First', 'sentence', '.'], ['Another', '.'], \n",
        "             [\"Oh\", \"here\", \"we\", \"Go\", \"now\", \"you\", \"fool\", \".\"], \n",
        "             [\"meaninglesswordnotinvocab\"]]\n",
        "             \n",
        "character_ids = batch_to_ids(sentences)\n",
        "\n",
        "embeddings = elmo(character_ids)\n",
        "\n",
        "print(character_ids.shape)\n",
        "embed = embeddings[\"elmo_representations\"]\n",
        "print(len(embed))\n",
        "print(embed[0].shape)\n",
        "print(embed[1].shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 8, 50])\n",
            "2\n",
            "torch.Size([4, 8, 1024])\n",
            "torch.Size([4, 8, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4N-meDamEjF7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ELMO takes a list of parsed sentences as an input\n",
        "# It generates an embedding of length 1024 per word\n",
        "# We then need to find a good method of combining the word vecs to create \n",
        "# a sentence embedding (this article is good: https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a). \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "t9Zt3py7E1ep"
      },
      "cell_type": "markdown",
      "source": [
        "## Import and preprocess Data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z9qQiPkQ3cna",
        "outputId": "f44b5c43-aa55-4de6-ed67-b5ac0e0250ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "cell_type": "code",
      "source": [
        "#ONLY RUN THIS CELL IF YOU WANT TO DOWNSAMPLE DATA - everything should work w/o this cell\n",
        "\n",
        "#Select a subset of the data so that the classes are equally balanced\n",
        "#Use downsampling for now. \n",
        "\n",
        "num_NOT = 8840\n",
        "num_OFF = 4400\n",
        "# Separate majority and minority classes\n",
        "df_majority = train_df[train_df[\"subtask_a\"] == 'NOT']\n",
        "df_minority = train_df[train_df[\"subtask_a\"] == 'OFF']\n",
        "\n",
        "# Downsample majority class\n",
        "df_majority_downsampled = resample(df_majority, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=num_OFF,     # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        " \n",
        "# Combine minority class with downsampled majority class\n",
        "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        " \n",
        "# Display new class counts\n",
        "print(df_downsampled.subtask_a.value_counts())\n",
        "\n",
        "df_downsampled = df_downsampled.sample(frac=1) #shuffle df\n",
        "\n",
        "\n",
        "train_df = df_downsampled"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e721546a3980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_OFF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Separate majority and minority classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_majority\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subtask_a\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NOT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf_minority\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subtask_a\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'OFF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aMY0mUyknLDu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tweet_preprocess(tweet_text):\n",
        "  \"\"\"Add tweet specific preprocessing steps here\"\"\"\n",
        "  \n",
        "  #Remove 'USER' (but leave '@')\n",
        "  tweet_text = tweet_text.replace(\"@USER\", \"@\") \n",
        "  \n",
        "  return tweet_text\n",
        "\n",
        "def convert_labels_A(labels):\n",
        "    \"\"\"Preproceses and return labels\"\"\"\n",
        "\n",
        "    final_labels = []\n",
        "    for label in labels:\n",
        "        assert label == \"OFF\" or label == \"NOT\", \"Label should not be: {}\".format(label)\n",
        "    \n",
        "        if label == \"OFF\":\n",
        "            res = 1\n",
        "        elif label == \"NOT\":\n",
        "            res = 0        \n",
        "        label = torch.tensor([res])\n",
        "        final_labels.append(label)\n",
        "    return final_labels\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "n1TwMNFOKRSm"
      },
      "cell_type": "markdown",
      "source": [
        "## Task A"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6NVQcb0MKUCh",
        "outputId": "4d681935-8d44-40ff-cc80-cfbca71a8763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "# Use two GloVe trained on two different corpuses for comparison:\n",
        "    # Glove.6B\n",
        "    # glove.twitter.27B\n",
        "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip glove.twitter.27B.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-25 09:40:33--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
            "--2019-02-25 09:40:33--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  10.7MB/s    in 4m 44s  \n",
            "\n",
            "2019-02-25 09:45:18 (5.11 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n",
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bpNZ2KEwMOyM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenizer(text): # create a tokenizer function for gloVe\n",
        "    res = [tok.text for tok in nlp_spaCy.tokenizer(text)]\n",
        "    return res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WO69uqM3LtBS",
        "outputId": "52f343c1-adb2-4c9a-af23-56dff2b28315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a',LABEL),\n",
        "               ('subtask_b',LABEL),\n",
        "               ('subtask_c',LABEL)]\n",
        "\n",
        "\n",
        "train = data.TabularDataset(train_fp, format='TSV', fields = \n",
        "                            data_fields, skip_header=True, filter_pred=None)\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d') #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
        "\n",
        "LABEL.build_vocab(train.subtask_a)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)\n",
        "\n",
        "# For retrieving tweet text later on\n",
        "train_df = pd.read_csv(train_fp, delimiter=\"\\t\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 10592\n",
            "Validation size: 2648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KkGDZeI-rccB",
        "outputId": "1b74f8d4-7c62-4085-f278-0b686661b352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "print('first tweet', train[0].tweet)\n",
        "print('first label', train[0].subtask_a)\n",
        "print(\"first tweet id:\", train[0].id)\n",
        "# print(TEXT.vocab.stoi) # word to index\n",
        "# print(LABEL.vocab.stoi) # word to index\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first tweet ['@user', '@user', 'a', 'must', 'read', '!', 'url']\n",
            "first label NOT\n",
            "first tweet id: 29719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q9_NCwh3C1Z4",
        "outputId": "ba2842c5-f6e8-45bb-fcdc-f10f90fc40ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#check loader\n",
        "for idx, batch in enumerate(train_iterator):\n",
        "    inputs, labels = batch.tweet, batch.subtask_a\n",
        "    print(inputs.shape)\n",
        "    print(labels.shape)\n",
        "    print(len(train_iterator))\n",
        "    break\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 74])\n",
            "torch.Size([128])\n",
            "83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "k4UHz12y6L7m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "\n",
        "def check_accuracy(task_header, loader, model, conf=False):\n",
        "    \"\"\"\n",
        "    Note at the moment this function assumes the batch size is equal to the \n",
        "    number of data in the loader when calculating the confusion matrix\n",
        "    \"\"\"\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    \n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(loader):\n",
        "            x, y = batch.tweet, getattr(batch, task_header)\n",
        "            y = y.view(-1, 1)\n",
        "                \n",
        "            x = x.to(device=device, dtype=torch.long)  # move to  GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            \n",
        "            if task_header == 'subtask_c':\n",
        "              pred_prob = F.softmax(model(x), dim=1)\n",
        "              pred_1 = torch.argmax(pred_prob, dim=1).view(-1, 1)\n",
        "            else:\n",
        "              pred_prob = torch.sigmoid(model(x))\n",
        "              pred_1 = (pred_prob > 0.5).type(torch.long)\n",
        "              \n",
        "            num_correct += (pred_1 == y).sum()\n",
        "            num_samples += pred_prob.size(0)\n",
        "            \n",
        "            # move to CPU to prevent memory overflow and calculate metrics\n",
        "            x = x.to(device=\"cpu\", dtype=torch.long)\n",
        "            y = y.to(device=\"cpu\", dtype=torch.long).numpy()\n",
        "            pred_1 = pred_1.to(device=\"cpu\", dtype=torch.long).numpy()\n",
        "            \n",
        "            \n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "        if conf:\n",
        "            print(metrics.confusion_matrix(y, pred_1))\n",
        "            print(metrics.classification_report(y, pred_1))\n",
        "            \n",
        "def check_loss(task_header, loader, model, loss_fn):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    loss = 0\n",
        "    for idx, batch in enumerate(loader):\n",
        "      x, y = batch.tweet, getattr(batch, task_header)\n",
        "      \n",
        "      x = x.to(device=device, dtype=torch.long) \n",
        "      y = y.to(device=device, dtype=torch.long if task_header == 'subtask_c' else torch.float)\n",
        "      \n",
        "      logits = model(x)\n",
        "      \n",
        "      loss += loss_fn(logits, y.view(-1,) if isinstance(loss_fn, nn.CrossEntropyLoss) else y.view(-1, 1))\n",
        "      \n",
        "    return loss/len(loader)\n",
        "      \n",
        "\n",
        "def train_helper(task_header, model, optimizer, train_loader, \n",
        "               valid_loader, epochs=1, loss_fn=F.binary_cross_entropy_with_logits, print_every=50):\n",
        "    \"\"\"\n",
        "    Train a model\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to GPU\n",
        "    \n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "    try:\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:\", epoch)\n",
        "            total_loss = 0\n",
        "            for batch_idx, batch in enumerate(train_loader):\n",
        "\n",
        "                model.train()  # put model to training mode\n",
        "                \n",
        "                inputs, targets = batch.tweet, getattr(batch, task_header)\n",
        "                \n",
        "                x = inputs.to(device=device, dtype=torch.long)  # move to device, e.g. GPU\n",
        "                y = targets.to(device=device, dtype=torch.long if task_header == 'subtask_c' else torch.float) #this should be a float cross entropy\n",
        "                #x = inputs\n",
        "                #y = targets\n",
        "                logits = model(x)\n",
        "                \n",
        "                # When using cross_entropy the targets need to have a shape (N,)\n",
        "                # However, for BCEWithLogits they just need\n",
        "                # to have the same shape as the logits\n",
        "                loss = loss_fn(logits, y.view(-1,) if isinstance(loss_fn, nn.CrossEntropyLoss) else y.view(-1, 1))\n",
        "                # Zero out all of the gradients for the variables which the optimizer\n",
        "                # will update.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # This is the backwards pass: compute the gradient of the loss with\n",
        "                # respect to each  parameter of the model.\n",
        "                loss.backward()\n",
        "\n",
        "                # Actually update the parameters of the model using the gradients\n",
        "                # computed by the backwards pass.\n",
        "                optimizer.step()\n",
        "\n",
        "                x = x.to(device=\"cpu\", dtype=torch.long)  # move to CPU to prevent memory overflow\n",
        "                y = y.to(device=\"cpu\", dtype=torch.long)\n",
        "\n",
        "                total_loss += loss.detach().item()\n",
        "                \n",
        "                if batch_idx % print_every == 0:\n",
        "                    print('Iteration %d, loss = %.4f' % (batch_idx, loss.item()))\n",
        "            \n",
        "            training_losses.append(total_loss/len(train_iterator))\n",
        "            print()\n",
        "            print(\"Validation Accuracy:\")\n",
        "            check_accuracy(task_header, valid_loader, model, conf=True)\n",
        "            valid_loss = check_loss(task_header, valid_loader, model, loss_fn)\n",
        "            validation_losses.append(valid_loss)\n",
        "            print()\n",
        "        return training_losses, validation_losses\n",
        "    except Exception as e:\n",
        "        #Attempt to prevent GPU memory overflow by transferring model back to cpu\n",
        "        #model = model.to(device=\"cpu\")\n",
        "        raise e    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeisH53s6cfR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#embedding (lookup layer) layer\n",
        "class SimpleClassifierGloVe(nn.Module):\n",
        "    \"\"\"Glove w. 2d conv\"\"\"\n",
        "    \n",
        "    def __init__(self, vocab, embedding_dim, window_size, out_channels, dropout, num_classes=2):\n",
        "        \n",
        "        super(SimpleClassifierGloVe, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.vocab = vocab\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "        self.embedding.weight.data.copy_(vocab.vectors) # copies pre-trained word vectors\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(window_size, embedding_dim))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(out_channels, 1 if num_classes == 2 else num_classes)\n",
        "\n",
        "        #Kaming normalization\n",
        "        nn.init.kaiming_normal_(self.conv.weight)\n",
        "        nn.init.kaiming_normal_(self.fc.weight)\n",
        "\n",
        "        \n",
        "        \n",
        "    def forward(self, x, ):\n",
        "        \n",
        "        embedded = self.embedding(x)\n",
        "                \n",
        "        #(batch size, max sent length, embedding dim)\n",
        "        \n",
        "        #images have 3 RGB channels \n",
        "        #for the text we add 1 channel\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #(batch size, 1, max sent length, embedding dim)\n",
        "        \n",
        "        feature_maps =  F.relu(self.conv(embedded).squeeze(3))\n",
        "        # (batch size, out_channels, max sent length - window size +1, 1)\n",
        "        # -> (batch size, out_channels, max sent length - window size +1)\n",
        "           \n",
        "        #the max pooling layer\n",
        "        pooled = F.max_pool1d(feature_maps, feature_maps.shape[2]).squeeze(2)\n",
        "        # (batch size, out_channels)      \n",
        "        \n",
        "        # Do batch normalize pooled then at sentiment\n",
        "        \n",
        "        return self.fc( self.dropout(pooled))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "X9LseL5F9n7P",
        "outputId": "6454583f-0431-4274-9686-57c012147fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6065
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab, embedding_dim, window_size, out_channels, dropout)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_a', model, optimizer, loss_fn = loss_fn, epochs = 20, train_loader=train_iterator, valid_loader=valid_iterator)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 0.9912\n",
            "Iteration 50, loss = 0.8042\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1817 / 2648 correct (68.62)\n",
            "[[1733   40]\n",
            " [ 791   84]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.98      0.81      1773\n",
            "           1       0.68      0.10      0.17       875\n",
            "\n",
            "   micro avg       0.69      0.69      0.69      2648\n",
            "   macro avg       0.68      0.54      0.49      2648\n",
            "weighted avg       0.68      0.69      0.60      2648\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 0.7402\n",
            "Iteration 50, loss = 0.6156\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1861 / 2648 correct (70.28)\n",
            "[[1726   47]\n",
            " [ 740  135]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.97      0.81      1773\n",
            "           1       0.74      0.15      0.26       875\n",
            "\n",
            "   micro avg       0.70      0.70      0.70      2648\n",
            "   macro avg       0.72      0.56      0.53      2648\n",
            "weighted avg       0.71      0.70      0.63      2648\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 0.6030\n",
            "Iteration 50, loss = 0.5625\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1911 / 2648 correct (72.17)\n",
            "[[1711   62]\n",
            " [ 675  200]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.97      0.82      1773\n",
            "           1       0.76      0.23      0.35       875\n",
            "\n",
            "   micro avg       0.72      0.72      0.72      2648\n",
            "   macro avg       0.74      0.60      0.59      2648\n",
            "weighted avg       0.73      0.72      0.67      2648\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.5909\n",
            "Iteration 50, loss = 0.6883\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1978 / 2648 correct (74.70)\n",
            "[[1658  115]\n",
            " [ 555  320]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.94      0.83      1773\n",
            "           1       0.74      0.37      0.49       875\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2648\n",
            "   macro avg       0.74      0.65      0.66      2648\n",
            "weighted avg       0.74      0.75      0.72      2648\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.5115\n",
            "Iteration 50, loss = 0.5996\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2017 / 2648 correct (76.17)\n",
            "[[1644  129]\n",
            " [ 502  373]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.93      0.84      1773\n",
            "           1       0.74      0.43      0.54       875\n",
            "\n",
            "   micro avg       0.76      0.76      0.76      2648\n",
            "   macro avg       0.75      0.68      0.69      2648\n",
            "weighted avg       0.76      0.76      0.74      2648\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.5024\n",
            "Iteration 50, loss = 0.4625\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2049 / 2648 correct (77.38)\n",
            "[[1622  151]\n",
            " [ 448  427]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.91      0.84      1773\n",
            "           1       0.74      0.49      0.59       875\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2648\n",
            "   macro avg       0.76      0.70      0.72      2648\n",
            "weighted avg       0.77      0.77      0.76      2648\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.5100\n",
            "Iteration 50, loss = 0.4919\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2058 / 2648 correct (77.72)\n",
            "[[1624  149]\n",
            " [ 441  434]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85      1773\n",
            "           1       0.74      0.50      0.60       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.77      0.71      0.72      2648\n",
            "weighted avg       0.77      0.78      0.76      2648\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.4323\n",
            "Iteration 50, loss = 0.4087\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2077 / 2648 correct (78.44)\n",
            "[[1599  174]\n",
            " [ 397  478]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.90      0.85      1773\n",
            "           1       0.73      0.55      0.63       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.77      0.72      0.74      2648\n",
            "weighted avg       0.78      0.78      0.77      2648\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.3355\n",
            "Iteration 50, loss = 0.4003\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2073 / 2648 correct (78.29)\n",
            "[[1635  138]\n",
            " [ 437  438]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85      1773\n",
            "           1       0.76      0.50      0.60       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.77      0.71      0.73      2648\n",
            "weighted avg       0.78      0.78      0.77      2648\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.3467\n",
            "Iteration 50, loss = 0.3878\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2083 / 2648 correct (78.66)\n",
            "[[1628  145]\n",
            " [ 420  455]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85      1773\n",
            "           1       0.76      0.52      0.62       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.78      0.72      0.73      2648\n",
            "weighted avg       0.78      0.79      0.77      2648\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.3240\n",
            "Iteration 50, loss = 0.3761\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2091 / 2648 correct (78.97)\n",
            "[[1609  164]\n",
            " [ 393  482]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85      1773\n",
            "           1       0.75      0.55      0.63       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.73      0.74      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.3280\n",
            "Iteration 50, loss = 0.3394\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2098 / 2648 correct (79.23)\n",
            "[[1612  161]\n",
            " [ 389  486]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.85      1773\n",
            "           1       0.75      0.56      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.78      0.73      0.75      2648\n",
            "weighted avg       0.79      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.3087\n",
            "Iteration 50, loss = 0.2954\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2102 / 2648 correct (79.38)\n",
            "[[1618  155]\n",
            " [ 391  484]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.86      1773\n",
            "           1       0.76      0.55      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.78      0.73      0.75      2648\n",
            "weighted avg       0.79      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.3426\n",
            "Iteration 50, loss = 0.3220\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2098 / 2648 correct (79.23)\n",
            "[[1584  189]\n",
            " [ 361  514]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85      1773\n",
            "           1       0.73      0.59      0.65       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.79      0.79      0.79      2648\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.3687\n",
            "Iteration 50, loss = 0.2941\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2098 / 2648 correct (79.23)\n",
            "[[1594  179]\n",
            " [ 371  504]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.74      0.58      0.65       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.79      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.2425\n",
            "Iteration 50, loss = 0.2859\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2097 / 2648 correct (79.19)\n",
            "[[1576  197]\n",
            " [ 354  521]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85      1773\n",
            "           1       0.73      0.60      0.65       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.79      0.79      0.79      2648\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.2427\n",
            "Iteration 50, loss = 0.2177\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2096 / 2648 correct (79.15)\n",
            "[[1579  194]\n",
            " [ 358  517]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85      1773\n",
            "           1       0.73      0.59      0.65       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.79      0.79      0.79      2648\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.2618\n",
            "Iteration 50, loss = 0.2824\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2103 / 2648 correct (79.42)\n",
            "[[1611  162]\n",
            " [ 383  492]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.86      1773\n",
            "           1       0.75      0.56      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.78      0.74      0.75      2648\n",
            "weighted avg       0.79      0.79      0.79      2648\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.2191\n",
            "Iteration 50, loss = 0.2578\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2097 / 2648 correct (79.19)\n",
            "[[1589  184]\n",
            " [ 367  508]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.73      0.58      0.65       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.79      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.2438\n",
            "Iteration 50, loss = 0.2115\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2081 / 2648 correct (78.59)\n",
            "[[1566  207]\n",
            " [ 360  515]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.85      1773\n",
            "           1       0.71      0.59      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.76      0.74      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_q8EEjwwLf3",
        "colab_type": "code",
        "outputId": "ac4c602d-4982-46e6-efda-82da837bd07b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "VFiG4aRQPpN5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task B"
      ]
    },
    {
      "metadata": {
        "id": "2YbsX0DyP1B0",
        "colab_type": "code",
        "outputId": "6440784c-3b00-4af1-cfae-904f357615c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a', LABEL),\n",
        "               ('subtask_b',LABEL)\n",
        "              ]\n",
        "\n",
        "train = data.TabularDataset(train_fp, format='TSV', fields = \n",
        "                            data_fields, skip_header=True, filter_pred=lambda d: d.subtask_a == 'OFF')\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d') #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
        "\n",
        "LABEL.build_vocab(train.subtask_b)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "print(LABEL.vocab.stoi)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 3520\n",
            "Validation size: 880\n",
            "defaultdict(<function _default_unk_index at 0x7f350e4ac598>, {'TIN': 0, 'UNT': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uww_bdubSnf3",
        "colab_type": "code",
        "outputId": "964b2171-2db5-4853-956a-519552f58bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5782
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab, embedding_dim, window_size, out_channels, dropout)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_b', model, optimizer, loss_fn = loss_fn, epochs = 20, train_loader=train_iterator, valid_loader=valid_iterator)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 0.8511\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "[[768   0]\n",
            " [112   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 0.5818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "[[768   0]\n",
            " [112   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 0.4405\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 767 / 880 correct (87.16)\n",
            "[[766   2]\n",
            " [111   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.33      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.60      0.50      0.47       880\n",
            "weighted avg       0.80      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.2660\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[766   2]\n",
            " [109   3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.60      0.03      0.05       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.74      0.51      0.49       880\n",
            "weighted avg       0.84      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.3367\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.3301\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.4049\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.2809\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.3704\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.3494\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.2880\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.2973\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.2461\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 771 / 880 correct (87.61)\n",
            "[[767   1]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.80      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.84      0.52      0.50       880\n",
            "weighted avg       0.87      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.1750\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 771 / 880 correct (87.61)\n",
            "[[766   2]\n",
            " [107   5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.71      0.04      0.08       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.80      0.52      0.51       880\n",
            "weighted avg       0.86      0.88      0.83       880\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.2645\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 772 / 880 correct (87.73)\n",
            "[[766   2]\n",
            " [106   6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.75      0.05      0.10       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.81      0.53      0.52       880\n",
            "weighted avg       0.86      0.88      0.83       880\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.3000\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 771 / 880 correct (87.61)\n",
            "[[767   1]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.80      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.84      0.52      0.50       880\n",
            "weighted avg       0.87      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.2369\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 772 / 880 correct (87.73)\n",
            "[[766   2]\n",
            " [106   6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.75      0.05      0.10       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.81      0.53      0.52       880\n",
            "weighted avg       0.86      0.88      0.83       880\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.2519\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 772 / 880 correct (87.73)\n",
            "[[766   2]\n",
            " [106   6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.75      0.05      0.10       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.81      0.53      0.52       880\n",
            "weighted avg       0.86      0.88      0.83       880\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.1988\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 773 / 880 correct (87.84)\n",
            "[[766   2]\n",
            " [105   7]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.78      0.06      0.12       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.83      0.53      0.53       880\n",
            "weighted avg       0.87      0.88      0.83       880\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.2493\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 773 / 880 correct (87.84)\n",
            "[[766   2]\n",
            " [105   7]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.78      0.06      0.12       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.83      0.53      0.53       880\n",
            "weighted avg       0.87      0.88      0.83       880\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AiLub0TBVF_i",
        "colab_type": "code",
        "outputId": "dd964608-875d-448a-f658-7c40fe024587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVA80AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HzDUdTT8Agxo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task C"
      ]
    },
    {
      "metadata": {
        "id": "Wf47-PIDAlIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "cb1894c8-4f6a-4de6-bd8d-75b366e19c3b"
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a', LABEL),\n",
        "               ('subtask_b',LABEL),\n",
        "               ('subtask_c', LABEL)\n",
        "              ]\n",
        "\n",
        "train = data.TabularDataset(train_fp, format='TSV', fields = \n",
        "                            data_fields, skip_header=True, filter_pred=lambda d: d.subtask_a == 'OFF' and d.subtask_b == 'TIN')\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d') #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
        "\n",
        "LABEL.build_vocab(train.subtask_c)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "print(LABEL.vocab.stoi)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 3101\n",
            "Validation size: 775\n",
            "defaultdict(<function _default_unk_index at 0x7f350e4ac598>, {'IND': 0, 'GRP': 1, 'OTH': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UTUbzJZBBBMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6454
        },
        "outputId": "6d658441-a7fa-4eaa-afaf-16dd12223dbc"
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab, embedding_dim, window_size, out_channels, dropout, num_classes=3)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_c', model, optimizer, loss_fn = loss_fn, epochs = 20, train_loader=train_iterator, valid_loader=valid_iterator)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 2.3727\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 470 / 775 correct (60.65)\n",
            "[[467   7   2]\n",
            " [204   3   0]\n",
            " [ 91   1   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.98      0.75       476\n",
            "           1       0.27      0.01      0.03       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.61      0.61      0.61       775\n",
            "   macro avg       0.30      0.33      0.26       775\n",
            "weighted avg       0.45      0.61      0.47       775\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 1.3247\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 487 / 775 correct (62.84)\n",
            "[[464  11   1]\n",
            " [184  23   0]\n",
            " [ 85   7   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.97      0.77       476\n",
            "           1       0.56      0.11      0.19       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.63      0.63      0.63       775\n",
            "   macro avg       0.40      0.36      0.32       775\n",
            "weighted avg       0.54      0.63      0.52       775\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 1.4876\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 490 / 775 correct (63.23)\n",
            "[[462  13   1]\n",
            " [179  28   0]\n",
            " [ 84   8   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.97      0.77       476\n",
            "           1       0.57      0.14      0.22       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.63      0.63      0.63       775\n",
            "   macro avg       0.40      0.37      0.33       775\n",
            "weighted avg       0.54      0.63      0.53       775\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.8619\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 505 / 775 correct (65.16)\n",
            "[[448  27   1]\n",
            " [150  57   0]\n",
            " [ 76  16   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.94      0.78       476\n",
            "           1       0.57      0.28      0.37       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.65      0.65      0.65       775\n",
            "   macro avg       0.41      0.41      0.38       775\n",
            "weighted avg       0.56      0.65      0.58       775\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.8480\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 512 / 775 correct (66.06)\n",
            "[[447  28   1]\n",
            " [142  65   0]\n",
            " [ 74  18   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.94      0.78       476\n",
            "           1       0.59      0.31      0.41       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.66      0.66      0.66       775\n",
            "   macro avg       0.42      0.42      0.40       775\n",
            "weighted avg       0.57      0.66      0.59       775\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.9497\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 520 / 775 correct (67.10)\n",
            "[[440  36   0]\n",
            " [127  80   0]\n",
            " [ 72  20   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.92      0.79       476\n",
            "           1       0.59      0.39      0.47       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.67      0.67      0.67       775\n",
            "   macro avg       0.43      0.44      0.42       775\n",
            "weighted avg       0.58      0.67      0.61       775\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.8494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Accuracy:\n",
            "Got 526 / 775 correct (67.87)\n",
            "[[437  39   0]\n",
            " [118  89   0]\n",
            " [ 69  23   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.92      0.79       476\n",
            "           1       0.59      0.43      0.50       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.43      0.45      0.43       775\n",
            "weighted avg       0.59      0.68      0.62       775\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.8481\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 527 / 775 correct (68.00)\n",
            "[[442  33   1]\n",
            " [122  85   0]\n",
            " [ 72  20   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.93      0.79       476\n",
            "           1       0.62      0.41      0.49       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.44      0.45      0.43       775\n",
            "weighted avg       0.59      0.68      0.62       775\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.7493\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 530 / 775 correct (68.39)\n",
            "[[438  37   1]\n",
            " [115  92   0]\n",
            " [ 68  24   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.92      0.80       476\n",
            "           1       0.60      0.44      0.51       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.44      0.45      0.44       775\n",
            "weighted avg       0.59      0.68      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.8177\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 524 / 775 correct (67.61)\n",
            "[[434  41   1]\n",
            " [117  90   0]\n",
            " [ 68  24   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.91      0.79       476\n",
            "           1       0.58      0.43      0.50       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.43      0.45      0.43       775\n",
            "weighted avg       0.59      0.68      0.62       775\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.7463\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 526 / 775 correct (67.87)\n",
            "[[434  41   1]\n",
            " [115  92   0]\n",
            " [ 68  24   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.91      0.79       476\n",
            "           1       0.59      0.44      0.51       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.43      0.45      0.43       775\n",
            "weighted avg       0.59      0.68      0.62       775\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.8494\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 521 / 775 correct (67.23)\n",
            "[[424  51   1]\n",
            " [110  97   0]\n",
            " [ 65  27   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.89      0.79       476\n",
            "           1       0.55      0.47      0.51       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.67      0.67      0.67       775\n",
            "   macro avg       0.42      0.45      0.43       775\n",
            "weighted avg       0.58      0.67      0.62       775\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.6226\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 526 / 775 correct (67.87)\n",
            "[[426  49   1]\n",
            " [107 100   0]\n",
            " [ 64  28   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.89      0.79       476\n",
            "           1       0.56      0.48      0.52       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.43      0.46      0.44       775\n",
            "weighted avg       0.59      0.68      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.6185\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 528 / 775 correct (68.13)\n",
            "[[424  51   1]\n",
            " [103 104   0]\n",
            " [ 62  30   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.89      0.80       476\n",
            "           1       0.56      0.50      0.53       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.43      0.46      0.44       775\n",
            "weighted avg       0.59      0.68      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.7378\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 527 / 775 correct (68.00)\n",
            "[[432  43   1]\n",
            " [112  95   0]\n",
            " [ 63  29   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.91      0.80       476\n",
            "           1       0.57      0.46      0.51       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.43      0.46      0.44       775\n",
            "weighted avg       0.59      0.68      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.5128\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 535 / 775 correct (69.03)\n",
            "[[426  49   1]\n",
            " [ 98 109   0]\n",
            " [ 57  35   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.89      0.81       476\n",
            "           1       0.56      0.53      0.55       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.43      0.47      0.45       775\n",
            "weighted avg       0.60      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.5899\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 530 / 775 correct (68.39)\n",
            "[[430  45   1]\n",
            " [107 100   0]\n",
            " [ 61  31   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.90      0.80       476\n",
            "           1       0.57      0.48      0.52       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.43      0.46      0.44       775\n",
            "weighted avg       0.59      0.68      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.6105\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 531 / 775 correct (68.52)\n",
            "[[429  46   1]\n",
            " [105 102   0]\n",
            " [ 60  32   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.90      0.80       476\n",
            "           1       0.57      0.49      0.53       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.43      0.46      0.44       775\n",
            "weighted avg       0.59      0.69      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.6204\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 529 / 775 correct (68.26)\n",
            "[[432  43   1]\n",
            " [110  97   0]\n",
            " [ 61  31   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.91      0.80       476\n",
            "           1       0.57      0.47      0.51       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.43      0.46      0.44       775\n",
            "weighted avg       0.59      0.68      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.5296\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 535 / 775 correct (69.03)\n",
            "[[429  46   1]\n",
            " [101 106   0]\n",
            " [ 57  35   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.90      0.81       476\n",
            "           1       0.57      0.51      0.54       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.43      0.47      0.45       775\n",
            "weighted avg       0.60      0.69      0.64       775\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TSbEtokDP1Dy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "c9885368-f9cd-4b63-dc1d-7ff0c4a8ad8d"
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "zza6aQ1QnMyy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}