{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_CW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "xGMVF5KTg-He",
        "t9Zt3py7E1ep",
        "SClCUJp08-zn",
        "u7glEGKc-rNE"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adesam146/nlpcw/blob/rest_of_tasks/NLP_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_i_qSkEMxlkg"
      },
      "cell_type": "markdown",
      "source": [
        "## Check GPU memory"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5-XwNX-831V6",
        "outputId": "0969aea8-bb7c-435c-95ec-3bc7d5a47942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "cell_type": "code",
      "source": [
        "#Check GPU Memory allocation\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NOXcwqriwFsu",
        "outputId": "55a6f646-18f1-4d45-a770-8314a032a7fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.9 GB  | Proc size: 142.4 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ecWOCoFgxS_j",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#run this if GPU utilization is not 0%\n",
        "# !kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wTfeo8tcxhwC"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ePuqIHSPf554",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U spacy ftfy torchtext\n",
        "!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Srpq8hYt4whg",
        "outputId": "854e1e1b-5883-44dd-f24c-579a1b0e4263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import sampler\n",
        "import spacy\n",
        "from torchtext import data\n",
        "from torchtext import datasets as nlp_dset\n",
        "import random\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "nlp_spaCy = spacy.load('en')\n",
        "\n",
        "GPU = True\n",
        "device_idx = 0\n",
        "if GPU:\n",
        "    device = torch.device(\"cuda:\"+str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "#Fix all seeds\n",
        "SEED = 0\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qtiwRhtm3s87",
        "outputId": "6499c4b1-907f-4236-bb4b-48ec1c0f0eea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "# Load datafiles from own google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_fp = \"\"\"/content/drive/My Drive/colab_data/offenseval-training-v1.tsv\"\"\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X3kA7Y0BjUnF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "64d419bd-8126-42a2-ff6c-dacf0befab2a"
      },
      "cell_type": "code",
      "source": [
        "# Used two GloVe trained on two different corpuses for comparison:\n",
        "# glove.twitter.27B\n",
        "# TAKES ABOUT FIVE MINUTES TO DOWNLOAD ON COLAB\n",
        "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip glove.twitter.27B.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-01 06:17:24--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
            "--2019-03-01 06:17:24--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  13.9MB/s    in 4m 16s  \n",
            "\n",
            "2019-03-01 06:21:40 (5.67 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n",
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "t9Zt3py7E1ep"
      },
      "cell_type": "markdown",
      "source": [
        "## Import and preprocess Data"
      ]
    },
    {
      "metadata": {
        "id": "8WRa2x424R1s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenizer(text): # create a tokenizer function for gloVe\n",
        "    res = [tok.text for tok in nlp_spaCy.tokenizer(text)]\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z9qQiPkQ3cna",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def downsample(train_df):\n",
        "  #ONLY USE THIS IF YOU WANT TO DOWNSAMPLE DATA - everything should work w/o this cell\n",
        "  #Select a subset of the data so that the classes are equally balanced\n",
        "  #Use downsampling for now. \n",
        "\n",
        "  num_NOT = 8840\n",
        "  num_OFF = 4400\n",
        "  # Separate majority and minority classes\n",
        "  df_majority = train_df[train_df[\"subtask_a\"] == 'NOT']\n",
        "  df_minority = train_df[train_df[\"subtask_a\"] == 'OFF']\n",
        "\n",
        "  # Downsample majority class\n",
        "  df_majority_downsampled = resample(df_majority, \n",
        "                                   replace=False,    # sample without replacement\n",
        "                                   n_samples=num_OFF,     # to match minority class\n",
        "                                   random_state=123) # reproducible results\n",
        "\n",
        "  # Combine minority class with downsampled majority class\n",
        "  df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "  # Display new class counts\n",
        "  print(df_downsampled.subtask_a.value_counts())\n",
        "\n",
        "  df_downsampled = df_downsampled.sample(frac=1) #shuffle df\n",
        "\n",
        "  return df_downsampled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aMY0mUyknLDu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tweet_preprocess(tweet_text):\n",
        "  \"\"\"Add tweet specific preprocessing steps here\"\"\"\n",
        "  \n",
        "  #Remove 'USER' (but leave '@')\n",
        "  tweet_text = tweet_text.replace(\"@USER\", \"@\") \n",
        "  \n",
        "  return tweet_text\n",
        "\n",
        "def convert_labels_A(labels):\n",
        "    \"\"\"Preproceses and return labels\"\"\"\n",
        "\n",
        "    final_labels = []\n",
        "    for label in labels:\n",
        "        assert label == \"OFF\" or label == \"NOT\", \"Label should not be: {}\".format(label)\n",
        "    \n",
        "        if label == \"OFF\":\n",
        "            res = 1\n",
        "        elif label == \"NOT\":\n",
        "            res = 0        \n",
        "        label = torch.tensor([res])\n",
        "        final_labels.append(label)\n",
        "    return final_labels\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "imjsxr66hDWP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def transfrom_for_scikit(task_header, text_field, label_field, embedding, train):\n",
        "  \"\"\"\n",
        "  task_header is one of subtask_a, subtask_b, subtask_c\n",
        "  \"\"\"\n",
        "  tokenised_train = [example.tweet for example in train]\n",
        "  labels = np.array(\n",
        "      label_field.process(\n",
        "          [getattr(example, task_header) for example in train]\n",
        "      )\n",
        "  )\n",
        "  \n",
        "  word_idxs = text_field.process(tokenised_train)\n",
        "  embeddings = torch.mean(embedding(word_idxs).detach(), dim=1)\n",
        "  \n",
        "  return embeddings.numpy(), labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuWD9loshx_X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Utils Functions For Neural Network Classifer"
      ]
    },
    {
      "metadata": {
        "id": "C8q-_NUtiT8n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def check_accuracy(task_header, loader, model, conf=False):\n",
        "    \"\"\"\n",
        "    Note at the moment this function assumes the batch size is equal to the \n",
        "    number of data in the loader when calculating the confusion matrix\n",
        "    \"\"\"\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    \n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(loader):\n",
        "            x, y = batch.tweet, getattr(batch, task_header)\n",
        "            y = y.view(-1, 1)\n",
        "                \n",
        "            x = x.to(device=device, dtype=torch.long)  # move to  GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            \n",
        "            if task_header == 'subtask_c':\n",
        "              pred_prob = F.softmax(model(x), dim=1)\n",
        "              pred_1 = torch.argmax(pred_prob, dim=1).view(-1, 1)\n",
        "            else:\n",
        "              pred_prob = torch.sigmoid(model(x))\n",
        "              pred_1 = (pred_prob > 0.5).type(torch.long)\n",
        "              \n",
        "            num_correct += (pred_1 == y).sum()\n",
        "            num_samples += pred_prob.size(0)\n",
        "            \n",
        "            # move to CPU to prevent memory overflow and calculate metrics\n",
        "            x = x.to(device=\"cpu\", dtype=torch.long)\n",
        "            y = y.to(device=\"cpu\", dtype=torch.long).numpy()\n",
        "            pred_1 = pred_1.to(device=\"cpu\", dtype=torch.long).numpy()\n",
        "            \n",
        "            \n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "        if conf:\n",
        "            print(metrics.confusion_matrix(y, pred_1))\n",
        "            print(metrics.classification_report(y, pred_1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oXFOMchMitEY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def check_loss(task_header, loader, model, loss_fn):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    loss = 0\n",
        "    for idx, batch in enumerate(loader):\n",
        "      x, y = batch.tweet, getattr(batch, task_header)\n",
        "      \n",
        "      x = x.to(device=device, dtype=torch.long) \n",
        "      y = y.to(device=device, dtype=torch.long if task_header == 'subtask_c' else torch.float)\n",
        "      \n",
        "      logits = model(x)\n",
        "      \n",
        "      loss += loss_fn(logits, y.view(-1,) if isinstance(loss_fn, nn.CrossEntropyLoss) else y.view(-1, 1))\n",
        "      \n",
        "    return loss/len(loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YurUJzZji6Rq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_helper(task_header, model, optimizer, train_loader, \n",
        "               valid_loader, epochs=1, loss_fn=F.binary_cross_entropy_with_logits, print_every=50):\n",
        "    \"\"\"\n",
        "    Train a model\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to GPU\n",
        "    \n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "    try:\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:\", epoch)\n",
        "            total_loss = 0\n",
        "            for batch_idx, batch in enumerate(train_loader):\n",
        "\n",
        "                model.train()  # put model to training mode\n",
        "                \n",
        "                inputs, targets = batch.tweet, getattr(batch, task_header)\n",
        "                \n",
        "                x = inputs.to(device=device, dtype=torch.long)  # move to device, e.g. GPU\n",
        "                y = targets.to(device=device, dtype=torch.long if task_header == 'subtask_c' else torch.float) #this should be a float cross entropy\n",
        "                #x = inputs\n",
        "                #y = targets\n",
        "                logits = model(x)\n",
        "                \n",
        "                # When using cross_entropy the targets need to have a shape (N,)\n",
        "                # However, for BCEWithLogits they just need\n",
        "                # to have the same shape as the logits\n",
        "                loss = loss_fn(logits, y.view(-1,) if isinstance(loss_fn, nn.CrossEntropyLoss) else y.view(-1, 1))\n",
        "                # Zero out all of the gradients for the variables which the optimizer\n",
        "                # will update.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # This is the backwards pass: compute the gradient of the loss with\n",
        "                # respect to each  parameter of the model.\n",
        "                loss.backward()\n",
        "\n",
        "                # Actually update the parameters of the model using the gradients\n",
        "                # computed by the backwards pass.\n",
        "                optimizer.step()\n",
        "\n",
        "                x = x.to(device=\"cpu\", dtype=torch.long)  # move to CPU to prevent memory overflow\n",
        "                y = y.to(device=\"cpu\", dtype=torch.long)\n",
        "\n",
        "                total_loss += loss.detach().item()\n",
        "                \n",
        "                if batch_idx % print_every == 0:\n",
        "                    print('Iteration %d, loss = %.4f' % (batch_idx, loss.item()))\n",
        "            \n",
        "            training_losses.append(total_loss/len(train_iterator))\n",
        "            print()\n",
        "            print(\"Validation Accuracy:\")\n",
        "            check_accuracy(task_header, valid_loader, model, conf=True)\n",
        "            valid_loss = check_loss(task_header, valid_loader, model, loss_fn)\n",
        "            validation_losses.append(valid_loss)\n",
        "            print()\n",
        "        return training_losses, validation_losses\n",
        "    except Exception as e:\n",
        "        #Attempt to prevent GPU memory overflow by transferring model back to cpu\n",
        "        #model = model.to(device=\"cpu\")\n",
        "        raise e    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tl9IC4d1jx-0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network Classifiers"
      ]
    },
    {
      "metadata": {
        "id": "yuwrip1gj43k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#embedding (lookup layer) layer\n",
        "class SimpleClassifierGloVe(nn.Module):\n",
        "    \"\"\"Glove w. 2d conv\"\"\"\n",
        "    \n",
        "    def __init__(self, vocab, embedding_dim, window_size, out_channels, dropout, num_classes=2):\n",
        "        \n",
        "        super(SimpleClassifierGloVe, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.vocab = vocab\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "        self.embedding.weight.data.copy_(vocab.vectors) # copies pre-trained word vectors\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(window_size, embedding_dim))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(out_channels, 1 if num_classes == 2 else num_classes)\n",
        "\n",
        "        #Kaming normalization\n",
        "        nn.init.kaiming_normal_(self.conv.weight)\n",
        "        nn.init.kaiming_normal_(self.fc.weight)\n",
        "\n",
        "        \n",
        "        \n",
        "    def forward(self, x, ):\n",
        "        \n",
        "        embedded = self.embedding(x)\n",
        "                \n",
        "        #(batch size, max sent length, embedding dim)\n",
        "        \n",
        "        #images have 3 RGB channels \n",
        "        #for the text we add 1 channel\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #(batch size, 1, max sent length, embedding dim)\n",
        "        \n",
        "        feature_maps =  F.relu(self.conv(embedded).squeeze(3))\n",
        "        # (batch size, out_channels, max sent length - window size +1, 1)\n",
        "        # -> (batch size, out_channels, max sent length - window size +1)\n",
        "           \n",
        "        #the max pooling layer\n",
        "        pooled = F.max_pool1d(feature_maps, feature_maps.shape[2]).squeeze(2)\n",
        "        # (batch size, out_channels)      \n",
        "        \n",
        "        # Do batch normalize pooled then at sentiment\n",
        "        \n",
        "        return self.fc(self.dropout(pooled))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "n1TwMNFOKRSm"
      },
      "cell_type": "markdown",
      "source": [
        "## Task A"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WO69uqM3LtBS",
        "outputId": "61a5a5f4-2014-4ada-cf57-53e653b45cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a',LABEL),\n",
        "               ('subtask_b',LABEL),\n",
        "               ('subtask_c',LABEL)]\n",
        "\n",
        "\n",
        "train = data.TabularDataset(train_fp, format='TSV', fields = \n",
        "                            data_fields, skip_header=True, filter_pred=None)\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d') #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
        "\n",
        "LABEL.build_vocab(train.subtask_a)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)\n",
        "\n",
        "# For retrieving tweet text later on\n",
        "train_df = pd.read_csv(train_fp, delimiter=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 10592\n",
            "Validation size: 2648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KkGDZeI-rccB",
        "outputId": "05eb5dd8-a003-4beb-ca26-e6694f35ceee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "print('first tweet', train[0].tweet)\n",
        "print('first label', train[0].subtask_a)\n",
        "print(\"first tweet id:\", train[0].id)\n",
        "# print(TEXT.vocab.stoi) # word to index\n",
        "# print(LABEL.vocab.stoi) # label to index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first tweet ['@user', '@user', 'a', 'must', 'read', '!', 'url']\n",
            "first label NOT\n",
            "first tweet id: 29719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q9_NCwh3C1Z4",
        "outputId": "58d1200a-8e20-49fa-c7c5-5c9c2502adf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#check loader\n",
        "for idx, batch in enumerate(train_iterator):\n",
        "    inputs, labels = batch.tweet, batch.subtask_a\n",
        "    print(inputs.shape)\n",
        "    print(labels.shape)\n",
        "    print(len(train_iterator))\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 74])\n",
            "torch.Size([128])\n",
            "83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "X9LseL5F9n7P",
        "outputId": "b10f2b4e-6671-409d-b424-921f78a82fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6065
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab,\n",
        "                              embedding_dim,\n",
        "                              window_size,\n",
        "                              out_channels,\n",
        "                              dropout)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_a',\n",
        "                                  model,\n",
        "                                  optimizer,\n",
        "                                  loss_fn = loss_fn,\n",
        "                                  epochs = 20,\n",
        "                                  train_loader=train_iterator,\n",
        "                                  valid_loader=valid_iterator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 1.0084\n",
            "Iteration 50, loss = 0.8035\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1821 / 2648 correct (68.77)\n",
            "[[1718   55]\n",
            " [ 772  103]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.97      0.81      1773\n",
            "           1       0.65      0.12      0.20       875\n",
            "\n",
            "   micro avg       0.69      0.69      0.69      2648\n",
            "   macro avg       0.67      0.54      0.50      2648\n",
            "weighted avg       0.68      0.69      0.61      2648\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 0.7128\n",
            "Iteration 50, loss = 0.6590\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1868 / 2648 correct (70.54)\n",
            "[[1712   61]\n",
            " [ 719  156]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.97      0.81      1773\n",
            "           1       0.72      0.18      0.29       875\n",
            "\n",
            "   micro avg       0.71      0.71      0.71      2648\n",
            "   macro avg       0.71      0.57      0.55      2648\n",
            "weighted avg       0.71      0.71      0.64      2648\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 0.6487\n",
            "Iteration 50, loss = 0.5014\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1933 / 2648 correct (73.00)\n",
            "[[1703   70]\n",
            " [ 645  230]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.96      0.83      1773\n",
            "           1       0.77      0.26      0.39       875\n",
            "\n",
            "   micro avg       0.73      0.73      0.73      2648\n",
            "   macro avg       0.75      0.61      0.61      2648\n",
            "weighted avg       0.74      0.73      0.68      2648\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.5280\n",
            "Iteration 50, loss = 0.5373\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1990 / 2648 correct (75.15)\n",
            "[[1665  108]\n",
            " [ 550  325]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.94      0.84      1773\n",
            "           1       0.75      0.37      0.50       875\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2648\n",
            "   macro avg       0.75      0.66      0.67      2648\n",
            "weighted avg       0.75      0.75      0.72      2648\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.6007\n",
            "Iteration 50, loss = 0.5544\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2017 / 2648 correct (76.17)\n",
            "[[1630  143]\n",
            " [ 488  387]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.92      0.84      1773\n",
            "           1       0.73      0.44      0.55       875\n",
            "\n",
            "   micro avg       0.76      0.76      0.76      2648\n",
            "   macro avg       0.75      0.68      0.69      2648\n",
            "weighted avg       0.76      0.76      0.74      2648\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.4959\n",
            "Iteration 50, loss = 0.5011\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2045 / 2648 correct (77.23)\n",
            "[[1626  147]\n",
            " [ 456  419]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.92      0.84      1773\n",
            "           1       0.74      0.48      0.58       875\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2648\n",
            "   macro avg       0.76      0.70      0.71      2648\n",
            "weighted avg       0.77      0.77      0.76      2648\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.4487\n",
            "Iteration 50, loss = 0.4952\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2055 / 2648 correct (77.61)\n",
            "[[1617  156]\n",
            " [ 437  438]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.91      0.85      1773\n",
            "           1       0.74      0.50      0.60       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.76      0.71      0.72      2648\n",
            "weighted avg       0.77      0.78      0.76      2648\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.4686\n",
            "Iteration 50, loss = 0.3792\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2066 / 2648 correct (78.02)\n",
            "[[1592  181]\n",
            " [ 401  474]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.90      0.85      1773\n",
            "           1       0.72      0.54      0.62       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.76      0.72      0.73      2648\n",
            "weighted avg       0.77      0.78      0.77      2648\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.3789\n",
            "Iteration 50, loss = 0.4144\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2064 / 2648 correct (77.95)\n",
            "[[1635  138]\n",
            " [ 446  429]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85      1773\n",
            "           1       0.76      0.49      0.60       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.77      0.71      0.72      2648\n",
            "weighted avg       0.78      0.78      0.76      2648\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.3694\n",
            "Iteration 50, loss = 0.3616\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2076 / 2648 correct (78.40)\n",
            "[[1613  160]\n",
            " [ 412  463]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85      1773\n",
            "           1       0.74      0.53      0.62       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.77      0.72      0.73      2648\n",
            "weighted avg       0.78      0.78      0.77      2648\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.3268\n",
            "Iteration 50, loss = 0.3907\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2082 / 2648 correct (78.63)\n",
            "[[1592  181]\n",
            " [ 385  490]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.73      0.56      0.63       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.73      0.74      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.3464\n",
            "Iteration 50, loss = 0.3135\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2080 / 2648 correct (78.55)\n",
            "[[1590  183]\n",
            " [ 385  490]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.73      0.56      0.63       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.73      0.74      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.3259\n",
            "Iteration 50, loss = 0.3107\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2092 / 2648 correct (79.00)\n",
            "[[1615  158]\n",
            " [ 398  477]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85      1773\n",
            "           1       0.75      0.55      0.63       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.78      0.73      0.74      2648\n",
            "weighted avg       0.79      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.3701\n",
            "Iteration 50, loss = 0.3375\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2091 / 2648 correct (78.97)\n",
            "[[1585  188]\n",
            " [ 369  506]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85      1773\n",
            "           1       0.73      0.58      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.3490\n",
            "Iteration 50, loss = 0.2864\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2092 / 2648 correct (79.00)\n",
            "[[1591  182]\n",
            " [ 374  501]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.73      0.57      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.73      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.2411\n",
            "Iteration 50, loss = 0.3509\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2091 / 2648 correct (78.97)\n",
            "[[1580  193]\n",
            " [ 364  511]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85      1773\n",
            "           1       0.73      0.58      0.65       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.2526\n",
            "Iteration 50, loss = 0.2456\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2089 / 2648 correct (78.89)\n",
            "[[1591  182]\n",
            " [ 377  498]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.73      0.57      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.73      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.2801\n",
            "Iteration 50, loss = 0.3200\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2084 / 2648 correct (78.70)\n",
            "[[1613  160]\n",
            " [ 404  471]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85      1773\n",
            "           1       0.75      0.54      0.63       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.72      0.74      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.2132\n",
            "Iteration 50, loss = 0.2144\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2089 / 2648 correct (78.89)\n",
            "[[1587  186]\n",
            " [ 373  502]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.73      0.57      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.73      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.2225\n",
            "Iteration 50, loss = 0.2152\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2087 / 2648 correct (78.81)\n",
            "[[1580  193]\n",
            " [ 368  507]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85      1773\n",
            "           1       0.72      0.58      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_q8EEjwwLf3",
        "colab_type": "code",
        "outputId": "95d94d53-27b1-48da-b2be-7e4d9d3c582b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "m1ieRLJXxc4u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
        "embedding.weight.data.copy_(TEXT.vocab.vectors) # copies pre-trained word vectors\n",
        "\n",
        "training_embeddings, training_labels = transfrom_for_scikit('subtask_a', TEXT, LABEL, embedding, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7p1nXF7VxRTe",
        "colab_type": "code",
        "outputId": "cd7c3621-e964-4c30-edca-b593202740fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=20, tol=None, class_weight={1: 2})\n",
        "clf.fit(training_embeddings, training_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.001, average=False, class_weight={1: 2},\n",
              "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=20,\n",
              "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
              "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
              "       validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "metadata": {
        "id": "jY98yEhJxoSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_embeddings, val_labels = transfrom_for_scikit('subtask_a', TEXT, LABEL, embedding, valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "9b6df2f5-c431-4c8b-b319-94954af070c5",
        "id": "I20xsZIJIzu3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "cell_type": "code",
      "source": [
        "preds = clf.predict(val_embeddings)\n",
        "\n",
        "print(metrics.confusion_matrix(val_labels, preds))\n",
        "print(metrics.classification_report(val_labels, preds))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(val_labels, preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1426  347]\n",
            " [ 476  399]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.80      0.78      1773\n",
            "           1       0.53      0.46      0.49       875\n",
            "\n",
            "   micro avg       0.69      0.69      0.69      2648\n",
            "   macro avg       0.64      0.63      0.63      2648\n",
            "weighted avg       0.68      0.69      0.68      2648\n",
            "\n",
            "Accuracy: 0.6891993957703928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VFiG4aRQPpN5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task B"
      ]
    },
    {
      "metadata": {
        "id": "2YbsX0DyP1B0",
        "colab_type": "code",
        "outputId": "aa2e14dc-a69b-4ae9-f0d7-4d821f7f1af9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first=True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a', LABEL),\n",
        "               ('subtask_b',LABEL)\n",
        "              ]\n",
        "\n",
        "train = data.TabularDataset(train_fp,\n",
        "                            format='TSV',\n",
        "                            fields=data_fields,\n",
        "                            skip_header=True,\n",
        "                            filter_pred=lambda d: d.subtask_a == 'OFF')\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "# This is where tokenization is performed on train\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d')\n",
        "\n",
        "LABEL.build_vocab(train.subtask_b)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "print(LABEL.vocab.stoi)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 3520\n",
            "Validation size: 880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1192615/1193514 [01:49<00:00, 11216.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fee7f466620>, {'TIN': 0, 'UNT': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uww_bdubSnf3",
        "colab_type": "code",
        "outputId": "8b49dd56-398b-479a-aa59-019c29a24a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5782
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab, embedding_dim, window_size, out_channels, dropout)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_b',\n",
        "                                  model,\n",
        "                                  optimizer,\n",
        "                                  loss_fn = loss_fn,\n",
        "                                  epochs = 30,\n",
        "                                  train_loader=train_iterator,\n",
        "                                  valid_loader=valid_iterator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 0.7425\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "[[768   0]\n",
            " [112   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 0.4688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "[[768   0]\n",
            " [112   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 0.3960\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "[[768   0]\n",
            " [112   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.2444\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[768   0]\n",
            " [111   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.94      0.50      0.48       880\n",
            "weighted avg       0.89      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.3320\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[768   0]\n",
            " [111   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.94      0.50      0.48       880\n",
            "weighted avg       0.89      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.3889\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[768   0]\n",
            " [111   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.94      0.50      0.48       880\n",
            "weighted avg       0.89      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.3955\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[768   0]\n",
            " [111   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.94      0.50      0.48       880\n",
            "weighted avg       0.89      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.2923\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[768   0]\n",
            " [111   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.94      0.50      0.48       880\n",
            "weighted avg       0.89      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.3602\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[768   0]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.02      0.04       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.94      0.51      0.48       880\n",
            "weighted avg       0.89      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.3019\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.2834\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.2668\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.2525\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.2077\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.2513\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.2616\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.2226\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.2668\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.2147\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.2171\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AiLub0TBVF_i",
        "colab_type": "code",
        "outputId": "896774e5-5393-41b7-b873-d833d18b764e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "O4Q7ir143rdl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_dim = 200\n",
        "embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
        "embedding.weight.data.copy_(TEXT.vocab.vectors) # copies pre-trained word vectors\n",
        "\n",
        "training_embeddings, training_labels = transfrom_for_scikit('subtask_b', TEXT, LABEL, embedding, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_1ONs8nc3-G2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "e35b247d-ca37-4a46-94ba-b59161fd6d11"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=20, tol=None, class_weight={1: 6.8})\n",
        "clf.fit(training_embeddings, training_labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.001, average=False, class_weight={1: 6.8},\n",
              "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=20,\n",
              "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
              "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
              "       validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "--Z5tRoD494A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_embeddings, val_labels = transfrom_for_scikit('subtask_b', TEXT, LABEL, embedding, valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OYC4b0Xj5HUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "a65c29fc-b02c-4a04-8e4d-54d104c0a72b"
      },
      "cell_type": "code",
      "source": [
        "preds = clf.predict(val_embeddings)\n",
        "\n",
        "print(metrics.confusion_matrix(val_labels, preds))\n",
        "print(metrics.classification_report(val_labels, preds))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(val_labels, preds))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[425 343]\n",
            " [ 30  82]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.55      0.70       768\n",
            "           1       0.19      0.73      0.31       112\n",
            "\n",
            "   micro avg       0.58      0.58      0.58       880\n",
            "   macro avg       0.56      0.64      0.50       880\n",
            "weighted avg       0.84      0.58      0.65       880\n",
            "\n",
            "Accuracy: 0.5761363636363637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HzDUdTT8Agxo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task C"
      ]
    },
    {
      "metadata": {
        "id": "Wf47-PIDAlIw",
        "colab_type": "code",
        "outputId": "87c92913-516b-4004-f257-2e724831c7ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a', LABEL),\n",
        "               ('subtask_b',LABEL),\n",
        "               ('subtask_c', LABEL)\n",
        "              ]\n",
        "\n",
        "train = data.TabularDataset(train_fp,\n",
        "                            format='TSV',\n",
        "                            fields=data_fields,\n",
        "                            skip_header=True,\n",
        "                            filter_pred=lambda d: d.subtask_a == 'OFF' and d.subtask_b == 'TIN')\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d')\n",
        "\n",
        "LABEL.build_vocab(train.subtask_c)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "print(LABEL.vocab.stoi)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 3101\n",
            "Validation size: 775\n",
            "defaultdict(<function _default_unk_index at 0x7fee7f466620>, {'IND': 0, 'GRP': 1, 'OTH': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UTUbzJZBBBMr",
        "colab_type": "code",
        "outputId": "c6f10f1a-f690-4a7d-ddc8-89b8a970fea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6401
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.001\n",
        "out_channels = 512\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab,\n",
        "                              embedding_dim,\n",
        "                              window_size,\n",
        "                              out_channels,\n",
        "                              dropout,\n",
        "                              num_classes=3)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr, weight_decay=0.0054326444080709255)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1.6, 3.7, 8.4], device=device))\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_c',\n",
        "                                  model, optimizer,\n",
        "                                  loss_fn = loss_fn,\n",
        "                                  epochs = 20,\n",
        "                                  train_loader=train_iterator,\n",
        "                                  valid_loader=valid_iterator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 2.4391\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 496 / 775 correct (64.00)\n",
            "[[364  53  59]\n",
            " [ 54 105  48]\n",
            " [ 38  27  27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.76      0.78       476\n",
            "           1       0.57      0.51      0.54       207\n",
            "           2       0.20      0.29      0.24        92\n",
            "\n",
            "   micro avg       0.64      0.64      0.64       775\n",
            "   macro avg       0.52      0.52      0.52       775\n",
            "weighted avg       0.67      0.64      0.65       775\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 1.3008\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 522 / 775 correct (67.35)\n",
            "[[372  84  20]\n",
            " [ 52 139  16]\n",
            " [ 39  42  11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79       476\n",
            "           1       0.52      0.67      0.59       207\n",
            "           2       0.23      0.12      0.16        92\n",
            "\n",
            "   micro avg       0.67      0.67      0.67       775\n",
            "   macro avg       0.52      0.52      0.51       775\n",
            "weighted avg       0.66      0.67      0.66       775\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 0.9364\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 534 / 775 correct (68.90)\n",
            "[[394  59  23]\n",
            " [ 60 121  26]\n",
            " [ 43  30  19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.83      0.81       476\n",
            "           1       0.58      0.58      0.58       207\n",
            "           2       0.28      0.21      0.24        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.55      0.54      0.54       775\n",
            "weighted avg       0.67      0.69      0.68       775\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.7581\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 453 / 775 correct (58.45)\n",
            "[[316  38 122]\n",
            " [ 36  87  84]\n",
            " [ 27  15  50]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.66      0.74       476\n",
            "           1       0.62      0.42      0.50       207\n",
            "           2       0.20      0.54      0.29        92\n",
            "\n",
            "   micro avg       0.58      0.58      0.58       775\n",
            "   macro avg       0.55      0.54      0.51       775\n",
            "weighted avg       0.70      0.58      0.62       775\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.7221\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 533 / 775 correct (68.77)\n",
            "[[367 102   7]\n",
            " [ 40 161   6]\n",
            " [ 39  48   5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.77      0.80       476\n",
            "           1       0.52      0.78      0.62       207\n",
            "           2       0.28      0.05      0.09        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.54      0.53      0.50       775\n",
            "weighted avg       0.68      0.69      0.67       775\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.5669\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 536 / 775 correct (69.16)\n",
            "[[378  86  12]\n",
            " [ 47 151   9]\n",
            " [ 40  45   7]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.79      0.80       476\n",
            "           1       0.54      0.73      0.62       207\n",
            "           2       0.25      0.08      0.12        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.53      0.53      0.51       775\n",
            "weighted avg       0.67      0.69      0.67       775\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.5583\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 542 / 775 correct (69.94)\n",
            "[[381  74  21]\n",
            " [ 46 142  19]\n",
            " [ 39  34  19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81       476\n",
            "           1       0.57      0.69      0.62       207\n",
            "           2       0.32      0.21      0.25        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.57      0.56      0.56       775\n",
            "weighted avg       0.69      0.70      0.69       775\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.5531\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 547 / 775 correct (70.58)\n",
            "[[395  71  10]\n",
            " [ 57 145   5]\n",
            " [ 43  42   7]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.83      0.81       476\n",
            "           1       0.56      0.70      0.62       207\n",
            "           2       0.32      0.08      0.12        92\n",
            "\n",
            "   micro avg       0.71      0.71      0.71       775\n",
            "   macro avg       0.56      0.54      0.52       775\n",
            "weighted avg       0.68      0.71      0.68       775\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.5779\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 527 / 775 correct (68.00)\n",
            "[[371  63  42]\n",
            " [ 47 129  31]\n",
            " [ 36  29  27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.78      0.80       476\n",
            "           1       0.58      0.62      0.60       207\n",
            "           2       0.27      0.29      0.28        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.56      0.57      0.56       775\n",
            "weighted avg       0.69      0.68      0.68       775\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.6121\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 537 / 775 correct (69.29)\n",
            "[[386  58  32]\n",
            " [ 54 127  26]\n",
            " [ 38  30  24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81       476\n",
            "           1       0.59      0.61      0.60       207\n",
            "           2       0.29      0.26      0.28        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.56      0.56      0.56       775\n",
            "weighted avg       0.69      0.69      0.69       775\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.5067\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 544 / 775 correct (70.19)\n",
            "[[392  70  14]\n",
            " [ 58 142   7]\n",
            " [ 41  41  10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81       476\n",
            "           1       0.56      0.69      0.62       207\n",
            "           2       0.32      0.11      0.16        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.56      0.54      0.53       775\n",
            "weighted avg       0.68      0.70      0.68       775\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.5317\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 542 / 775 correct (69.94)\n",
            "[[388  76  12]\n",
            " [ 55 145   7]\n",
            " [ 40  43   9]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81       476\n",
            "           1       0.55      0.70      0.62       207\n",
            "           2       0.32      0.10      0.15        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.56      0.54      0.52       775\n",
            "weighted avg       0.68      0.70      0.68       775\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.4676\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 540 / 775 correct (69.68)\n",
            "[[370  79  27]\n",
            " [ 41 151  15]\n",
            " [ 35  38  19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.78      0.80       476\n",
            "           1       0.56      0.73      0.64       207\n",
            "           2       0.31      0.21      0.25        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.57      0.57      0.56       775\n",
            "weighted avg       0.70      0.70      0.69       775\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.5204\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 534 / 775 correct (68.90)\n",
            "[[365  81  30]\n",
            " [ 41 147  19]\n",
            " [ 34  36  22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.77      0.80       476\n",
            "           1       0.56      0.71      0.62       207\n",
            "           2       0.31      0.24      0.27        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.57      0.57      0.56       775\n",
            "weighted avg       0.70      0.69      0.69       775\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.5524\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 547 / 775 correct (70.58)\n",
            "[[387  76  13]\n",
            " [ 52 150   5]\n",
            " [ 38  44  10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81       476\n",
            "           1       0.56      0.72      0.63       207\n",
            "           2       0.36      0.11      0.17        92\n",
            "\n",
            "   micro avg       0.71      0.71      0.71       775\n",
            "   macro avg       0.57      0.55      0.54       775\n",
            "weighted avg       0.69      0.71      0.69       775\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.5114\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 541 / 775 correct (69.81)\n",
            "[[378  70  28]\n",
            " [ 49 139  19]\n",
            " [ 36  32  24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.79      0.81       476\n",
            "           1       0.58      0.67      0.62       207\n",
            "           2       0.34      0.26      0.29        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.58      0.58      0.57       775\n",
            "weighted avg       0.70      0.70      0.70       775\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.5272\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 540 / 775 correct (69.68)\n",
            "[[391  54  31]\n",
            " [ 61 123  23]\n",
            " [ 39  27  26]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81       476\n",
            "           1       0.60      0.59      0.60       207\n",
            "           2       0.33      0.28      0.30        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.57      0.57      0.57       775\n",
            "weighted avg       0.69      0.70      0.69       775\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.5495\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 535 / 775 correct (69.03)\n",
            "[[359  98  19]\n",
            " [ 38 164   5]\n",
            " [ 36  44  12]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.75      0.79       476\n",
            "           1       0.54      0.79      0.64       207\n",
            "           2       0.33      0.13      0.19        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.57      0.56      0.54       775\n",
            "weighted avg       0.69      0.69      0.68       775\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.5380\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 550 / 775 correct (70.97)\n",
            "[[385  68  23]\n",
            " [ 51 143  13]\n",
            " [ 36  34  22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.81      0.81       476\n",
            "           1       0.58      0.69      0.63       207\n",
            "           2       0.38      0.24      0.29        92\n",
            "\n",
            "   micro avg       0.71      0.71      0.71       775\n",
            "   macro avg       0.59      0.58      0.58       775\n",
            "weighted avg       0.70      0.71      0.70       775\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.4838\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 532 / 775 correct (68.65)\n",
            "[[379  51  46]\n",
            " [ 51 117  39]\n",
            " [ 32  24  36]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81       476\n",
            "           1       0.61      0.57      0.59       207\n",
            "           2       0.30      0.39      0.34        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.58      0.58      0.58       775\n",
            "weighted avg       0.70      0.69      0.69       775\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TSbEtokDP1Dy",
        "colab_type": "code",
        "outputId": "82b7e654-9297-491d-bba3-f7529b922380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkJ1R4WsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "zza6aQ1QnMyy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
        "embedding.weight.data.copy_(TEXT.vocab.vectors) # copies pre-trained word vectors\n",
        "\n",
        "embeddings, training_labels = transfrom_for_scikit('subtask_c', TEXT, LABEL, embedding, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qW-g6VVXgU-B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_embeddings, val_labels = transfrom_for_scikit('subtask_c', TEXT, LABEL, embedding, valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahOuuuoUpZlR",
        "colab_type": "code",
        "outputId": "1dfa8029-6b1b-4736-d726-83367fc7ec28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None, class_weight={0:1.6, 1:3.7, 2:8.4})\n",
        "\n",
        "clf.fit(embeddings, training_labels)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.001, average=False,\n",
              "       class_weight={0: 1.6, 1: 3.7, 2: 8.4}, early_stopping=False,\n",
              "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
              "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
              "       n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
              "       random_state=42, shuffle=True, tol=None, validation_fraction=0.1,\n",
              "       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "s_x8Fon_pfsY",
        "colab_type": "code",
        "outputId": "9badd8f1-c407-434a-e179-10569e8ba561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "preds = clf.predict(val_embeddings)\n",
        "\n",
        "print(metrics.confusion_matrix(val_labels, preds))\n",
        "print(metrics.classification_report(val_labels, preds))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(val_labels, preds))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[363  83  30]\n",
            " [ 57 122  28]\n",
            " [ 34  38  20]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.76      0.78       476\n",
            "           1       0.50      0.59      0.54       207\n",
            "           2       0.26      0.22      0.24        92\n",
            "\n",
            "   micro avg       0.65      0.65      0.65       775\n",
            "   macro avg       0.52      0.52      0.52       775\n",
            "weighted avg       0.66      0.65      0.65       775\n",
            "\n",
            "Accuracy: 0.6516129032258065\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}