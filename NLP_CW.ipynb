{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_CW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "xGMVF5KTg-He",
        "t9Zt3py7E1ep",
        "SClCUJp08-zn",
        "u7glEGKc-rNE"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adesam146/nlpcw/blob/rest_of_tasks/NLP_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_i_qSkEMxlkg"
      },
      "cell_type": "markdown",
      "source": [
        "## Check GPU memory"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5-XwNX-831V6",
        "outputId": "0969aea8-bb7c-435c-95ec-3bc7d5a47942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "cell_type": "code",
      "source": [
        "#Check GPU Memory allocation\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NOXcwqriwFsu",
        "outputId": "55a6f646-18f1-4d45-a770-8314a032a7fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.9 GB  | Proc size: 142.4 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ecWOCoFgxS_j",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#run this if GPU utilization is not 0%\n",
        "# !kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wTfeo8tcxhwC"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ePuqIHSPf554",
        "outputId": "bc5194d2-c1de-475d-db03-450c07c4a9f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1046
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U spacy ftfy torchtext\n",
        "  !python -m spacy download en"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/86/df789c5834f15ae1ca53a8d4c1fc4788676c2e32112f6a786f2625d9c6e6/ftfy-5.5.1-py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 4.9MB/s \n",
            "\u001b[?25hRequirement already up-to-date: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
            "Requirement already satisfied, skipping upgrade: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Collecting numpy>=1.15.0 (from spacy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 17.3MB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.9)\n",
            "Requirement already satisfied, skipping upgrade: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.0.1.post2)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Collecting wrapt<1.11.0,>=1.10.0 (from thinc<6.13.0,>=6.12.1->spacy)\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/47/66897906448185fcb77fc3c2b1bc20ed0ecca81a0f2f88eda3fc5a34fc3d/wrapt-1.10.11.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
            "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.11.29)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/48/5d/04/22361a593e70d23b1f7746d932802efe1f0e523376a74f321e\n",
            "Successfully built wrapt\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mpymc3 3.6 has requirement joblib<0.13.0, but you'll have joblib 0.13.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: ftfy, numpy, wrapt\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: wrapt 1.11.1\n",
            "    Uninstalling wrapt-1.11.1:\n",
            "      Successfully uninstalled wrapt-1.11.1\n",
            "Successfully installed ftfy-5.5.1 numpy-1.16.2 wrapt-1.10.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Srpq8hYt4whg",
        "outputId": "840f766a-5fb1-4e79-9e43-ca9ac5a5d3ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import sampler\n",
        "import spacy\n",
        "from torchtext import data\n",
        "from torchtext import datasets as nlp_dset\n",
        "import random\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "nlp_spaCy = spacy.load('en')\n",
        "\n",
        "GPU = True\n",
        "device_idx = 0\n",
        "if GPU:\n",
        "    device = torch.device(\"cuda:\"+str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "#Fix all seeds\n",
        "SEED = 0\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qtiwRhtm3s87",
        "outputId": "705cdc7e-076b-41bb-d131-a51d46d37ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "# Load datafiles from own google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_fp = \"\"\"/content/drive/My Drive/colab_data/offenseval-training-v1.tsv\"\"\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "t9Zt3py7E1ep"
      },
      "cell_type": "markdown",
      "source": [
        "## Import and preprocess Data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z9qQiPkQ3cna",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def downsample(train_df):\n",
        "  #ONLY USE THIS IF YOU WANT TO DOWNSAMPLE DATA - everything should work w/o this cell\n",
        "  #Select a subset of the data so that the classes are equally balanced\n",
        "  #Use downsampling for now. \n",
        "\n",
        "  num_NOT = 8840\n",
        "  num_OFF = 4400\n",
        "  # Separate majority and minority classes\n",
        "  df_majority = train_df[train_df[\"subtask_a\"] == 'NOT']\n",
        "  df_minority = train_df[train_df[\"subtask_a\"] == 'OFF']\n",
        "\n",
        "  # Downsample majority class\n",
        "  df_majority_downsampled = resample(df_majority, \n",
        "                                   replace=False,    # sample without replacement\n",
        "                                   n_samples=num_OFF,     # to match minority class\n",
        "                                   random_state=123) # reproducible results\n",
        "\n",
        "  # Combine minority class with downsampled majority class\n",
        "  df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "  # Display new class counts\n",
        "  print(df_downsampled.subtask_a.value_counts())\n",
        "\n",
        "  df_downsampled = df_downsampled.sample(frac=1) #shuffle df\n",
        "\n",
        "  return df_downsampled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aMY0mUyknLDu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tweet_preprocess(tweet_text):\n",
        "  \"\"\"Add tweet specific preprocessing steps here\"\"\"\n",
        "  \n",
        "  #Remove 'USER' (but leave '@')\n",
        "  tweet_text = tweet_text.replace(\"@USER\", \"@\") \n",
        "  \n",
        "  return tweet_text\n",
        "\n",
        "def convert_labels_A(labels):\n",
        "    \"\"\"Preproceses and return labels\"\"\"\n",
        "\n",
        "    final_labels = []\n",
        "    for label in labels:\n",
        "        assert label == \"OFF\" or label == \"NOT\", \"Label should not be: {}\".format(label)\n",
        "    \n",
        "        if label == \"OFF\":\n",
        "            res = 1\n",
        "        elif label == \"NOT\":\n",
        "            res = 0        \n",
        "        label = torch.tensor([res])\n",
        "        final_labels.append(label)\n",
        "    return final_labels\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "n1TwMNFOKRSm"
      },
      "cell_type": "markdown",
      "source": [
        "## Task A"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6NVQcb0MKUCh",
        "outputId": "4b9ab3d6-bd07-4df6-92d7-a8cb3babd067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "  # Use two GloVe trained on two different corpuses for comparison:\n",
        "    # Glove.6B\n",
        "    # glove.twitter.27B\n",
        "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip glove.twitter.27B.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-27 13:29:01--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
            "--2019-02-27 13:29:01--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  1.16MB/s    in 9m 24s  \n",
            "\n",
            "2019-02-27 13:38:26 (2.57 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n",
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bpNZ2KEwMOyM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenizer(text): # create a tokenizer function for gloVe\n",
        "    res = [tok.text for tok in nlp_spaCy.tokenizer(text)]\n",
        "    return res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WO69uqM3LtBS",
        "outputId": "f4e98a56-e6c3-43a3-d463-10ec238577b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a',LABEL),\n",
        "               ('subtask_b',LABEL),\n",
        "               ('subtask_c',LABEL)]\n",
        "\n",
        "\n",
        "train = data.TabularDataset(train_fp, format='TSV', fields = \n",
        "                            data_fields, skip_header=True, filter_pred=None)\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d') #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
        "\n",
        "LABEL.build_vocab(train.subtask_a)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)\n",
        "\n",
        "# For retrieving tweet text later on\n",
        "train_df = pd.read_csv(train_fp, delimiter=\"\\t\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 10592\n",
            "Validation size: 2648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1192807/1193514 [01:48<00:00, 10675.82it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KkGDZeI-rccB",
        "outputId": "c95f9697-eba1-4989-c241-a242c527835f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "print('first tweet', train[0].tweet)\n",
        "print('first label', train[0].subtask_a)\n",
        "print(\"first tweet id:\", train[0].id)\n",
        "# print(TEXT.vocab.stoi) # word to index\n",
        "# print(LABEL.vocab.stoi) # word to index\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first tweet ['@user', '@user', 'a', 'must', 'read', '!', 'url']\n",
            "first label NOT\n",
            "first tweet id: 29719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q9_NCwh3C1Z4",
        "outputId": "5512eff2-c8f5-4f31-e258-8ce37c77672b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#check loader\n",
        "for idx, batch in enumerate(train_iterator):\n",
        "    inputs, labels = batch.tweet, batch.subtask_a\n",
        "    print(inputs.shape)\n",
        "    print(labels.shape)\n",
        "    print(len(train_iterator))\n",
        "    break\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 1192807/1193514 [02:00<00:00, 10675.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 74])\n",
            "torch.Size([128])\n",
            "83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "k4UHz12y6L7m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "\n",
        "def check_accuracy(task_header, loader, model, conf=False):\n",
        "    \"\"\"\n",
        "    Note at the moment this function assumes the batch size is equal to the \n",
        "    number of data in the loader when calculating the confusion matrix\n",
        "    \"\"\"\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    \n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(loader):\n",
        "            x, y = batch.tweet, getattr(batch, task_header)\n",
        "            y = y.view(-1, 1)\n",
        "                \n",
        "            x = x.to(device=device, dtype=torch.long)  # move to  GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            \n",
        "            if task_header == 'subtask_c':\n",
        "              pred_prob = F.softmax(model(x), dim=1)\n",
        "              pred_1 = torch.argmax(pred_prob, dim=1).view(-1, 1)\n",
        "            else:\n",
        "              pred_prob = torch.sigmoid(model(x))\n",
        "              pred_1 = (pred_prob > 0.5).type(torch.long)\n",
        "              \n",
        "            num_correct += (pred_1 == y).sum()\n",
        "            num_samples += pred_prob.size(0)\n",
        "            \n",
        "            # move to CPU to prevent memory overflow and calculate metrics\n",
        "            x = x.to(device=\"cpu\", dtype=torch.long)\n",
        "            y = y.to(device=\"cpu\", dtype=torch.long).numpy()\n",
        "            pred_1 = pred_1.to(device=\"cpu\", dtype=torch.long).numpy()\n",
        "            \n",
        "            \n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "        if conf:\n",
        "            print(metrics.confusion_matrix(y, pred_1))\n",
        "            print(metrics.classification_report(y, pred_1))\n",
        "            \n",
        "def check_loss(task_header, loader, model, loss_fn):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    loss = 0\n",
        "    for idx, batch in enumerate(loader):\n",
        "      x, y = batch.tweet, getattr(batch, task_header)\n",
        "      \n",
        "      x = x.to(device=device, dtype=torch.long) \n",
        "      y = y.to(device=device, dtype=torch.long if task_header == 'subtask_c' else torch.float)\n",
        "      \n",
        "      logits = model(x)\n",
        "      \n",
        "      loss += loss_fn(logits, y.view(-1,) if isinstance(loss_fn, nn.CrossEntropyLoss) else y.view(-1, 1))\n",
        "      \n",
        "    return loss/len(loader)\n",
        "      \n",
        "\n",
        "def train_helper(task_header, model, optimizer, train_loader, \n",
        "               valid_loader, epochs=1, loss_fn=F.binary_cross_entropy_with_logits, print_every=50):\n",
        "    \"\"\"\n",
        "    Train a model\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to GPU\n",
        "    \n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "    try:\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:\", epoch)\n",
        "            total_loss = 0\n",
        "            for batch_idx, batch in enumerate(train_loader):\n",
        "\n",
        "                model.train()  # put model to training mode\n",
        "                \n",
        "                inputs, targets = batch.tweet, getattr(batch, task_header)\n",
        "                \n",
        "                x = inputs.to(device=device, dtype=torch.long)  # move to device, e.g. GPU\n",
        "                y = targets.to(device=device, dtype=torch.long if task_header == 'subtask_c' else torch.float) #this should be a float cross entropy\n",
        "                #x = inputs\n",
        "                #y = targets\n",
        "                logits = model(x)\n",
        "                \n",
        "                # When using cross_entropy the targets need to have a shape (N,)\n",
        "                # However, for BCEWithLogits they just need\n",
        "                # to have the same shape as the logits\n",
        "                loss = loss_fn(logits, y.view(-1,) if isinstance(loss_fn, nn.CrossEntropyLoss) else y.view(-1, 1))\n",
        "                # Zero out all of the gradients for the variables which the optimizer\n",
        "                # will update.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # This is the backwards pass: compute the gradient of the loss with\n",
        "                # respect to each  parameter of the model.\n",
        "                loss.backward()\n",
        "\n",
        "                # Actually update the parameters of the model using the gradients\n",
        "                # computed by the backwards pass.\n",
        "                optimizer.step()\n",
        "\n",
        "                x = x.to(device=\"cpu\", dtype=torch.long)  # move to CPU to prevent memory overflow\n",
        "                y = y.to(device=\"cpu\", dtype=torch.long)\n",
        "\n",
        "                total_loss += loss.detach().item()\n",
        "                \n",
        "                if batch_idx % print_every == 0:\n",
        "                    print('Iteration %d, loss = %.4f' % (batch_idx, loss.item()))\n",
        "            \n",
        "            training_losses.append(total_loss/len(train_iterator))\n",
        "            print()\n",
        "            print(\"Validation Accuracy:\")\n",
        "            check_accuracy(task_header, valid_loader, model, conf=True)\n",
        "            valid_loss = check_loss(task_header, valid_loader, model, loss_fn)\n",
        "            validation_losses.append(valid_loss)\n",
        "            print()\n",
        "        return training_losses, validation_losses\n",
        "    except Exception as e:\n",
        "        #Attempt to prevent GPU memory overflow by transferring model back to cpu\n",
        "        #model = model.to(device=\"cpu\")\n",
        "        raise e    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeisH53s6cfR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#embedding (lookup layer) layer\n",
        "class SimpleClassifierGloVe(nn.Module):\n",
        "    \"\"\"Glove w. 2d conv\"\"\"\n",
        "    \n",
        "    def __init__(self, vocab, embedding_dim, window_size, out_channels, dropout, num_classes=2):\n",
        "        \n",
        "        super(SimpleClassifierGloVe, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.vocab = vocab\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "        self.embedding.weight.data.copy_(vocab.vectors) # copies pre-trained word vectors\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(window_size, embedding_dim))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(out_channels, 1 if num_classes == 2 else num_classes)\n",
        "\n",
        "        #Kaming normalization\n",
        "        nn.init.kaiming_normal_(self.conv.weight)\n",
        "        nn.init.kaiming_normal_(self.fc.weight)\n",
        "\n",
        "        \n",
        "        \n",
        "    def forward(self, x, ):\n",
        "        \n",
        "        embedded = self.embedding(x)\n",
        "                \n",
        "        #(batch size, max sent length, embedding dim)\n",
        "        \n",
        "        #images have 3 RGB channels \n",
        "        #for the text we add 1 channel\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #(batch size, 1, max sent length, embedding dim)\n",
        "        \n",
        "        feature_maps =  F.relu(self.conv(embedded).squeeze(3))\n",
        "        # (batch size, out_channels, max sent length - window size +1, 1)\n",
        "        # -> (batch size, out_channels, max sent length - window size +1)\n",
        "           \n",
        "        #the max pooling layer\n",
        "        pooled = F.max_pool1d(feature_maps, feature_maps.shape[2]).squeeze(2)\n",
        "        # (batch size, out_channels)      \n",
        "        \n",
        "        # Do batch normalize pooled then at sentiment\n",
        "        \n",
        "        return self.fc( self.dropout(pooled))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "X9LseL5F9n7P",
        "outputId": "926e17f7-86cd-4e9d-9b26-c795de64e4db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6065
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab, embedding_dim, window_size, out_channels, dropout)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_a', model, optimizer, loss_fn = loss_fn, epochs = 20, train_loader=train_iterator, valid_loader=valid_iterator)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 0.9912\n",
            "Iteration 50, loss = 0.8042\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1817 / 2648 correct (68.62)\n",
            "[[1733   40]\n",
            " [ 791   84]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.98      0.81      1773\n",
            "           1       0.68      0.10      0.17       875\n",
            "\n",
            "   micro avg       0.69      0.69      0.69      2648\n",
            "   macro avg       0.68      0.54      0.49      2648\n",
            "weighted avg       0.68      0.69      0.60      2648\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 0.7402\n",
            "Iteration 50, loss = 0.6156\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1861 / 2648 correct (70.28)\n",
            "[[1726   47]\n",
            " [ 740  135]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.97      0.81      1773\n",
            "           1       0.74      0.15      0.26       875\n",
            "\n",
            "   micro avg       0.70      0.70      0.70      2648\n",
            "   macro avg       0.72      0.56      0.53      2648\n",
            "weighted avg       0.71      0.70      0.63      2648\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 0.6030\n",
            "Iteration 50, loss = 0.5625\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1910 / 2648 correct (72.13)\n",
            "[[1710   63]\n",
            " [ 675  200]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.96      0.82      1773\n",
            "           1       0.76      0.23      0.35       875\n",
            "\n",
            "   micro avg       0.72      0.72      0.72      2648\n",
            "   macro avg       0.74      0.60      0.59      2648\n",
            "weighted avg       0.73      0.72      0.67      2648\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.5908\n",
            "Iteration 50, loss = 0.6883\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1978 / 2648 correct (74.70)\n",
            "[[1658  115]\n",
            " [ 555  320]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.94      0.83      1773\n",
            "           1       0.74      0.37      0.49       875\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2648\n",
            "   macro avg       0.74      0.65      0.66      2648\n",
            "weighted avg       0.74      0.75      0.72      2648\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.5115\n",
            "Iteration 50, loss = 0.5996\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2016 / 2648 correct (76.13)\n",
            "[[1644  129]\n",
            " [ 503  372]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.93      0.84      1773\n",
            "           1       0.74      0.43      0.54       875\n",
            "\n",
            "   micro avg       0.76      0.76      0.76      2648\n",
            "   macro avg       0.75      0.68      0.69      2648\n",
            "weighted avg       0.76      0.76      0.74      2648\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.5023\n",
            "Iteration 50, loss = 0.4624\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2048 / 2648 correct (77.34)\n",
            "[[1622  151]\n",
            " [ 449  426]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.91      0.84      1773\n",
            "           1       0.74      0.49      0.59       875\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2648\n",
            "   macro avg       0.76      0.70      0.72      2648\n",
            "weighted avg       0.77      0.77      0.76      2648\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.5102\n",
            "Iteration 50, loss = 0.4917\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2059 / 2648 correct (77.76)\n",
            "[[1625  148]\n",
            " [ 441  434]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85      1773\n",
            "           1       0.75      0.50      0.60       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.77      0.71      0.72      2648\n",
            "weighted avg       0.77      0.78      0.76      2648\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.4321\n",
            "Iteration 50, loss = 0.4088\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2076 / 2648 correct (78.40)\n",
            "[[1600  173]\n",
            " [ 399  476]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.90      0.85      1773\n",
            "           1       0.73      0.54      0.62       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.77      0.72      0.74      2648\n",
            "weighted avg       0.78      0.78      0.77      2648\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.3355\n",
            "Iteration 50, loss = 0.4001\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2073 / 2648 correct (78.29)\n",
            "[[1637  136]\n",
            " [ 439  436]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85      1773\n",
            "           1       0.76      0.50      0.60       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.78      0.71      0.73      2648\n",
            "weighted avg       0.78      0.78      0.77      2648\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.3473\n",
            "Iteration 50, loss = 0.3881\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2082 / 2648 correct (78.63)\n",
            "[[1628  145]\n",
            " [ 421  454]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85      1773\n",
            "           1       0.76      0.52      0.62       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.78      0.72      0.73      2648\n",
            "weighted avg       0.78      0.79      0.77      2648\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.3242\n",
            "Iteration 50, loss = 0.3761\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2093 / 2648 correct (79.04)\n",
            "[[1610  163]\n",
            " [ 392  483]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85      1773\n",
            "           1       0.75      0.55      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.78      0.73      0.74      2648\n",
            "weighted avg       0.79      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.3277\n",
            "Iteration 50, loss = 0.3389\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2097 / 2648 correct (79.19)\n",
            "[[1610  163]\n",
            " [ 388  487]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.85      1773\n",
            "           1       0.75      0.56      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.78      0.73      0.75      2648\n",
            "weighted avg       0.79      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.3090\n",
            "Iteration 50, loss = 0.2953\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2100 / 2648 correct (79.31)\n",
            "[[1614  159]\n",
            " [ 389  486]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.85      1773\n",
            "           1       0.75      0.56      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.78      0.73      0.75      2648\n",
            "weighted avg       0.79      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.3422\n",
            "Iteration 50, loss = 0.3210\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2098 / 2648 correct (79.23)\n",
            "[[1586  187]\n",
            " [ 363  512]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85      1773\n",
            "           1       0.73      0.59      0.65       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.79      0.79      0.79      2648\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.3688\n",
            "Iteration 50, loss = 0.2929\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2098 / 2648 correct (79.23)\n",
            "[[1595  178]\n",
            " [ 372  503]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.74      0.57      0.65       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.79      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.2418\n",
            "Iteration 50, loss = 0.2865\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2099 / 2648 correct (79.27)\n",
            "[[1577  196]\n",
            " [ 353  522]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85      1773\n",
            "           1       0.73      0.60      0.66       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.79      0.79      0.79      2648\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.2422\n",
            "Iteration 50, loss = 0.2188\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2096 / 2648 correct (79.15)\n",
            "[[1580  193]\n",
            " [ 359  516]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85      1773\n",
            "           1       0.73      0.59      0.65       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.79      0.79      0.79      2648\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.2633\n",
            "Iteration 50, loss = 0.2825\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2103 / 2648 correct (79.42)\n",
            "[[1612  161]\n",
            " [ 384  491]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.86      1773\n",
            "           1       0.75      0.56      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.78      0.74      0.75      2648\n",
            "weighted avg       0.79      0.79      0.79      2648\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.2199\n",
            "Iteration 50, loss = 0.2575\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2095 / 2648 correct (79.12)\n",
            "[[1587  186]\n",
            " [ 367  508]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.73      0.58      0.65       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.79      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.2430\n",
            "Iteration 50, loss = 0.2121\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2086 / 2648 correct (78.78)\n",
            "[[1570  203]\n",
            " [ 359  516]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85      1773\n",
            "           1       0.72      0.59      0.65       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_q8EEjwwLf3",
        "colab_type": "code",
        "outputId": "d52b34bd-574d-486d-d8b9-fab68fdc8e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "  ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "VFiG4aRQPpN5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task B"
      ]
    },
    {
      "metadata": {
        "id": "2YbsX0DyP1B0",
        "colab_type": "code",
        "outputId": "57ea7581-3851-4a62-a11e-6552db46120e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a', LABEL),\n",
        "               ('subtask_b',LABEL)\n",
        "              ]\n",
        "\n",
        "train = data.TabularDataset(train_fp, format='TSV', fields = \n",
        "                            data_fields, skip_header=True, filter_pred=lambda d: d.subtask_a == 'OFF')\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "# This is where tokenization is performed on train\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d') #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
        "\n",
        "LABEL.build_vocab(train.subtask_b)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "print(LABEL.vocab.stoi)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 3520\n",
            "Validation size: 880\n",
            "defaultdict(<function _default_unk_index at 0x7f902694c2f0>, {'TIN': 0, 'UNT': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uww_bdubSnf3",
        "colab_type": "code",
        "outputId": "e670beb7-b866-4d5e-9e5e-943d79fbff98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5782
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab, embedding_dim, window_size, out_channels, dropout)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_b', model, optimizer, loss_fn = loss_fn, epochs = 20, train_loader=train_iterator, valid_loader=valid_iterator)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 0.8511\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "[[768   0]\n",
            " [112   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 0.5818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "[[768   0]\n",
            " [112   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 0.4405\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 767 / 880 correct (87.16)\n",
            "[[766   2]\n",
            " [111   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.33      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.60      0.50      0.47       880\n",
            "weighted avg       0.80      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.2660\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[766   2]\n",
            " [109   3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.60      0.03      0.05       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.74      0.51      0.49       880\n",
            "weighted avg       0.84      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.3367\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.3301\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.4049\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.2809\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.3704\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.3494\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.2880\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.2973\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[766   2]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.67      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.77      0.52      0.50       880\n",
            "weighted avg       0.85      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.2461\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 771 / 880 correct (87.61)\n",
            "[[767   1]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.80      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.84      0.52      0.50       880\n",
            "weighted avg       0.87      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.1750\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 771 / 880 correct (87.61)\n",
            "[[766   2]\n",
            " [107   5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.71      0.04      0.08       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.80      0.52      0.51       880\n",
            "weighted avg       0.86      0.88      0.83       880\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.2645\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 772 / 880 correct (87.73)\n",
            "[[766   2]\n",
            " [106   6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.75      0.05      0.10       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.81      0.53      0.52       880\n",
            "weighted avg       0.86      0.88      0.83       880\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.3000\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 771 / 880 correct (87.61)\n",
            "[[767   1]\n",
            " [108   4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.80      0.04      0.07       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.84      0.52      0.50       880\n",
            "weighted avg       0.87      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.2369\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 772 / 880 correct (87.73)\n",
            "[[766   2]\n",
            " [106   6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.75      0.05      0.10       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.81      0.53      0.52       880\n",
            "weighted avg       0.86      0.88      0.83       880\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.2519\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 772 / 880 correct (87.73)\n",
            "[[766   2]\n",
            " [106   6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.75      0.05      0.10       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.81      0.53      0.52       880\n",
            "weighted avg       0.86      0.88      0.83       880\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.1988\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 773 / 880 correct (87.84)\n",
            "[[766   2]\n",
            " [105   7]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.78      0.06      0.12       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.83      0.53      0.53       880\n",
            "weighted avg       0.87      0.88      0.83       880\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.2493\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 773 / 880 correct (87.84)\n",
            "[[766   2]\n",
            " [105   7]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93       768\n",
            "           1       0.78      0.06      0.12       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.83      0.53      0.53       880\n",
            "weighted avg       0.87      0.88      0.83       880\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AiLub0TBVF_i",
        "colab_type": "code",
        "outputId": "1d58abf9-f48b-4fe2-f55a-1a006af8d218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVA80AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HzDUdTT8Agxo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task C"
      ]
    },
    {
      "metadata": {
        "id": "Wf47-PIDAlIw",
        "colab_type": "code",
        "outputId": "42d3c987-18c8-46b1-c0d3-9446fb2c4aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a', LABEL),\n",
        "               ('subtask_b',LABEL),\n",
        "               ('subtask_c', LABEL)\n",
        "              ]\n",
        "\n",
        "train = data.TabularDataset(train_fp, format='TSV', fields = \n",
        "                            data_fields, skip_header=True, filter_pred=lambda d: d.subtask_a == 'OFF' and d.subtask_b == 'TIN')\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d') #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
        "\n",
        "LABEL.build_vocab(train.subtask_c)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "print(LABEL.vocab.stoi)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 3101\n",
            "Validation size: 775\n",
            "defaultdict(<function _default_unk_index at 0x7f902694c2f0>, {'IND': 0, 'GRP': 1, 'OTH': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tRQmlBhS69_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad4aa338-8f54-4ba7-da3c-7ad9f38c4126"
      },
      "cell_type": "code",
      "source": [
        "train[0]"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torchtext.data.example.Example at 0x7f9021de7048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "metadata": {
        "id": "UTUbzJZBBBMr",
        "colab_type": "code",
        "outputId": "616c9a05-24ff-4d02-ba0d-3de3bfff778b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6454
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab, embedding_dim, window_size, out_channels, dropout, num_classes=3)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_c', model, optimizer, loss_fn = loss_fn, epochs = 20, train_loader=train_iterator, valid_loader=valid_iterator)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 1.8077\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 471 / 775 correct (60.77)\n",
            "[[467   9   0]\n",
            " [203   4   0]\n",
            " [ 90   2   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.98      0.76       476\n",
            "           1       0.27      0.02      0.04       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.61      0.61      0.61       775\n",
            "   macro avg       0.29      0.33      0.26       775\n",
            "weighted avg       0.45      0.61      0.47       775\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 1.1325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Accuracy:\n",
            "Got 483 / 775 correct (62.32)\n",
            "[[463  13   0]\n",
            " [187  20   0]\n",
            " [ 85   7   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.97      0.76       476\n",
            "           1       0.50      0.10      0.16       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.62      0.62      0.62       775\n",
            "   macro avg       0.38      0.36      0.31       775\n",
            "weighted avg       0.52      0.62      0.51       775\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 1.2046\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 498 / 775 correct (64.26)\n",
            "[[448  28   0]\n",
            " [157  50   0]\n",
            " [ 79  13   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.94      0.77       476\n",
            "           1       0.55      0.24      0.34       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.64      0.64      0.64       775\n",
            "   macro avg       0.40      0.39      0.37       775\n",
            "weighted avg       0.55      0.64      0.56       775\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.9665\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 510 / 775 correct (65.81)\n",
            "[[450  26   0]\n",
            " [147  60   0]\n",
            " [ 76  16   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.95      0.78       476\n",
            "           1       0.59      0.29      0.39       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.66      0.66      0.66       775\n",
            "   macro avg       0.42      0.41      0.39       775\n",
            "weighted avg       0.57      0.66      0.58       775\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.9172\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 522 / 775 correct (67.35)\n",
            "[[446  30   0]\n",
            " [131  76   0]\n",
            " [ 73  19   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.94      0.79       476\n",
            "           1       0.61      0.37      0.46       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.67      0.67      0.67       775\n",
            "   macro avg       0.43      0.43      0.42       775\n",
            "weighted avg       0.58      0.67      0.61       775\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.7127\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 526 / 775 correct (67.87)\n",
            "[[439  37   0]\n",
            " [120  87   0]\n",
            " [ 70  22   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.92      0.79       476\n",
            "           1       0.60      0.42      0.49       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.43      0.45      0.43       775\n",
            "weighted avg       0.59      0.68      0.62       775\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 1.0162\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 526 / 775 correct (67.87)\n",
            "[[434  42   0]\n",
            " [115  92   0]\n",
            " [ 64  28   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.91      0.80       476\n",
            "           1       0.57      0.44      0.50       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.43      0.45      0.43       775\n",
            "weighted avg       0.59      0.68      0.62       775\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.7607\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 531 / 775 correct (68.52)\n",
            "[[435  41   0]\n",
            " [111  96   0]\n",
            " [ 63  29   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.91      0.80       476\n",
            "           1       0.58      0.46      0.51       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.43      0.46      0.44       775\n",
            "weighted avg       0.59      0.69      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.7989\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 531 / 775 correct (68.52)\n",
            "[[436  40   0]\n",
            " [112  95   0]\n",
            " [ 66  26   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.92      0.80       476\n",
            "           1       0.59      0.46      0.52       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.43      0.46      0.44       775\n",
            "weighted avg       0.59      0.69      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.7282\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 534 / 775 correct (68.90)\n",
            "[[435  41   0]\n",
            " [108  99   0]\n",
            " [ 61  31   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.91      0.81       476\n",
            "           1       0.58      0.48      0.52       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.43      0.46      0.44       775\n",
            "weighted avg       0.60      0.69      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.7055\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 537 / 775 correct (69.29)\n",
            "[[432  44   0]\n",
            " [102 105   0]\n",
            " [ 57  35   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.91      0.81       476\n",
            "           1       0.57      0.51      0.54       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.43      0.47      0.45       775\n",
            "weighted avg       0.60      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.6359\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 536 / 775 correct (69.16)\n",
            "[[431  44   1]\n",
            " [102 105   0]\n",
            " [ 60  32   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.91      0.81       476\n",
            "           1       0.58      0.51      0.54       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.44      0.47      0.45       775\n",
            "weighted avg       0.60      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.6601\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 536 / 775 correct (69.16)\n",
            "[[427  48   1]\n",
            " [ 98 109   0]\n",
            " [ 58  34   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.90      0.81       476\n",
            "           1       0.57      0.53      0.55       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.43      0.47      0.45       775\n",
            "weighted avg       0.60      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.6562\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 541 / 775 correct (69.81)\n",
            "[[432  43   1]\n",
            " [ 98 109   0]\n",
            " [ 58  34   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.91      0.81       476\n",
            "           1       0.59      0.53      0.55       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.44      0.48      0.46       775\n",
            "weighted avg       0.61      0.70      0.65       775\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.5233\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 541 / 775 correct (69.81)\n",
            "[[430  45   1]\n",
            " [ 96 111   0]\n",
            " [ 57  35   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.90      0.81       476\n",
            "           1       0.58      0.54      0.56       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.44      0.48      0.46       775\n",
            "weighted avg       0.61      0.70      0.65       775\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.6025\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 540 / 775 correct (69.68)\n",
            "[[427  48   1]\n",
            " [ 94 113   0]\n",
            " [ 56  36   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.90      0.81       476\n",
            "           1       0.57      0.55      0.56       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.44      0.48      0.46       775\n",
            "weighted avg       0.61      0.70      0.65       775\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.6448\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 542 / 775 correct (69.94)\n",
            "[[426  49   1]\n",
            " [ 91 116   0]\n",
            " [ 56  36   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.89      0.81       476\n",
            "           1       0.58      0.56      0.57       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.44      0.49      0.46       775\n",
            "weighted avg       0.61      0.70      0.65       775\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.6055\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 543 / 775 correct (70.06)\n",
            "[[428  47   1]\n",
            " [ 92 115   0]\n",
            " [ 57  35   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.90      0.81       476\n",
            "           1       0.58      0.56      0.57       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.44      0.48      0.46       775\n",
            "weighted avg       0.61      0.70      0.65       775\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.6314\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 545 / 775 correct (70.32)\n",
            "[[429  46   1]\n",
            " [ 91 116   0]\n",
            " [ 57  35   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.90      0.81       476\n",
            "           1       0.59      0.56      0.57       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.44      0.49      0.46       775\n",
            "weighted avg       0.61      0.70      0.65       775\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.4427\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 544 / 775 correct (70.19)\n",
            "[[425  50   1]\n",
            " [ 88 119   0]\n",
            " [ 56  36   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.89      0.81       476\n",
            "           1       0.58      0.57      0.58       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       775\n",
            "   macro avg       0.44      0.49      0.46       775\n",
            "weighted avg       0.61      0.70      0.65       775\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TSbEtokDP1Dy",
        "colab_type": "code",
        "outputId": "8909cf6d-e85f-4388-8492-53665dc23345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "zza6aQ1QnMyy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
        "embedding.weight.data.copy_(TEXT.vocab.vectors) # copies pre-trained word vectors\n",
        "# tokenised_train = [example.tweet for example in train]\n",
        "# print(len(tokenised_train[0]), len(tokenised_train[1]))\n",
        "# word_idxs = TEXT.numericalize(tokenised_train)\n",
        "\n",
        "def transfrom(task_header, loader, embedding):\n",
        "  \"\"\"\n",
        "  ASSUMES LOADER IN CPU\n",
        "  \"\"\"\n",
        "  embeddings = None\n",
        "  labels = None\n",
        "  \n",
        "  for idx, batch in enumerate(loader):\n",
        "    # Doing averaging to get sentence embedding\n",
        "    if idx == 0:\n",
        "      embeddings = torch.mean(embedding(batch.tweet).detach(), dim=1)\n",
        "      #TODO: make more generic\n",
        "      labels = getattr(batch, task_header)\n",
        "    else:\n",
        "      new_batch = torch.mean(embedding(batch.tweet).detach(), dim=1)\n",
        "      embeddings = torch.cat((embeddings, new_batch), dim=0)\n",
        "\n",
        "      labels = torch.cat((labels, getattr(batch, task_header)), dim=0)\n",
        "  \n",
        "  return embeddings.numpy(), labels.numpy()\n",
        "\n",
        "embeddings, training_labels = transfrom('subtask_c', train_iterator, embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahOuuuoUpZlR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d481cb89-e1d1-4a10-dd2c-5bbc158874b5"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# clf = svm.SVC()\n",
        "# clf = SGDClassifier(loss='hinge', penalty='l1',\n",
        "#                           alpha=1e-3, random_state=42,\n",
        "#                           max_iter=5, tol=None, class_weight={2.0: 1})\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# The decision trees have max_depth 1\n",
        "clf = AdaBoostClassifier(n_estimators=1000)\n",
        "\n",
        "clf.fit(embeddings, training_labels)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
              "          learning_rate=1.0, n_estimators=1000, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "metadata": {
        "id": "s_x8Fon_pfsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "b8065119-c907-4104-e865-e0409cc81ae5"
      },
      "cell_type": "code",
      "source": [
        "val_embeddings, val_labels = transfrom('subtask_c', valid_iterator, embedding=embedding)\n",
        "\n",
        "preds = clf.predict(val_embeddings)\n",
        "\n",
        "print(metrics.confusion_matrix(val_labels, preds))\n",
        "print(metrics.classification_report(val_labels, preds))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(val_labels, preds))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[411  57   8]\n",
            " [ 92 103  12]\n",
            " [ 54  32   6]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.86      0.80       476\n",
            "           1       0.54      0.50      0.52       207\n",
            "           2       0.23      0.07      0.10        92\n",
            "\n",
            "   micro avg       0.67      0.67      0.67       775\n",
            "   macro avg       0.50      0.48      0.47       775\n",
            "weighted avg       0.62      0.67      0.64       775\n",
            "\n",
            "Accuracy: 0.6709677419354839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PFtMdQrS-XFY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}