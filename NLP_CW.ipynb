{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_CW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "xGMVF5KTg-He",
        "t9Zt3py7E1ep",
        "SClCUJp08-zn",
        "u7glEGKc-rNE"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adesam146/nlpcw/blob/rest_of_tasks/NLP_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_i_qSkEMxlkg"
      },
      "cell_type": "markdown",
      "source": [
        "## Check GPU memory"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5-XwNX-831V6",
        "outputId": "0969aea8-bb7c-435c-95ec-3bc7d5a47942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "cell_type": "code",
      "source": [
        "#Check GPU Memory allocation\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NOXcwqriwFsu",
        "outputId": "55a6f646-18f1-4d45-a770-8314a032a7fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.9 GB  | Proc size: 142.4 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ecWOCoFgxS_j",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#run this if GPU utilization is not 0%\n",
        "# !kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wTfeo8tcxhwC"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ePuqIHSPf554",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U spacy ftfy torchtext\n",
        "!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Srpq8hYt4whg",
        "outputId": "346eaf49-fef5-4f96-d7b6-f0721656222a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import sampler\n",
        "import spacy\n",
        "from torchtext import data\n",
        "from torchtext import datasets as nlp_dset\n",
        "import random\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "nlp_spaCy = spacy.load('en')\n",
        "\n",
        "GPU = True\n",
        "device_idx = 0\n",
        "if GPU:\n",
        "    device = torch.device(\"cuda:\"+str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "#Fix all seeds\n",
        "SEED = 0\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qtiwRhtm3s87",
        "outputId": "612d98e8-c073-47e5-cc3b-320d2b648c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "# Load datafiles from own google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_fp = \"\"\"/content/drive/My Drive/colab_data/offenseval-training-v1.tsv\"\"\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X3kA7Y0BjUnF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use two GloVe trained on two different corpuses for comparison:\n",
        "  # Glove.6B\n",
        "  # glove.twitter.27B\n",
        "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip glove.twitter.27B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "t9Zt3py7E1ep"
      },
      "cell_type": "markdown",
      "source": [
        "## Import and preprocess Data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z9qQiPkQ3cna",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def downsample(train_df):\n",
        "  #ONLY USE THIS IF YOU WANT TO DOWNSAMPLE DATA - everything should work w/o this cell\n",
        "  #Select a subset of the data so that the classes are equally balanced\n",
        "  #Use downsampling for now. \n",
        "\n",
        "  num_NOT = 8840\n",
        "  num_OFF = 4400\n",
        "  # Separate majority and minority classes\n",
        "  df_majority = train_df[train_df[\"subtask_a\"] == 'NOT']\n",
        "  df_minority = train_df[train_df[\"subtask_a\"] == 'OFF']\n",
        "\n",
        "  # Downsample majority class\n",
        "  df_majority_downsampled = resample(df_majority, \n",
        "                                   replace=False,    # sample without replacement\n",
        "                                   n_samples=num_OFF,     # to match minority class\n",
        "                                   random_state=123) # reproducible results\n",
        "\n",
        "  # Combine minority class with downsampled majority class\n",
        "  df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        "\n",
        "  # Display new class counts\n",
        "  print(df_downsampled.subtask_a.value_counts())\n",
        "\n",
        "  df_downsampled = df_downsampled.sample(frac=1) #shuffle df\n",
        "\n",
        "  return df_downsampled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aMY0mUyknLDu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tweet_preprocess(tweet_text):\n",
        "  \"\"\"Add tweet specific preprocessing steps here\"\"\"\n",
        "  \n",
        "  #Remove 'USER' (but leave '@')\n",
        "  tweet_text = tweet_text.replace(\"@USER\", \"@\") \n",
        "  \n",
        "  return tweet_text\n",
        "\n",
        "def convert_labels_A(labels):\n",
        "    \"\"\"Preproceses and return labels\"\"\"\n",
        "\n",
        "    final_labels = []\n",
        "    for label in labels:\n",
        "        assert label == \"OFF\" or label == \"NOT\", \"Label should not be: {}\".format(label)\n",
        "    \n",
        "        if label == \"OFF\":\n",
        "            res = 1\n",
        "        elif label == \"NOT\":\n",
        "            res = 0        \n",
        "        label = torch.tensor([res])\n",
        "        final_labels.append(label)\n",
        "    return final_labels\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "imjsxr66hDWP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def transfrom_for_scikit(task_header, text_field, label_field, embedding, train):\n",
        "  \"\"\"\n",
        "  task_header is one of subtask_a, subtask_b, subtask_c\n",
        "  \"\"\"\n",
        "  tokenised_train = [example.tweet for example in train]\n",
        "  labels = np.array(\n",
        "      label_field.process(\n",
        "          [getattr(example, task_header) for example in train]\n",
        "      )\n",
        "  )\n",
        "  \n",
        "  word_idxs = text_field.process(tokenised_train)\n",
        "  embeddings = torch.mean(embedding(word_idxs).detach(), dim=1)\n",
        "  \n",
        "  return embeddings.numpy(), labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuWD9loshx_X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Utils Functions For Neural Network Classifer"
      ]
    },
    {
      "metadata": {
        "id": "DpSLEwoMjDdv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenizer(text): # create a tokenizer function for gloVe\n",
        "    res = [tok.text for tok in nlp_spaCy.tokenizer(text)]\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C8q-_NUtiT8n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def check_accuracy(task_header, loader, model, conf=False):\n",
        "    \"\"\"\n",
        "    Note at the moment this function assumes the batch size is equal to the \n",
        "    number of data in the loader when calculating the confusion matrix\n",
        "    \"\"\"\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    \n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(loader):\n",
        "            x, y = batch.tweet, getattr(batch, task_header)\n",
        "            y = y.view(-1, 1)\n",
        "                \n",
        "            x = x.to(device=device, dtype=torch.long)  # move to  GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            \n",
        "            if task_header == 'subtask_c':\n",
        "              pred_prob = F.softmax(model(x), dim=1)\n",
        "              pred_1 = torch.argmax(pred_prob, dim=1).view(-1, 1)\n",
        "            else:\n",
        "              pred_prob = torch.sigmoid(model(x))\n",
        "              pred_1 = (pred_prob > 0.5).type(torch.long)\n",
        "              \n",
        "            num_correct += (pred_1 == y).sum()\n",
        "            num_samples += pred_prob.size(0)\n",
        "            \n",
        "            # move to CPU to prevent memory overflow and calculate metrics\n",
        "            x = x.to(device=\"cpu\", dtype=torch.long)\n",
        "            y = y.to(device=\"cpu\", dtype=torch.long).numpy()\n",
        "            pred_1 = pred_1.to(device=\"cpu\", dtype=torch.long).numpy()\n",
        "            \n",
        "            \n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "        if conf:\n",
        "            print(metrics.confusion_matrix(y, pred_1))\n",
        "            print(metrics.classification_report(y, pred_1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oXFOMchMitEY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def check_loss(task_header, loader, model, loss_fn):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    loss = 0\n",
        "    for idx, batch in enumerate(loader):\n",
        "      x, y = batch.tweet, getattr(batch, task_header)\n",
        "      \n",
        "      x = x.to(device=device, dtype=torch.long) \n",
        "      y = y.to(device=device, dtype=torch.long if task_header == 'subtask_c' else torch.float)\n",
        "      \n",
        "      logits = model(x)\n",
        "      \n",
        "      loss += loss_fn(logits, y.view(-1,) if isinstance(loss_fn, nn.CrossEntropyLoss) else y.view(-1, 1))\n",
        "      \n",
        "    return loss/len(loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YurUJzZji6Rq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_helper(task_header, model, optimizer, train_loader, \n",
        "               valid_loader, epochs=1, loss_fn=F.binary_cross_entropy_with_logits, print_every=50):\n",
        "    \"\"\"\n",
        "    Train a model\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to GPU\n",
        "    \n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "    try:\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:\", epoch)\n",
        "            total_loss = 0\n",
        "            for batch_idx, batch in enumerate(train_loader):\n",
        "\n",
        "                model.train()  # put model to training mode\n",
        "                \n",
        "                inputs, targets = batch.tweet, getattr(batch, task_header)\n",
        "                \n",
        "                x = inputs.to(device=device, dtype=torch.long)  # move to device, e.g. GPU\n",
        "                y = targets.to(device=device, dtype=torch.long if task_header == 'subtask_c' else torch.float) #this should be a float cross entropy\n",
        "                #x = inputs\n",
        "                #y = targets\n",
        "                logits = model(x)\n",
        "                \n",
        "                # When using cross_entropy the targets need to have a shape (N,)\n",
        "                # However, for BCEWithLogits they just need\n",
        "                # to have the same shape as the logits\n",
        "                loss = loss_fn(logits, y.view(-1,) if isinstance(loss_fn, nn.CrossEntropyLoss) else y.view(-1, 1))\n",
        "                # Zero out all of the gradients for the variables which the optimizer\n",
        "                # will update.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # This is the backwards pass: compute the gradient of the loss with\n",
        "                # respect to each  parameter of the model.\n",
        "                loss.backward()\n",
        "\n",
        "                # Actually update the parameters of the model using the gradients\n",
        "                # computed by the backwards pass.\n",
        "                optimizer.step()\n",
        "\n",
        "                x = x.to(device=\"cpu\", dtype=torch.long)  # move to CPU to prevent memory overflow\n",
        "                y = y.to(device=\"cpu\", dtype=torch.long)\n",
        "\n",
        "                total_loss += loss.detach().item()\n",
        "                \n",
        "                if batch_idx % print_every == 0:\n",
        "                    print('Iteration %d, loss = %.4f' % (batch_idx, loss.item()))\n",
        "            \n",
        "            training_losses.append(total_loss/len(train_iterator))\n",
        "            print()\n",
        "            print(\"Validation Accuracy:\")\n",
        "            check_accuracy(task_header, valid_loader, model, conf=True)\n",
        "            valid_loss = check_loss(task_header, valid_loader, model, loss_fn)\n",
        "            validation_losses.append(valid_loss)\n",
        "            print()\n",
        "        return training_losses, validation_losses\n",
        "    except Exception as e:\n",
        "        #Attempt to prevent GPU memory overflow by transferring model back to cpu\n",
        "        #model = model.to(device=\"cpu\")\n",
        "        raise e    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tl9IC4d1jx-0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network Classifiers"
      ]
    },
    {
      "metadata": {
        "id": "yuwrip1gj43k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#embedding (lookup layer) layer\n",
        "class SimpleClassifierGloVe(nn.Module):\n",
        "    \"\"\"Glove w. 2d conv\"\"\"\n",
        "    \n",
        "    def __init__(self, vocab, embedding_dim, window_size, out_channels, dropout, num_classes=2):\n",
        "        \n",
        "        super(SimpleClassifierGloVe, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.vocab = vocab\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "        self.embedding.weight.data.copy_(vocab.vectors) # copies pre-trained word vectors\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(window_size, embedding_dim))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(out_channels, 1 if num_classes == 2 else num_classes)\n",
        "\n",
        "        #Kaming normalization\n",
        "        nn.init.kaiming_normal_(self.conv.weight)\n",
        "        nn.init.kaiming_normal_(self.fc.weight)\n",
        "\n",
        "        \n",
        "        \n",
        "    def forward(self, x, ):\n",
        "        \n",
        "        embedded = self.embedding(x)\n",
        "                \n",
        "        #(batch size, max sent length, embedding dim)\n",
        "        \n",
        "        #images have 3 RGB channels \n",
        "        #for the text we add 1 channel\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #(batch size, 1, max sent length, embedding dim)\n",
        "        \n",
        "        feature_maps =  F.relu(self.conv(embedded).squeeze(3))\n",
        "        # (batch size, out_channels, max sent length - window size +1, 1)\n",
        "        # -> (batch size, out_channels, max sent length - window size +1)\n",
        "           \n",
        "        #the max pooling layer\n",
        "        pooled = F.max_pool1d(feature_maps, feature_maps.shape[2]).squeeze(2)\n",
        "        # (batch size, out_channels)      \n",
        "        \n",
        "        # Do batch normalize pooled then at sentiment\n",
        "        \n",
        "        return self.fc(self.dropout(pooled))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "n1TwMNFOKRSm"
      },
      "cell_type": "markdown",
      "source": [
        "## Task A"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WO69uqM3LtBS",
        "outputId": "25902829-63bf-418f-a0cf-725eaf1d40c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a',LABEL),\n",
        "               ('subtask_b',LABEL),\n",
        "               ('subtask_c',LABEL)]\n",
        "\n",
        "\n",
        "train = data.TabularDataset(train_fp, format='TSV', fields = \n",
        "                            data_fields, skip_header=True, filter_pred=None)\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d') #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
        "\n",
        "LABEL.build_vocab(train.subtask_a)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)\n",
        "\n",
        "# For retrieving tweet text later on\n",
        "train_df = pd.read_csv(train_fp, delimiter=\"\\t\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 10592\n",
            "Validation size: 2648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KkGDZeI-rccB",
        "outputId": "05eb5dd8-a003-4beb-ca26-e6694f35ceee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "print('first tweet', train[0].tweet)\n",
        "print('first label', train[0].subtask_a)\n",
        "print(\"first tweet id:\", train[0].id)\n",
        "# print(TEXT.vocab.stoi) # word to index\n",
        "# print(LABEL.vocab.stoi) # label to index"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first tweet ['@user', '@user', 'a', 'must', 'read', '!', 'url']\n",
            "first label NOT\n",
            "first tweet id: 29719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q9_NCwh3C1Z4",
        "outputId": "58d1200a-8e20-49fa-c7c5-5c9c2502adf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#check loader\n",
        "for idx, batch in enumerate(train_iterator):\n",
        "    inputs, labels = batch.tweet, batch.subtask_a\n",
        "    print(inputs.shape)\n",
        "    print(labels.shape)\n",
        "    print(len(train_iterator))\n",
        "    break"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 74])\n",
            "torch.Size([128])\n",
            "83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "X9LseL5F9n7P",
        "outputId": "b10f2b4e-6671-409d-b424-921f78a82fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6065
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab,\n",
        "                              embedding_dim,\n",
        "                              window_size,\n",
        "                              out_channels,\n",
        "                              dropout)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_a',\n",
        "                                  model,\n",
        "                                  optimizer,\n",
        "                                  loss_fn = loss_fn,\n",
        "                                  epochs = 20,\n",
        "                                  train_loader=train_iterator,\n",
        "                                  valid_loader=valid_iterator)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 1.0084\n",
            "Iteration 50, loss = 0.8035\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1821 / 2648 correct (68.77)\n",
            "[[1718   55]\n",
            " [ 772  103]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.97      0.81      1773\n",
            "           1       0.65      0.12      0.20       875\n",
            "\n",
            "   micro avg       0.69      0.69      0.69      2648\n",
            "   macro avg       0.67      0.54      0.50      2648\n",
            "weighted avg       0.68      0.69      0.61      2648\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 0.7128\n",
            "Iteration 50, loss = 0.6590\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1868 / 2648 correct (70.54)\n",
            "[[1712   61]\n",
            " [ 719  156]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.97      0.81      1773\n",
            "           1       0.72      0.18      0.29       875\n",
            "\n",
            "   micro avg       0.71      0.71      0.71      2648\n",
            "   macro avg       0.71      0.57      0.55      2648\n",
            "weighted avg       0.71      0.71      0.64      2648\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 0.6487\n",
            "Iteration 50, loss = 0.5014\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1933 / 2648 correct (73.00)\n",
            "[[1703   70]\n",
            " [ 645  230]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.96      0.83      1773\n",
            "           1       0.77      0.26      0.39       875\n",
            "\n",
            "   micro avg       0.73      0.73      0.73      2648\n",
            "   macro avg       0.75      0.61      0.61      2648\n",
            "weighted avg       0.74      0.73      0.68      2648\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.5280\n",
            "Iteration 50, loss = 0.5373\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1990 / 2648 correct (75.15)\n",
            "[[1665  108]\n",
            " [ 550  325]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.94      0.84      1773\n",
            "           1       0.75      0.37      0.50       875\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2648\n",
            "   macro avg       0.75      0.66      0.67      2648\n",
            "weighted avg       0.75      0.75      0.72      2648\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.6007\n",
            "Iteration 50, loss = 0.5544\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2017 / 2648 correct (76.17)\n",
            "[[1630  143]\n",
            " [ 488  387]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.92      0.84      1773\n",
            "           1       0.73      0.44      0.55       875\n",
            "\n",
            "   micro avg       0.76      0.76      0.76      2648\n",
            "   macro avg       0.75      0.68      0.69      2648\n",
            "weighted avg       0.76      0.76      0.74      2648\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.4959\n",
            "Iteration 50, loss = 0.5011\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2045 / 2648 correct (77.23)\n",
            "[[1626  147]\n",
            " [ 456  419]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.92      0.84      1773\n",
            "           1       0.74      0.48      0.58       875\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2648\n",
            "   macro avg       0.76      0.70      0.71      2648\n",
            "weighted avg       0.77      0.77      0.76      2648\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.4487\n",
            "Iteration 50, loss = 0.4952\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2055 / 2648 correct (77.61)\n",
            "[[1617  156]\n",
            " [ 437  438]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.91      0.85      1773\n",
            "           1       0.74      0.50      0.60       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.76      0.71      0.72      2648\n",
            "weighted avg       0.77      0.78      0.76      2648\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.4686\n",
            "Iteration 50, loss = 0.3792\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2066 / 2648 correct (78.02)\n",
            "[[1592  181]\n",
            " [ 401  474]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.90      0.85      1773\n",
            "           1       0.72      0.54      0.62       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.76      0.72      0.73      2648\n",
            "weighted avg       0.77      0.78      0.77      2648\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.3789\n",
            "Iteration 50, loss = 0.4144\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2064 / 2648 correct (77.95)\n",
            "[[1635  138]\n",
            " [ 446  429]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85      1773\n",
            "           1       0.76      0.49      0.60       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.77      0.71      0.72      2648\n",
            "weighted avg       0.78      0.78      0.76      2648\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.3694\n",
            "Iteration 50, loss = 0.3616\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2076 / 2648 correct (78.40)\n",
            "[[1613  160]\n",
            " [ 412  463]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85      1773\n",
            "           1       0.74      0.53      0.62       875\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2648\n",
            "   macro avg       0.77      0.72      0.73      2648\n",
            "weighted avg       0.78      0.78      0.77      2648\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.3268\n",
            "Iteration 50, loss = 0.3907\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2082 / 2648 correct (78.63)\n",
            "[[1592  181]\n",
            " [ 385  490]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.73      0.56      0.63       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.73      0.74      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.3464\n",
            "Iteration 50, loss = 0.3135\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2080 / 2648 correct (78.55)\n",
            "[[1590  183]\n",
            " [ 385  490]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.73      0.56      0.63       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.73      0.74      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.3259\n",
            "Iteration 50, loss = 0.3107\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2092 / 2648 correct (79.00)\n",
            "[[1615  158]\n",
            " [ 398  477]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85      1773\n",
            "           1       0.75      0.55      0.63       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.78      0.73      0.74      2648\n",
            "weighted avg       0.79      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.3701\n",
            "Iteration 50, loss = 0.3375\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2091 / 2648 correct (78.97)\n",
            "[[1585  188]\n",
            " [ 369  506]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85      1773\n",
            "           1       0.73      0.58      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.3490\n",
            "Iteration 50, loss = 0.2864\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2092 / 2648 correct (79.00)\n",
            "[[1591  182]\n",
            " [ 374  501]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.73      0.57      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.73      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.2411\n",
            "Iteration 50, loss = 0.3509\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2091 / 2648 correct (78.97)\n",
            "[[1580  193]\n",
            " [ 364  511]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85      1773\n",
            "           1       0.73      0.58      0.65       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.2526\n",
            "Iteration 50, loss = 0.2456\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2089 / 2648 correct (78.89)\n",
            "[[1591  182]\n",
            " [ 377  498]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.73      0.57      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.73      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.2801\n",
            "Iteration 50, loss = 0.3200\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2084 / 2648 correct (78.70)\n",
            "[[1613  160]\n",
            " [ 404  471]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.91      0.85      1773\n",
            "           1       0.75      0.54      0.63       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.72      0.74      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.2132\n",
            "Iteration 50, loss = 0.2144\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2089 / 2648 correct (78.89)\n",
            "[[1587  186]\n",
            " [ 373  502]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85      1773\n",
            "           1       0.73      0.57      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.73      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.2225\n",
            "Iteration 50, loss = 0.2152\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 2087 / 2648 correct (78.81)\n",
            "[[1580  193]\n",
            " [ 368  507]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85      1773\n",
            "           1       0.72      0.58      0.64       875\n",
            "\n",
            "   micro avg       0.79      0.79      0.79      2648\n",
            "   macro avg       0.77      0.74      0.75      2648\n",
            "weighted avg       0.78      0.79      0.78      2648\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_q8EEjwwLf3",
        "colab_type": "code",
        "outputId": "95d94d53-27b1-48da-b2be-7e4d9d3c582b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd8lfX9/vHXfUb2yT4nGxIyGIEE\nEkARQaaiYB110Fppa60dtrbqt63SVrStaLfW9tfa1lqttqKUuhURxcEwkIQAYYQEEsLI3iE75/dH\nQgQZYSQ5ycn19BHPOfe573Peb06SK/f63IbT6XQiIiIiA87k6gJERESGK4WwiIiIiyiERUREXEQh\nLCIi4iIKYRERERdRCIuIiLiIQlhkkBs9ejQlJSWuLkNE+oFCWERExEUsri5ARM5PS0sLDz/8MJ98\n8gkmk4nLLruMH/zgB5jNZp577jmef/55nE4nfn5+PPLIIyQmJp52en5+Pg8++CDl5eV4eHiwfPly\nJkyYQGNjIz/84Q/Zt28fra2tTJs2jWXLlmG1Wl3dvohbUAiLDFHPPPMMJSUlvPHGG7S3t/OlL32J\n119/nblz5/L444/z/vvv4+fnx1tvvcW6deuIiIg45fT4+HjuvPNObr/9dm688UYyMzP59re/zfvv\nv8/LL7+Mv78/b731Fu3t7fz85z8nPz+fsWPHurp9EbegEBYZotatW8dtt92GxWLBYrFw9dVXs379\neq666ioMw2DlypUsWrSIK6+8EoC2trZTTs/Pz6eyspIbbrgBgPT0dIKDg8nOzu65/fjjj5k6dSoP\nPfSQy/oVcUfaJywyRFVVVREQENDzOCAggMrKSqxWK//85z/Jysriiiuu4Itf/CJ79uw57fS6ujqa\nm5u58sorWbBgAQsWLKCyspKamhquvPJKvvKVr/D4448zbdo0HnroIVpbW13YtYh70ZqwyBAVGhpK\nTU1Nz+OamhpCQ0MBGDduHH/4wx9obW3l73//O8uWLeOFF1445fTf/OY3+Pr68vbbb5/yfRYvXszi\nxYspLS3lu9/9Li+//DI33XTTgPQo4u60JiwyRM2aNYuVK1fS0dHB0aNHeeWVV7jsssvYs2cPd911\nF62trXh4eDB+/HgMwzjt9KioKMLDw3tCuKqqinvuuYejR4/ypz/9iZUrVwIQFhZGdHQ0hmG4sm0R\nt6I1YZEh4NZbb8VsNvc8/sUvfsGtt95KcXExCxcuxDAMFixY0LOfNzo6mkWLFmG1WvH19eWBBx4g\nKSnplNMNw+B3v/sdDz74II899hgmk4mvfvWr+Pj4cM0113D//ffzt7/9DcMwSE1N5ZprrnHVP4OI\n2zF0PWERERHX0OZoERERF1EIi4iIuIhCWERExEUUwiIiIi6iEBYREXGRAT9Fqby8vk9fLyjIh+rq\no336moOBO/bljj2Be/alnoYOd+zLHXuy222nnD7k14QtFnPvMw1B7tiXO/YE7tmXeho63LEvd+zp\ndIZ8CIuIiAxVCmEREREXUQiLiIi4iEJYRETERRTCIiIiLqIQFhERcRGFsIiIiIuc1WAdy5cvJycn\nB8MwWLp0KSkpKT3PPf/887z66quYTCbGjx/Pj3/8434rVkRE3N+jjz5KdnYOVVWVNDc3ExkZhb9/\nAMuX//qMy7355mv4+vpx2WWzT/n844//lhtvXExkZFR/lH1eeg3hjIwMioqKWLFiBQUFBSxdupQV\nK1YA0NDQwFNPPcU777yDxWLhtttuY+vWrUycOLHfCxcREfd03333UV5ez5tvvsa+fQV85zvfP6vl\nrrrq6jM+/73v3dsX5fWpXkN448aNzJs3D4D4+Hhqa2tpaGjAz88Pq9WK1Wrl6NGj+Pj40NTUREBA\nQL8XLSIiw0tW1hZeeOE5jh49yne+czfZ2ZmsW7eWzs5Opk2bzm233cFTTz1JYGAgcXHxrFr1IoZh\noqhoP7NmzeW22+7gO9+5g3vu+SHvv7+WxsYGDhwo4tChg9x1171Mmzad5577J++++w6RkVG0t7ez\nePEtpKVN7te+eg3hiooKkpOTex4HBwdTXl6On58fnp6e3HnnncybNw9PT08WLlxIXFzcGV8vKMin\nz4Yka2nrYO3mA8ycFIXVDYc5O91Yo0OZO/YE7tmXeho6+rOvf7yWy/qcQ336mtNTo7jt6uQzzmO3\n27DZvPDx8cButxEY6ENh4T5Wr16Nh4cHe/fu4KWXVmAymZg7dy533vkNfH098fPzIjDQhz17dvHW\nW2/R2dnJnDlz+NGP7sXDw0JQkC++vp4cPnyAZ555mg8//JAXXniBmTMv5uWXV7J69WoaGhq4/PLL\n+eY3v97v3zPnfAEHp9PZc7+hoYEnn3ySt99+Gz8/P7785S+ze/duxowZc9rl+3JQ7uy8cp5YtZ3S\n8gbmT4nps9cdDOx2W59f7MLV3LEncM++1NPQ0d99NR1tpaPD2fuM5/iaZ6r5WE/19c0c7Z63puYo\ncXHx1Na2AC20txvcfPMXMJvNVFVVs2/fIRobW7Bam6mpOUpCQhINDe1AV26Vl9fT2tpOdXUjjY0t\njB6dTHl5PZ6eNqqqasjJ2UVs7Cjq69sAT8aMSaam5mif/dueLsx7DWGHw0FFRUXP47KyMux2OwAF\nBQXExMQQHBwMwOTJk9mxY8cZQ7gvjYr0xzAgc0+Z24WwiMhgcNOcBG6ak+DqMgCwWq0AlJQcYcWK\n5/nHP57Hx8eHW2+96aR5zeYzbx09/nmn04nTCSbTpycMGUYfFd2LXk9Rmj59OqtXrwYgNzcXh8OB\nn58fAFFRURQUFNDc3AzAjh07iI2N7b9qPyPAz5OxscHsPVhLbWPrgL2viIi4Tk1NDUFBQfj4+LBn\nz25KSkpoa2u7oNeMiIhg374C2tvbqa6uZvfuXX1U7Zn1uiaclpZGcnIyixcvxjAMli1bxqpVq7DZ\nbMyfP5+vfe1rLFmyBLPZzKRJk5g8uX93Yn/WtAmR7NxfRfbecmZNHDyHnYuISP9ITEzC29uHb33r\nNiZMmMg111zPb3/7S1JSUs/7NYODQ5g/fwFf//oSRo6MY9y45F7XpvuC4Tx+J+8A6Ot9F51mM7c/\nvIbxccHcc7P7nBrljvuv3LEncM++1NPQ4Y59uaqnN998jfnzF2A2m1myZDG/+90TOBxhffLa571P\neLALC/ZhZLiNXUXVHG1uw8fL6uqSRERkCKqsrOSOO76M1erB5Zcv6LMAPpMhH8IA6Ul2ikrqycmv\nZNr4cFeXIyIiQ9Ctt36FW2/9yoC+p1uMHZ0+uuto7cy8chdXIiIicvbcIoQjQnyJCPFhx75KWlo7\nXF2OiIjIWXGLEIauteHW9k6276t0dSkiIiJnxX1COMkBQJY2SYuIyBDhNiE8IsyPEH8vcgoqaGvv\ndHU5IiJynm6++eaTBsv4y1/+yH/+89xJ82ZlbeEnP/khAPfdd89Jz//3vyt46qknT/te+fl7OXCg\nCIBly+6npaX5Qko/Z24TwoZhkD7aTlNLB7uKql1djoiInKdFixbx3ntrTpi2bt17zJt3+RmXe/TR\n353ze33wwXsUFx8A4KGHHsHT0+ucX+NCuMUpSsekJdl5Z3MxWXllpMSHuLocERE5D1dddRU33XQz\n3/72XQDs3r0Lu91OYeF+fvKTH2G1WrHZbPzsZ4+esNzChXN54421bNmSwR/+8FuCg0MICQntuTTh\nww8/SHl5GU1NTdx22x2Eh0fwyiur+OCD9wgKCuKBB+7n2WdX0NBQzyOP/Iy2tjZMJhP33fdTDMPg\n4YcfJDIyivz8vSQljea++356wb26VQgnRAcQ4OtBVl4FS65wYjIN0AjcIiJualX+62SXbe/T15zk\nmMD1CYtO+3xISAiRkVHs3LmDcePG8957a5g/fwH19fUsW/YLIiOj+PnPH+CTTzbi4+Nz0vJPPvlH\nfvrTn5OYmMT//d9dREZGUV9fx9SpF3PllYs4dOggP/3pffzjH89x0UXTmDVrLuPGje9Z/u9//wuL\nFl3D3LmX8/777/KPf/yVr33tG+zZs4uHHlpOUFAw1113FfX19dhsF3apQ7fZHA1gMgwmJdlpaGpj\n78EaV5cjIiLnaf78Baxd27VJev36D5k1ay6BgYH88pe/4DvfuYPs7Ezq6mpPueyRI0dITEwCYOLE\nNABsNn927crlW9+6jYcffvC0ywLs2bOLSZPSAUhLm8zevXsAiIqKISQkFJPJRGioncbGhgvu063W\nhKFr9Kx12YfI3FPO6BFBri5HRGRIuz5h0RnXWvvLZZfN5tln/8H8+VcQEzMCf39/Hnnk5/z6148R\nGxvH7373y9Mue/wlCY9dHmHNmrepq6vjT3/6O3V1ddx++61neHejZ7m2tnYMo+v1PntBh7649IJb\nrQkDjB4RiI+nhcy8cjoH9toUIiLSR3x8fImPT+TZZ59m/vwFADQ2NhAWFk59fT1ZWZmnvXxhaKid\nAwcKcTqdZGdnAl2XP4yIiMRkMvHBB+/1LGsYBh0dJw7yNHbsOLKytgCwdWsmY8aM7a823S+ELWYT\nExNDqa5vofCIe11ZRERkOJk/fwGbN3/CpZfOBOD662/kW9/6Gr/61cPccssSnnvun1RWVpy03B13\nfJuf/ORH/OhHd/dchGHWrDls2PAR3/vet/D29sbhcPD0038jNXUSjz32a7ZsyehZ/vbbv8nbb7/J\nXXd9kzfffJ2vfe0b/dbjkL+U4akueZWdV84Tq7Zz5cUjuHFWQp++30DR5cmGDnfsSz0NHe7Yl7v2\ndCputyYMkBwXjIfVROae8j7ZZi8iItIf3DKEPaxmUkaFUFbdxKGKRleXIyIickpuGcIAad2XN8za\no7GkRURkcHLbEE6ND8ViNnSNYRERGbTcNoS9PS2Miw2muKyBsuqjri5HRETkJG4bwtA1cAdAVt7J\nh7CLiIi4mluH8MTEUAwDMvPKXF2KiIjISdw6hG0+HoyOCaTgUB3V9S2uLkdEROQEbh3CAOmjHQBk\n6QAtEREZZNw+hCclhgIKYRERGXzcPoSD/b0YFenPngM11B9tdXU5IiIiPdw+hKHrKOlOp5Ot+TpK\nWkREBo9hEcIaPUtERAajYRHCYUE+RNv9yC2soqml3dXliIiIAMMkhAHSR9tp73CyfV+lq0sREREB\nhlMId4+elalN0iIiMkgMmxCOsvviCPJmW0ElrW0dri5HRERk+ISwYRikJ9lpaesgt7DK1eWIiIgM\nnxAGHSUtIiKDy7AK4bgIf4JsnmzNr6C9o9PV5YiIyDA3rELYZBikJdppbG5nT3GNq8sREZFhbliF\nMHSdqgTaJC0iIq437EI4MSYAP28rWXnldDqdri5HRESGsWEXwmaTiUmJodQ2trLvUJ2ryxERkWFs\n2IUwfLpJOjOvzMWViIjIcGY5m5mWL19OTk4OhmGwdOlSUlJSACgtLeX//u//euYrLi7m3nvv5eqr\nr+6favvI2JHBeHmYydxTzk2zEzAMw9UliYjIMNRrCGdkZFBUVMSKFSsoKChg6dKlrFixAoCwsDD+\n9a9/AdDe3s6tt97KnDlz+rfiPmC1mEhNCOWTnaUcKG1gZLjN1SWJiMgw1Ovm6I0bNzJv3jwA4uPj\nqa2tpaGh4aT5/ve//3HFFVfg6+vb91X2g56xpPN0lLSIiLhGryFcUVFBUFBQz+Pg4GDKy08Orpde\neokbbrihb6vrR+NHBWO1mMhSCIuIiIuc1T7h4zlPcVpPdnY2o0aNws/Pr9flg4J8sFjM5/q2Z2S3\nn9/m5LTRDj7JLaG5E2LCBt8m6fPtazBzx57APftST0OHO/bljj2dSq8h7HA4qKio6HlcVlaG3W4/\nYZ5169Yxbdq0s3rD6uqj51jimdntNsrL689r2QlxQXySW8LaTwpZOC22T+u6UBfS12Dljj2Be/al\nnoYOd+zLXXs6lV43R0+fPp3Vq1cDkJubi8PhOGmNd/v27YwZM6YPyhxYqQmhmE2GrjEsIiIu0eua\ncFpaGsnJySxevBjDMFi2bBmrVq3CZrMxf/58AMrLywkJCen3Yvuar5eVMSODyN1fRWVtMyEBXq4u\nSUREhpGz2id8/LnAwElrva+99lrfVTTA0pPs5O6vIiuvnPlTYlxdjoiIDCPDcsSs401KDMVApyqJ\niMjAG/YhHODnSUJ0AHuLa6htbHV1OSIiMowM+xCGrk3STiB7r9aGRURk4CiEgbQkXWNYREQGnkIY\nCA30ZmSYjV1F1RxtbnN1OSIiMkwohLuljbbT0ekkJ7/S1aWIiMgwoRDuNnm0LuggIiIDSyHcLSLE\nl4gQH3bsq6SltcPV5YiIyDCgED5O+mg7re2d7NivTdIiItL/FMLHSU9yANokLSIiA0MhfJwRYX6E\n+HuRk19Be0enq8sRERE3pxA+jmEYpI+209TSwc7CaleXIyIibk4h/BnHBu7YvKvUxZWIiIi7Uwh/\nRkJUAGFB3mzMLeVQeYOryxERETemEP4Mk8ng5rmJdDqdvLB2L06n09UliYiIm1IIn0JqfAjjRwWT\nW1jN1vwKV5cjIiJuSiF8CoZhsHhOImaTwYq1+bS160hpERHpewrh04gM9WVOWjRlNU2s2VLs6nJE\nRMQNKYTP4JpLY/HztvLahkJqGlpcXY6IiLgZhfAZ+HhZuf6yUbS0dvDfdQWuLkdERNyMQrgXM1Mi\nGeHwY/2OEvYdrnN1OSIi4kYUwr0wmQy+MC8RgH+/m0enTlkSEZE+ohA+C6NHBDFljIN9h+vYlFvi\n6nJERMRNKITP0o2z47FaTLy0roDm1nZXlyMiIm5AIXyWQgO8ufKiEdQ2tPLGxiJXlyMiIm5AIXwO\nrrx4JEE2T1ZnFFNW0+TqckREZIhTCJ8DT6uZm2Yn0N7RyYvv5bu6HBERGeIUwudo6lgHidEBZOWV\ns7OwytXliIjIEKYQPkeGYfDFeUkYwH/W7qWjU+NKi4jI+VEIn4eR4TZmpEZwqLyRddmHXV2OiIgM\nUQrh83T9zHi8Pc28/NE+GpraXF2OiIgMQQrh8+Tv68HnpsfR2NzOyx/tc3U5IiIyBCmEL8Dc9GjC\ngn14P/sQB8saXF2OiIgMMQrhC2Axm/jC3ASczq6DtJwaV1pERM6BQvgCpcSHkhIfwq6iarLyKlxd\njoiIDCEK4T5w85wEzCaDFe/tpa29w9XliIjIEKEQ7gMRIb7MTY+moraZdzYXu7ocEREZIhTCfeRz\n0+Ow+Vh5fUMR1fUtri5HRESGAIVwH/HxsvD5y+Jpaetg5boCV5cjIiJDgEK4D106IYIRYX5szC2h\n4FCtq8sREZFBTiHch0ymrnGlAf79bh6dOmVJRETO4KxCePny5dx8880sXryYbdu2nfDckSNH+MIX\nvsANN9zAAw880C9FDiVJMYFMHetg/5F6Nu4ocXU5IiIyiPUawhkZGRQVFbFixQoefvhhHn744ROe\nf/TRR7nttttYuXIlZrOZw4d1QYObZifgYTGxcl0BTS3tri5HREQGqV5DeOPGjcybNw+A+Ph4amtr\naWjoGqKxs7OTzMxM5syZA8CyZcuIjIzsx3KHhmB/L666eCS1ja28vrHQ1eWIiMggZelthoqKCpKT\nk3seBwcHU15ejp+fH1VVVfj6+vLII4+Qm5vL5MmTuffee8/4ekFBPlgs5guv/Dh2u61PX68v3LJw\nHOtzS1iz+SDXzk4kMtTvnF9jMPZ1odyxJ3DPvtTT0OGOfbljT6fSawh/1vHjIzudTkpLS1myZAlR\nUVHccccdrFu3jlmzZp12+erqo+dV6OnY7TbKy+v79DX7yudnjuIvr+Tyl5U5fPfzKee07GDu63y5\nY0/gnn2pp6HDHfty155OpdfN0Q6Hg4qKT8dELisrw263AxAUFERkZCQjRozAbDYzbdo09u7d20cl\n966ts51NxVk0tw/OwTGmjHGQFBNI9t4KcvdXubocEREZZHoN4enTp7N69WoAcnNzcTgc+Pl1bVq1\nWCzExMRQWFjY83xcXFz/VfsZedUF/G7D33h082MU1h0YsPc9W4Zh8MV5iRh0XWWpvaPT1SWJiMgg\n0msIp6WlkZyczOLFi/nFL37BsmXLWLVqFWvWrAFg6dKl3H///SxevBibzdZzkNZAGBucyOfGXE5F\nUxW/zfx/vF24lk7n4Aq6EWE2Zk6M5HBFI+uyD7m6HBERGUQM5wBfBLevt/Pb7TY+3pPNs7tWUNNS\nS3xAHF8et5gQ76A+fZ8LUXe0lfuf3IQB/PQrkwkL8ul1GXfdJ+JuPYF79qWehg537MtdezoVtxgx\na3RwAkun3s1E+wQKavfzyObfs6V0q6vL6uHv48HiuQkcbWnndyu2UtvY6uqSRERkEHCLEAbwtfpw\n+/gvccuYG+lwdvJ07r95ZucLNLU3u7o0AGakRLLokljKa5p5/KUcmls1iIeIyHDnNiEMXQdCXRI5\nhfunfI+RthgySrJ4JOMx9tUWubo0AK6bEcelEyIoLKnn/728QwdqiYgMc24Vwsc4fOzcm/5tFoyc\nQ1VzNb/P+jNv7F9DR2eHS+syDIMlC0YzYVQIO/ZV8cxbuxngXfIiIjKIuGUIA5hNZq6OX8D3Jn2D\nAA9/3ty/ht9n/YWKJteer2sxm/jWtcnEhttYv6OE/320z6X1iIiI67htCB+TGDSKpVPvJt2Ryv66\nIh7J+D0ZJVkuXQP18rDw/RtTcQR68/qGIt7POuiyWkRExHXcPoQBfKzefDX5iywZezMAz+x8gX/u\n/A9H25pcVpO/rwf33JyKzcfKc+/kkbmn3GW1iIiIawyLEIau/bEXRaRz/9TvE+c/ki2lW1me8Xvy\na/a7rCZHkA/fvzEVD6uZJ1/NJa+4xmW1iIjIwBs2IXxMqHcId6d9k6vi5lPTUstjWX/htX2rXXbQ\nVlyEP9++bjydnU6e+O82DlU0uqQOEREZeMMuhKHroK2FcfO5J/1bBHsF8nbhWn6b9f8oO1rR+8L9\nYMKoEL5y5Rgam9v5/Ytbqa4fnBekEBGRvjUsQ/iYUQGx3D/1bqaGp1FUV8wjmx9j4+HNLjlo69KU\nCK6fOYqquhZ+/2IOjU1tA16DiIgMrGEdwgDeFi++PG4xXx33BcyGied2v8RTO56jsa1vr3t8NhZO\nG8nstCgOljew/J8ZtLVrMA8REXc27EP4mMnhk7h/yt3EB8SRXb6dn236NR8e3Dig+4oNw+CWeUlM\nSgxlW34FT72xk04N5iEi4rYUwscJ8Q7i+2nf4LqEhbR3trMi7388svkxdlXmDVgNJpPBNz6XzNjY\nYDJ2lfHie/kD9t4iIjKwFMKfYTJMzBtxGcum/ZDpkVMpaSzjjzl/5885/6CksWxAavCwmvnp1y4i\nIsSHdzYXszrjwIC8r4iIDCyF8Gn4e9j44pgb+NGU75EUGM+Oyt08nPE7Xsp7ZUD2F9t8PLjnpokE\n+nmw4r18PtlZ2u/vKSIiA0sh3IsYWyR3TbqDOyZ8mWCvINYdXM+DG3/J+8Uf9/v+4pAAL+6+aSLe\nnmb+/vpOdhW6dtxrERHpWwrhs2AYBqn2ZH5y0b1cl7AQJ05W7n2VhzN+x46KXf16SlOMw4/vXJ8C\nwB//t50DpfX99l4iIjKwFMLnwGqydO0vvviHzIiaRtnRCv687Wn+lPMUhxtK+u19x44M4vZF42hq\n6eD3L+VQUeu6Ma9FRKTvKITPg83Dj8Wjr2Pp1LsZE5TIrqo8lmf8nhf2/I/61oZ+ec+LxoWxeE4C\ntQ2t/P7FHBo0mIeIyJCnEL4AkX7hfGfi7Xwr5as4fEL56NBGHtr0K9Ye+JD2zvY+f7/Lp47g8ikx\nHKk8yh9WbqO1zTXjXYuISN9QCF8gwzAYHzqWH0+9hxsSP4eBwar81/nFJ78lpzy3z/cX3zQngYvG\nhZF/qJYnX82ls1ODeYiIDFUK4T5iNpmZHXMpy6b9kMuip1PZXM1ftz/DH7b+jUMNR/rsfUyGwW1X\njWXsyCCy91bw/Jo8l4x1LSIiF04h3Mf8rL7clHQNP556N8khY8irzueRjMf49+6V1LX2zZHNVouJ\nO6+bQLTdj/ezD/HC2nwNbykiMgQphPtJuG8Y3069jTtTv0aYr4P1hzN4cOMveWv/Wlo7Wi/49X28\nLNx9UyoRIT6s2VLMk6/k0taufcQiIkOJQrifjQsZzdIp3+fmpGuxmqy8vn81D278FRsOZ9DpvLCr\nJAXZPLn/S+kkRQeweXcZv12RQ2OzjpoWERkqFMIDwGwyMzP6Eh6c9iMWjJzD0fYmnt+9kuUZv7/g\nwT78vK3cu3gik0fbySuuYfm/Mqmsbe7D6kVEpL8ohAeQt8WLq+MX8OC0H3JJxBRKGsv487an+UP2\nXymqKz7v17VazHzz2vHMn9x1+tIv/rVFI2uJiAwBCmEXCPQM4JaxN7L02MFbNQX8assTPJ37byqa\nzm98aJNh8IV5iT0Dejz6fBa5GmtaRGRQUwi7UKRfON9OvY27Jt7BCFsUW0q38vNNv+a/e1+joaXx\nvF7z8qkj+OY1ybR3dPLYizls2NF3p0eJiEjfUggPAqODE/jB5O/y1XFfIMDTn/eKP+K7b/yUNUXr\naOs49wOtpo4N496bJ+JpNfP313fxxsZCnUssIjIIKYQHCZNhYnL4JH568Q/4fMIiMAxeLniThzb9\nmk+OZJ7zkdSjRwRx/5fSCPb35L8f7OO5d/I0upaIyCCjEB5krCYLc0bM5ImFP2PeiMuob2vg2V0r\n+OXmP7C7au85vVaU3Y8f3zqZGEfXoB5/XLWdFo03LSIyaCiEByk/D1+uS1jIAxf9gKnhaRxqOMIT\nW//GH7f+nYP1h8/6dYJsntx3SxrjYoPYml/Br/+TTd3RCx8sRERELpxCeJAL8Q7iy+MW86Mpd/Vc\nNvHRzY/z7M4VVDfXnNVreHta+P6NqUxLDmff4TqW/yuTsuqj/Vy5iIj0RiE8RMTYovjupK/zndTb\nifQL55OSTB7a9Ctezn/zrMLYYjZx+6KxLJw2krLqJh7+Vyb7j9QNQOUiInI6FlcXIOdmbEgSo4MT\nyCjJ4rV9q1lzYB1rDqwjPiCOyWGpTHKkYPPwO+WyhmHw+cviCfb34rl39vDLf2fxzWvGMzEhdIC7\nEBERUAgPSSbDxMURk0lzpPLFMkmcAAAgAElEQVRJSSaZpVvJr9lPQe1+Xsx7hdFBCaSHTWSiPRkf\nq89Jy8+eFEWgnwdPvpLLE//dxpIrRnPZxCgXdCIiMrwphIcwD7OVGVEXMyPqYmpaasku205m6VZ2\nV+9ld/VeXtizirHBSaSHpZISOg4vi1fPspMS7fzgC5N4fOU2nnl7D1V1LVw7Iw7DMFzYkYjI8KIQ\ndhOBngHMjrmU2TGXUtFURVZZDpmlOeyo3MWOyl1YTRbGh4wlPWwiySFj8DBbiY8K4Me3pvP7F3N4\nbUMhVfXNfHnBGCxmHSogIjIQziqEly9fTk5ODoZhsHTpUlJSUnqemzNnDuHh4ZjNZgB+85vfEBYW\n1j/VylkJ9Q7m8pGzuXzkbEoay8jsDuTs8u1kl2/H0+xBSmgy6WGpjA1OYumt6Ty+Mof120uoaWjl\n29eOx9tTf5+JiPS3Xn/TZmRkUFRUxIoVKygoKGDp0qWsWLHihHn+9re/4evr229FyvkL93WwMG4+\nV8XO41DDkZ5A3lyazebSbHws3ky0j+faK1NY+4GFbQVV/PLfWXz/xlQC/TxdXb6IiFvrNYQ3btzI\nvHnzAIiPj6e2tpaGhgb8/E59BK4MToZhEG2LJNoWyedGLaCovpjM0q5A3nBkMxuObMYW7sfIwGiK\n9/jz4D9b+PrCZJLjgl1duoiI2+o1hCsqKkhOTu55HBwcTHl5+QkhvGzZMg4dOkR6ejr33nuvDu4Z\n5AzDINZ/BLH+I7guYSEFNYVkluWQXbaNMvNuPMdBa7uVJ7I3MWrfSBalTmJU4Ai8LFozFhHpS+e8\n4++zV+O56667mDFjBgEBAdx5552sXr2aBQsWnHb5oCAfLBbzuVd6Bna7rU9fb7AYqL7CHKlckpRK\nR2cHO8r2sPFAJlsP76bKUk4R5fxp2xYMDGIDo0kKHcXo0FEkhcZj9wk+5z+49FkNHepp6HDHvtyx\np1PpNYQdDgcVFRU9j8vKyrDb7T2Pr7322p77M2fOJC8v74whXN3HwyXa7TbKy+v79DUHA1f1FWmO\n4fNxMXw+Dsobanhu/SZ2VezHYquhiMPsrylmdf4HAAR42IgLiCUuYASjAmKJsUVhNZ3+W0qf1dCh\nnoYOd+zLXXs6lV5DePr06TzxxBMsXryY3NxcHA5Hz6bo+vp6vv/97/PnP/8ZDw8PNm/ezBVXXNG3\nlYvL2P0CufuKBWTuKeOfb+2msaWV0UkG41NMHD56kP21hWwt387W8u0AWAwzI/yjiQsYyaiAWOL8\nRxLgOTz+mhUROR+9hnBaWhrJycksXrwYwzBYtmwZq1atwmazMX/+fGbOnMnNN9+Mp6cn48aNO+Na\nsAxN6aMdjIoM4O+v72TXnmqOHLRy+8KruH18MFXNNeyvLWRfXRH7aosorCtmX20Ra/kQgBCvYEYF\njGRUwEgmmcfi1eGH1Wx1cUciIoOD4fzsTt5+1tebGNxxswUMzr46nU7eySjmvx8U0NHpZP7kGG6Y\nNQrrcfv4WzpaKeoO4v21heyvPUBj+6e7IEyGCYd3KFF+EUT6hXfd+oYT7BU0ZA/oG4yf1YVST0OH\nO/blrj2dikZkkLNmMgwWXDSCsSODePLVXNZsKWZXUTXf+Nw4ouxduyg8zR4kBcWTFBQPdB3IV3a0\nnH21RZS2lVBQUczhhhJKjnYNInKMl9mLSL/wrmD2PRbQ4XhbvF3Sq4jIQFAIyzkbGW5j2VensGLt\nXtZtPczPntnCTbMTmJMWddLarGEYhPk6CPN19Px163Q6qWqu4XDjEQ41lHC44QiHGksorDvAvtrC\nE5YP8gw8aa05zMeO2dS3R9iLiLiCQljOi6fVzJIFY5gwKoSn39rN82vy2L6vkq9eNZYAX48zLmsY\nBiHeQYR4BzEhdFzP9LaONkqOlneH8hEOdwf0sfGvj7EYZsJ8Hcdtyg7E38OfAE8b/h7+Op9ZRHrV\n6eyktaOV5o4Wmtubu29baO5owcfiRVJQwoDUoRCWCzIpyU5shD//eGMn2woqWfbUJ9y2cCwp8ed+\njWKr2UqMLZIYW+QJ0+tbG7oCubGEQw1HTrh/Kp5mDwI8/PH3tOHvYeu5f8Kthw1fq8+Q3Q8tMpS0\ndrRR01JDe2dHzzQnnx6O5HQee9T1/3qzD9V1jSfOg5NPj2D6dP62jvaeIG05LkibO5o/vX98yB6b\nr6PljDU/eukDp702e19SCMsFC7J5cvfNE3l3czErPyjgsZe2MTc9mhtnxeNhvfDNxjYPP0YHJzA6\n+NO/TDudnVQ0VXK4sZSallrqWuqpba379La1nvKayhN+iD/LbJjx97CdENBdoW3Dx+qDh8mKxWTB\nw9x9a7JiMVmxmqx4mC1YTFYshjaLi7R1tlPdXE1lczWVTVU9t1XN1VQ0V1Hf2uDqErGYLHiZPfEy\ne2Lz8MPT7Im3xRNPsydeFi+8LF3PeVm8sHuHDEgAg0JY+ojJMLh86gjGdB+0tTbzILsPVPONq5OJ\ndvT9N7PJMOHwsePwsZ92no7ODurbGk4I6LrWempb66lrqaO2tZ7aljoO1R+myFl8XnUYGFjNFqxG\nV1Bbzdae8LaarFi7p1lNFjzMHtisfvh7+GHzsGHz8MPm4dezVm4ydAlJGZw6Ojuobqmhsqk7aJur\nuu93BW1tS90p/+A1GSaCvYKIDAonyCsQq8nKp9ueDLo2RBkc+7+BAQZ4e3vQ3NR2bK5js2N0/9fz\nCoaBxTCfFKJdAevVHbBd0y1nGEjIlXSK0iA1lPtqaevgxffzeT/rEBaziRtnxTNvcjQOh/+g7Mnp\ndHK0vYnalq416NqWOpram2nrbOv+av/0tqPtM/fbwdRJU2sLrZ1ttHdPP3b/TGvixzMw8PPwxd/D\nhs3qd0JA27pD2797ms3q1+8Hpg3l77/TcYeeOp2dn34/dn8vBgR6U1FVT6ezs+er47j7J33hpLOz\no2senHQ6O+h0Ok+Yp7m9mcrm6q412aYqalpqT/m9bGAQ5BVIiFcQIV7BBHsHEeoVTLBXEKHewQR4\n+p/XH5fu8Fl91ulOUVIID1Lu0NfW/Ar+8cYuGpraGD8qmB/eOoX2ljZXl9XnTvdZOZ1O2p0dtHe2\n0drRTktHCw1tDdS1NlDfWt99e+yrnvrWrueaO5p7fU9fi09PUHuYPTAbZsyGCbPJ3H3fjNlkxmKY\nMZlMPdMsPc+bMJssXbfd8356ayI40I+62uaefeYmo3sdxDB133avlRybfvz909x2/Zsc+8XfSYez\n47hf/F1h8Nnw6PjMfecpAsZkmLr7smAxmbGYLFiM7ltT9zTDgj3En/ralu75LFhNZszd8/b2R82x\nz7Kjs532zg7anV23HZ3t3Z9xOx3dt+2d3bfHpnd29Nw/5R9zxwXqiY+77rd2ttHW0U57Zxvtzo4z\n1tnXDAwCPP27QtY7mBCvIIK9ggn17roN8gzolz8I3eH332cphIcYd+mrtqGFp97YxY79VQT4efDl\nK8YwMfHcD9oazPr6s2rtaKO+taE7sD8N50+Dup76tkbqW+tpbOvbsdiHKwPjuAC3YBgGHZ0dtDm7\nQrRjAMPPZJi6dmN0H39gNR93v2f3hrVnHj8fL1pbOjAZJkyYMBkmzIYJ4zO3phO+jO5bMyaMk+bz\nMHsQ7BXUvQl54Dfjusvvv+MphIcYd+qr0+lk7ZaDrPyggLb2TmZPiuKmOQl49sFBW4OBKz+rY2tZ\nHZ3tdHSvXX467diaZUfXWpuzo+f5ju61zmPzdnZPO7act4+VhsaW7qNWO3Fy7AhW5+lvPzOtEyec\nMA/dv/zNPUFh+szXGacdFzAmU1d4GIYJp7OzZ02z/TNrqsemdTg7sHgaNDQ20dbZQYfz5DXW4+ft\ndHaesEZt7l6bPhbU5p417ZPXwM3HrX1bute2rd3Te8L1M0F6/MF/57pm6U6/K45x155OZXDuqRa3\nYjIM5k+J4ZJJ0Tz6TAbvZx9i94Fq7rg6mZHhusDDhTCbzJgxg/nM52afK3f9JehuPcnQp8MxZcDE\nRvjzwJcnM29yNEcqj/KLZ7fw1qYiOgd2Y4yIyKChEJYBZbWY+eK8JO65KRU/bysvrSvgN//Jpqqu\n94ORRETcjUJYXGL8qBAe+tpUJiWGsvtADQ88lcHm3WWuLktEZEAphMVl/H08+M71E1iyYDTtnZ38\n+eUdPPX6Tppa2l1dmojIgNCBWeJShmEwa2IUo2MC+etrO1m/o4S8gzV8/epkEqICXF2eiEi/0pqw\nDAoRIb78+NZ0Fk4bSUVNM48+l8UrH++no7PT1aWJiPQbhbAMGhazic9fFs8PvziJQJsHr3y8n0ef\nz6KspsnVpYmI9AuFsAw6o0cE8dBtU5k61kHBoToe/EcG67cfYYDHlRER6XcKYRmUfL2sfONzydy+\naCwAT72xi7+8kktjs/uNPS0iw5cOzJJByzAMLhkfQWJ0IH97bSebd5eRf6iWry8ax5iRQa4uT0Tk\ngmlNWAY9e6A3P7plEtfOiKO2oZVf/yeblesKaO/QQVsiMrQphGVIMJtMfG56HPd/KQ17oDdvbiri\n4WczOVLZ6OrSRETOm0JYhpT4qACWfXUKl06IoKi0noee3sx/PyjQsJciMiRpn7AMOd6eFm5bOJaU\n+BCeXb2HNzYW8damA0weY2deegzxUf49F6MXERnMFMIyZE0e4yAlPoRNO0t5d0sxGbvKyNhVRmy4\njXmTo5kyJgyrRRt7RGTwUgjLkOZhNTMzNZIZKRHsOVDDmi3FbM2v4O+v7+LF9wuYNTGS2ZOiCPDz\ndHWpIiInUQiLWzAMgzEjgxgzMojymibeyzrIhzlHeHV9IW9sLGLqWAfzJscQF+Hv6lJFRHoohMXt\n2AO9uXlOItdcGsfGHSW8m3mQjbmlbMwtJSEqgHmTo0lLsmMxa1O1iLiWQljclpeHhdlp0cyaFEVu\nYRXvbjnItoJK8g/VEmTzZPakKC6bGInNx8PVpYrIMKUQFrdnGAbj40IYHxdCadVR1mYe5OPtR1j1\n4T5eXV/IxclhzJ8cQ4zDz9WlisgwoxCWYSUs2Icvzk/iupmj+Hjbka5A3naEj7cdYXRMIPMmxzAp\nMRSTSac4iUj/UwjLsOTtaWH+lBjmTo5mW0Ela7cUk1tYzZ7iGkIDvJiTFs2M1Ah8vayuLlVE3JhC\nWIY1k2EwMSGUiQmhHKpoZG3mQTbsOMKL7+fz8sf7uGR8BHPTo4kK9XV1qSLihhTCIt2iQn1ZcsVo\nPn/ZKD7K6dpUvS77EOuyD5EcG8TcyTGkxIdg0mhcItJHFMIin+HrZWXBRSO4fEoM2XsrWJvZtak6\nt7AaR6A3c9OjuTQlAm9P/fiIyIXRbxGR0zCZDNJH20kfbedAaT1rMw+yaWcp/1m7l1Uf7ePSCV2b\nqu12m6tLFZEhSiEschZGhNn46lVjuWFWPB/mHOa9rEOszTzI2syDpI9xcFlKBOPigrWpWkTOiUJY\n5BzYfDxYOC2WK6aOIHtvBWu2FJO5u4zM3WWEB/swNz2a6RPC8fLQj5aI9E6/KUTOg8VsYsoYB1PG\nOKht7uCld/eQsauU59fkserDAmakRDInPRpHoLerSxWRQUwhLHKBEmICuX3ROG6cncAH2Yd4P/sQ\n72wuZs3mYlITQpk3OZqxI4N0jWMROclZhfDy5cvJycnBMAyWLl1KSkrKSfP89re/ZevWrfzrX//q\n8yJFhoIAXw8+d2kcV00byZbdZazZcpCt+RVsza8gKtSXuZOjmT4+HKvF7OpSRWSQ6DWEMzIyKCoq\nYsWKFRQUFLB06VJWrFhxwjz5+fls3rwZq1WjC4lYzCYuTg7n4uRwCg7XsnbLQTbvLuPZt/fwykf7\nuWLqCGZNitR+YxGh12u5bdy4kXnz5gEQHx9PbW0tDQ0NJ8zz6KOPcvfdd/dPhSJDWHxkAHd8Lplf\nfesSrrx4BM1tHbz4fj4/+H8bePXj/TQ0tbm6RBFxoV7/FK+oqCA5ObnncXBwMOXl5fj5dV1xZtWq\nVUydOpWoqKizesOgIB8sfbw5zl3P03THvtyxJ+i9L7vdRtKoUJYsTOa1j/fz2kcFvPzxflZvPsBV\nl8Rxzcx4gvy9Bqjas+OOn5U79gTu2Zc79nQq57w9zOl09tyvqalh1apVPP3005SWlp7V8tXVR8/1\nLc/IbrdRXl7fp685GLhjX+7YE5x7X/MmRXJpsoN12YdZvfkA/30/n1c/2seMlAgWXDSC0ADXH1Ht\njp+VO/YE7tmXu/Z0Kr2GsMPhoKKioudxWVkZdrsdgE2bNlFVVcUtt9xCa2srBw4cYPny5SxdurSP\nyhZxT14eFhZcNIK56VF8vL2EtzYV8V7WIT7YepiLk8O46uKRRIToohEi7q7XEJ4+fTpPPPEEixcv\nJjc3F4fD0bMpesGCBSxYsACAgwcPcv/99yuARc6B1WJm9qQoZqREkLGrlDc2FrF+ewkbtpeQPsbB\nomkjGRE2PDbLiQxHvYZwWloaycnJLF68GMMwWLZsGatWrcJmszF//vyBqFHE7VnMJi4ZH8HFyeFk\n55Xz+oYituwuY8vuMlLiQ1g0LZaE6ABXlykifcxwHr+TdwD09XZ+d9x3AO7Zlzv2BP3Tl9PpZMf+\nKt7YUEjewVoAxowIZOG0WMbF9v/AH+74WbljT+CefblrT6eiExVFBiHDMJgwKoQJo0LIK67h9Y2F\n7NhXxe4DW4mLsLFwWiwTE0N1wQiRIU4hLDLIJcUEck/MRApL6nhjYxFZe8r546rtRIX6ctW0kUwd\n68Bs6vWUfxEZhBTCIkNEbLg/d143gUMVjby1qYhNuaX87bWdvPh+PpdOiGBGSgSOIB9Xlyki50Ah\nLDLERIX6cvuicVxzaRzvZBSzIbeENzYW8cbGIsaODGJGagTpSXaNUS0yBCiERYYoe6A3t1yexI2z\n48ncU86HOYfZVVTNrqJqfL0sTEsOZ2ZqJNEOP1eXKiKnoRAWGeI8rGamjQ9n2vhwSqqO8tG2w6zf\nXsK7mQd5N/MgcRH+zEyNYOrYMLw99SMvMpjoJ1LEjYQH+3DjrASumzGKbQWVfJhzmO37Ktl/pI4X\n1uYzdayDmamRjIr01/WNRQYBhbCIG7KYTaQl2UlLslNV18zH24/wUc4RPtrW9RUV6suM1EimJYdh\n8/Fwdbkiw5ZCWMTNBft78bnpcSy6JJZdhdV8mHOYrLxyXli7l5Xr8klLsjMjNZKxI4N03rHIAFMI\niwwTJsMgOS6Y5Lhg6o62smlHCR/kHCZjVxkZu8oIDfBiRkoE0ydEDJvLyIm4mkJYZBjy9/Hg8qkj\nmD8lhoLDdXyYc5iMXaX876P9vPzxfiYlOZgQF8TERDsBvtpcLdJfFMIiw5hhGCREBZAQFcAX5iby\nya5SPso5TNaeMrL2lPHs23tIiA4gLcnOpCQ7jkDXX+tYxJ0ohEUEAG9PC7MmRjFrYhQdJhPvbiok\nK6+c/IO17D1Yy4r38om2+5GWFEpakp0Yh5+OsBa5QAphETlJeIgvV0wdwRVTR1Db2EpOfgVZeeXs\nLKzi1fUNvLq+EHugF5MSu47ATogKwGRSIIucK4WwiJxRgK8HM1MjmZkaSVNLO9v3VZKVV862gkre\n2VzMO5uL8ff1YGJC1xry2JFBWC26oITI2VAIi8hZ8/a0MHVsGFPHhtHW3smuoiqy8srJ3lvBhzmH\n+TDnMN6eZiaMCiEtyc6EUSEapUvkDPTTISLnxWoxkRIfSkp8KEuucJJ/qJasvHKy8sp7TnuymE2M\niw0iLcnOxMRQ/DUwiMgJFMIicsFMJoOkmECSYgK5eU4CxWUN3YFcwbaCSrYVVGK8BbERtq5zlWOD\niY8KwGLWZmsZ3hTCItKnDMNgRJiNEWE2rp0xirLqo2TlVbA1v4KCQ7XsP1LP6xuK8PQwMyYmsGcA\nkfBgHx1tLcOOQlhE+pUjyIcFF41gwUUjaGppZ09xDbn7q9hZWEVOQSU5BZUABPt7khzbFcjjYoPx\n87a6uHKR/qcQFpEB4+1pYWJCKBMTQgGorG0mt7ArkHP3V/VcYMIARoZ3bboeH6dN1+K+FMIi4jIh\nAV49pz91djopKq0nd39XIOcfqqWwpJ43NhbhaTUzekRgz/7kiBBtuhb3oBAWkUHBZDKIi/AnLsKf\nRZfE0tzazp4DXZuucwureg7wAgiyefYE8oRRwfh4adO1DE0KYREZlLw8LKQmhJLavem6qq65J5B3\nFlbz8bYjfLztCBazwYRRIVw0LozUhFA8rWYXVy5y9hTCIjIkBPt7MSM1khmpkXQ6nRworWd7QSWb\nd5eRvbeC7L0VeHqYSUsM5aJxYYyLDdZ+ZBn0FMIiMuSYDIPYcH9iw/25enocB8sb+GRnKZ/sLGVj\nbteXn7eVyWMcXDwujIToAFeXLHJKCmERGfKi7X5EX+bH9TNHse9wHZ/sLCVjdxnrsg+xLvsQwf6e\nzEqLYUJsECPCdPUnGTwUwiLiNgzDID4qgPioAG6em8DuAzV8kltKZl45q9blswqICPHhorFhXDQu\njLBgH1eXLMOcQlhE3JLZZOoa/CM2mFuvSKKo4ijvbCoiJ7+Clz/ez8sf7yc23MbF48KYMjaMIJun\nq0uWYUghLCJuz2oxM21CJAnhNppa2sneW86mnaXs3F9NYUk9K97LZ/SIQC4aF0b6aIdG65IBoxAW\nkWHF29PCJeMjuGR8BHVHW9myu4xPdpay+0ANuw/U8Nw7eUwYFcIl48NJTQjBatEpT9J/FMIiMmz5\n+3gwJy2aOWnRVNQ2sXlXGZt2lrI1v+uCEz6eFqaOdXDJ+Ajio/x1QJf0OYWwiAgQGuDNlReP5MqL\nR3KwrIENuSVszC1h3dbDrNt6GEegN5eMD2fa+HDsgd6uLlfchEJYROQzoh1+3ORI4IbL4tlZVMWG\nHSVk7SnvOaArKTqASyZEMHm0Ax8v/RqV86fvHhGR0zCZDMbHhTA+LoSmy9vJ3FPOhh1H2HOghryD\ntTy/Jo9JiaFcMj6c5LhgzCaN0CXnRiEsInIWvD0tXJoSwaUpEVTWNrNpZwnrt5eQsauMjF1l+Pt6\ncPG4MC4ZH06MQwOCyNlRCIuInKOQAC8WTovlqotHUlhSz4btJXyyq5R3NhfzzuZiou2+XDI+govG\n6fxjOTOFsIjIeTKMTy+/ePPcBLYXVLJhRwlb8yt48f18XlqXT3JsMJeMD2dSkl1XeJKTKIRFRPqA\nxWxiUpKdSUl2Gpra2LyrlA07Stixv4od+6vw9DCTMiqEiYmhTBgVogFBBFAIi4j0OT9vK7PTopmd\nFk1J1VE27Cjhk50lbN5dxubdZZgMg6SYACYmhDIxMRRHkMawHq7OKoSXL19OTk4OhmGwdOlSUlJS\nep578cUXWblyJSaTiTFjxrBs2TIdkCAi0i082IfrZ47iuhlxHK5o7BoIZG8Fe7pH6HrhvXwiQ32Z\nmBDKpMRQ4iL9Mel36LDRawhnZGRQVFTEihUrKCgoYOnSpaxYsQKApqYm3njjDZ5//nmsVitLliwh\nOzubtLS0fi9cRGQoMQyDKLsfUXY/Fk6LpbahhZyCSrburWBnYRVvbirizU1F+PtYSe1eQx4XG6z9\nyG6u1xDeuHEj8+bNAyA+Pp7a2loaGhrw8/PD29ubZ555BugK5IaGBux2e/9WLCLiBgL8PJmZGsnM\n1Eha2jrYWVjF1r0V5ORX8NG2I3y07QhWS9eVoCYmhpIaH0KAn460dje9hnBFRQXJyck9j4ODgykv\nL8fPz69n2l//+leeffZZlixZQkxMTP9UKiLipjytZiYl2pmUaKfT6WT/4Tq25leQvbeiZxxrAxgV\n6c/ExFAmJoQSGeqrXX9u4JwPzHI6nSdNu+OOO1iyZAlf//rXSU9PJz09/bTLBwX5YOnjq5LY7bY+\nfb3Bwh37cseewD37Uk+uE+bw5+KJ0QAcrmggI7eUjNwScvdXUnC4jv9+sI/wEB+mJodzaUoUY2KD\n3C6Qh8pndaF6DWGHw0FFRUXP47Kysp5NzjU1Nezdu5cpU6bg5eXFzJkzycrKOmMIV1cf7YOyP2W3\n2ygvr+/T1xwM3LEvd+wJ3LMv9TR4WIHp4xxMH+egoamN7fu69iNv31fJqx/u49UP9xER4sOMlEim\njQ8nwNfD1SVfsKH6WZ3J6f6o6HWg0+nTp7N69WoAcnNzcTgcPZui29vbue+++2hsbARg+/btxMXF\n9VXNIiJyHD9vK9OSw/nWteN5/K4Z3H1TKjMnRlFe08SL7+fzf39azxP/3cbW/Ao6OjtdXa6chV7X\nhNPS0khOTmbx4sUYhsGyZctYtWoVNpuN+fPnc+edd7JkyRIsFgujR49m7ty5A1G3iMiwZrWYmDAq\nhDkXxbL/QBWbckv4aNsRsvd27UsO9PNg+oSusa7DdB7yoGU4T7WTtx/19SYGd9xsAe7Zlzv2BO7Z\nl3oaOo7vy+l0UlRaz0fbjrApt5SmlnYARscEMiM1gvTRjiFxypM7flan2xytEbNERNyEYRjEhvsT\nG+7PzbMTyMwr56Ocw+w+UMOe4hqeX5PHRWPDmJEaSWy4ze0O5hqKFMIiIm7Iw2pmWnI405LDKas+\nysfbj7B+ewnrth5m3dbDRNt9ew7m0jjWrqMQFhFxc44gH66fGc+1l45ix/4qPtp2mK17K/jP2r28\ntC6fSYl2ZqRGMG5kMCaT1o4HkkJYRGSYMJkMUuJDSIkPoe5oK5t2dB3MdezCEiH+nkyfEMElEyJw\nBHq7utxhQSEsIjIM+ft4cPnUEcyfEsO+I3V8lHOEjF2lvLq+kFfXF+II8mbcyCDGdH/5+wz9848H\nI4WwiMgwZhgG8ZEBxEcG8IW5iWzeXUZWXjl7iqt79h8DxDj8GDsyiLEjg0iKCcTbU/HRF/SvKCIi\nAHh6mLk0pevc4o7OTgpL6tlVWM2uomr2HqyluKyBdzYXYzYZxEX494RyfFQAVkuvYz/JKSiERUTk\nJGaTqWcNedElsbS1d5K1dJkAAAs3SURBVJB/sJadRdXsLqpm3+E68g/V8tqGQjwsJhKjAxgbG8zY\nkUGMDLPpAK+zpBAWEZFeWS3mrpCNDYb/397dx1RV/3EAf597L0+Xp8u9cC+gP3y4KiI/RTITZIAP\naelW2T9Otjtro1Uq0pyF2DLY2iLl1nLUKug5a2tha1htupb7rSmQqT8U+BUh0xAFuZcHuYTQvX5/\nf1w9eQUUSjn30Pu1MXbO9x73+e57jm/O954HAL9fcaOptQeN57rw87luNJz1/gCAPkiHxASD90x5\nuhHxJj3vSR4FQ5iIiMZNH6zzvlZxdjQAoLd/CD+f805d/+9cl/z4TACIDAtE0rQozJ9pwvyZJt6X\nfAOGMBER/W2RoYFYMs+CJfMsAABHz8C1QO5G47lu1DR0oKahA5IEWKdEIsVqQsqsaEz5h78XmSFM\nRER3XLQhBJmGEGSmxEMIgbbOfpxqcaKu2YHmtl40n+/F/v+0wBQRjAWzTEixRiNpmgEBd/h98/6O\nIUxERHeVJEmYag7DVHMY1qZNk9+LXNfsQH1LFw6faMPhE20IDNBg3jQjMhZOwUxLGKLCg5Qu/a5j\nCBMR0YS6/l7k9ORYeK5eRfP5XtSd8Ybyf6/9AECCJQwp1mikzIrG9LhwaCbhtDVDmIiIFKPVaJCY\nEIXEhCisXz4Ll3oG0NLuwpG6NvzyWzd+63DhwNGziNAHYL7VO22dPMM4aR4WMjl6QUREk4LZEILk\n2WakzY3BwKAbjWe7UXfGgVNnnDhyuh1HTrdDq5GQmGDAAms05iYYEGfSq/a7ZIYwERH5pZAgHRYl\nxmBRYgyuCoFz7X2oa3ag7owTjWe70XjtvmRJ8r4pakp0KOKjQzHl2k+sSQ+d1r+f5MUQJiIiv6eR\nvI/KnBEXgXWZM9HjGsSpM06cbe/DhU4X2hz9ONH0O040dfpsYzGG/BnOMWGIjw6FJSrEb8KZIUxE\nRKpjCAtCVko8slK8y0II9PYPoc3Rjwud/d7fDu/vi87fgV/+DGetRkKsUX8tmEPlkDZHhUCrmdhw\nZggTEZHqSZIEQ1gQDGFBSL72aE3AG87dfYNyIN8Yzm2Ofhz7+c9/Q6eVEGsMxZx/RWLDytkTcrbM\nECYioklLkiQYI4JhjAjGv2ea5PVCCHRdHkSbw+V79uzsR2fvANZlzkRYCEOYiIjojpMkCabIYJgi\ng7HAGi2vvyoErl4VE/adMUOYiIjoGo0kQaOduIeC+MflYURERP9ADGEiIiKFMISJiIgUwhAmIiJS\nCEOYiIhIIQxhIiIihTCEiYiIFMIQJiIiUghDmIiISCEMYSIiIoUwhImIiBQiCSGE0kUQERH9E/FM\nmIiISCEMYSIiIoUwhImIiBTCECYiIlIIQ5iIiEghDGEiIiKF6JQuYDxefvll1NXVQZIkPP/881iw\nYIHcdvToUbz22mvQarXIysrCli1bFKx07Pbs2YPjx4/D7XbjqaeewurVq+W2FStWIDY2FlqtFgBg\nt9thsViUKnXMamtr8cwzz2D27NkAgDlz5mDXrl1yuxrH6osvvkBVVZW8XF9fj5MnT8rLycnJuOee\ne+TlDz/8UB43f9TU1ITNmzfj8ccfh81mw8WLF1FQUACPx4OYmBiUlpYiMDDQZ5tbHX/+YKQ+7dy5\nE263GzqdDqWlpYiJiZE/f7v91F/c3K/CwkI0NDTAYDAAAHJzc7Fs2TKfbdQ2Vvn5+eju7gYA9PT0\nYOHChXjppZfkz3/55ZfYu3cvEhISAABLly7Fpk2bFKn9jhMqUVtbK5588kkhhBDNzc1i/fr1Pu1r\n1qwRFy5cEB6PR+Tk5Ihff/1ViTLHpbq6WjzxxBNCCCG6urpEdna2T/vy5cuFy+VSoLK/p6amRmzd\nunXUdjWO1Y1qa2tFcXGxz7r77rtPoWrGr7+/X9hsNvHCCy+ITz75RAghRGFhofj222+FEEK8+uqr\n4tNPP/XZ5nbHn9JG6lNBQYH45ptvhBBC7Nu3T+zevdtnm9vtp/5gpH7t2LFDfP/996Nuo8axulFh\nYaGoq6vzWbd//37xyiuvTFSJE0o109HV1dW4//77AQBWqxW9vb1wuVwAgNbWVkRGRiIuLg4ajQbZ\n2dmorq5WstwxWbx4Mfbu3QsAiIiIwMDAADwej8JV3V1qHasbvfnmm9i8ebPSZfxlgYGBqKiogNls\nltfV1tZi5cqVAIDly5cPG5NbHX/+YKQ+FRUV4YEHHgAAREVFoaenR6ny/rKR+nU7ahyr61paWtDX\n1+d3Z+53k2pC2OFwICoqSl42Go3o7OwEAHR2dsJoNI7Y5s+0Wi30ej0AoLKyEllZWcOmMIuKipCT\nkwO73Q6hooebNTc34+mnn0ZOTg6OHDkir1frWF136tQpxMXF+UxrAsDQ0BC2b9+ODRs24IMPPlCo\nurHR6XQIDg72WTcwMCBPP5tMpmFjcqvjzx+M1Ce9Xg+tVguPx4PPPvsMDz300LDtRttP/cVI/QKA\nffv2YePGjdi2bRu6urp82tQ4Vtd9/PHHsNlsI7b9+OOPyM3NxWOPPYbGxsa7WeKEUtV3wjdSUyDd\nznfffYfKykq8//77Puvz8/ORmZmJyMhIbNmyBQcPHsSDDz6oUJVjN336dOTl5WHNmjVobW3Fxo0b\ncejQoWHfMapRZWUlHn300WHrCwoK8PDDD0OSJNhsNtx7772YP3++AhX+fWM5ttRy/Hk8HhQUFCAt\nLQ3p6ek+bWrdTx955BEYDAYkJSWhvLwcb7zxBl588cVRP6+WsRoaGsLx48dRXFw8rC0lJQVGoxHL\nli3DyZMnsWPHDhw4cGDii7wLVHMmbDab4XA45OVLly7JZyM3t3V0dIxr+kZJP/zwA95++21UVFQg\nPDzcp23dunUwmUzQ6XTIyspCU1OTQlWOj8Viwdq1ayFJEhISEhAdHY2Ojg4A6h4rwDttm5qaOmx9\nTk4OQkNDodfrkZaWppqxuk6v1+PKlSsARh6TWx1//mznzp2YNm0a8vLyhrXdaj/1Z+np6UhKSgLg\nvXjz5n1NrWN17NixUaehrVarfPFZamoqurq6Js1Xd6oJ4YyMDBw8eBAA0NDQALPZjLCwMADA1KlT\n4XK5cP78ebjdbhw+fBgZGRlKljsmfX192LNnD9555x35Sscb23JzczE0NATAu4Nev4rT31VVVeG9\n994D4J1+djqd8lXdah0rwBtOoaGhw86UWlpasH37dggh4Ha7ceLECdWM1XVLly6Vj69Dhw4hMzPT\np/1Wx5+/qqqqQkBAAPLz80dtH20/9Wdbt25Fa2srAO8fhTfva2ocKwA4ffo05s6dO2JbRUUFvv76\nawDeK6uNRqNf330wHqp6i5LdbsdPP/0ESZJQVFSExsZGhIeHY9WqVTh27BjsdjsAYPXq1cjNzVW4\n2tv7/PPPUVZWhhkzZsjrlixZgsTERKxatQofffQRvvrqKwQFBWHevHnYtWsXJElSsOKxcblcePbZ\nZ3H58mX88ccfyMvLg9PpVPVYAd7bkl5//XW8++67AIDy8nIsXrwYqampKC0tRU1NDTQaDVasWOHX\nt0/U19dj9+7daGtrg06ng8Vigd1uR2FhIQYHBxEfH4+SkhIEBARg27ZtKCkpQXBw8LDjb7T/MJUw\nUp+cTieCgoLkALJarSguLpb75Ha7h+2n2dnZCvfE10j9stlsKC8vR0hICPR6PUpKSmAymVQ9VmVl\nZSgrK8OiRYuwdu1a+bObNm3CW2+9hfb2djz33HPyH7r+eNvVX6WqECYiIppMVDMdTURENNkwhImI\niBTCECYiIlIIQ5iIiEghDGEiIiKFMISJiIgUwhAmIiJSCEOYiIhIIf8H8GOiXzI1GnEAAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "m1ieRLJXxc4u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
        "embedding.weight.data.copy_(TEXT.vocab.vectors) # copies pre-trained word vectors\n",
        "\n",
        "training_embeddings, training_labels = transfrom_for_scikit('subtask_a', TEXT, LABEL, embedding, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7p1nXF7VxRTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "b3b44103-4f05-42a4-a356-066e9a6c17f2"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=20, tol=None, class_weight={1: 2})\n",
        "\n",
        "clf.fit(training_embeddings, training_labels)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.001, average=False, class_weight={1: 2},\n",
              "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=20,\n",
              "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
              "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
              "       validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "metadata": {
        "id": "jY98yEhJxoSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_embeddings, val_labels = transfrom_for_scikit('subtask_a', TEXT, LABEL, embedding, valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r6jidX2iyKwj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "d513b944-8747-4978-d2f5-8e339ea21feb"
      },
      "cell_type": "code",
      "source": [
        "preds = clf.predict(val_embeddings)\n",
        "\n",
        "print(metrics.confusion_matrix(val_labels, preds))\n",
        "print(metrics.classification_report(val_labels, preds))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(val_labels, preds))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1426  347]\n",
            " [ 476  399]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.80      0.78      1773\n",
            "           1       0.53      0.46      0.49       875\n",
            "\n",
            "   micro avg       0.69      0.69      0.69      2648\n",
            "   macro avg       0.64      0.63      0.63      2648\n",
            "weighted avg       0.68      0.69      0.68      2648\n",
            "\n",
            "Accuracy: 0.6891993957703928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VFiG4aRQPpN5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task B"
      ]
    },
    {
      "metadata": {
        "id": "2YbsX0DyP1B0",
        "colab_type": "code",
        "outputId": "23d20c1c-26c4-4bd8-fa33-da4d85d7a2d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first=True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a', LABEL),\n",
        "               ('subtask_b',LABEL)\n",
        "              ]\n",
        "\n",
        "train = data.TabularDataset(train_fp,\n",
        "                            format='TSV',\n",
        "                            fields=data_fields,\n",
        "                            skip_header=True,\n",
        "                            filter_pred=lambda d: d.subtask_a == 'OFF')\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "# This is where tokenization is performed on train\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d')\n",
        "\n",
        "LABEL.build_vocab(train.subtask_b)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "print(LABEL.vocab.stoi)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 3520\n",
            "Validation size: 880\n",
            "defaultdict(<function _default_unk_index at 0x7fee2eecb6a8>, {'TIN': 0, 'UNT': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uww_bdubSnf3",
        "colab_type": "code",
        "outputId": "8b49dd56-398b-479a-aa59-019c29a24a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5782
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab, embedding_dim, window_size, out_channels, dropout)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_b',\n",
        "                                  model,\n",
        "                                  optimizer,\n",
        "                                  loss_fn = loss_fn,\n",
        "                                  epochs = 20,\n",
        "                                  train_loader=train_iterator,\n",
        "                                  valid_loader=valid_iterator)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 0.7425\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "[[768   0]\n",
            " [112   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 0.4688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "[[768   0]\n",
            " [112   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 0.3960\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 768 / 880 correct (87.27)\n",
            "[[768   0]\n",
            " [112   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.00      0.00      0.00       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.44      0.50      0.47       880\n",
            "weighted avg       0.76      0.87      0.81       880\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.2444\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[768   0]\n",
            " [111   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.94      0.50      0.48       880\n",
            "weighted avg       0.89      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.3320\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[768   0]\n",
            " [111   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.94      0.50      0.48       880\n",
            "weighted avg       0.89      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.3889\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[768   0]\n",
            " [111   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.94      0.50      0.48       880\n",
            "weighted avg       0.89      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.3955\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[768   0]\n",
            " [111   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.94      0.50      0.48       880\n",
            "weighted avg       0.89      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.2923\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[768   0]\n",
            " [111   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.01      0.02       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.94      0.50      0.48       880\n",
            "weighted avg       0.89      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.3602\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 770 / 880 correct (87.50)\n",
            "[[768   0]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       1.00      0.02      0.04       112\n",
            "\n",
            "   micro avg       0.88      0.88      0.88       880\n",
            "   macro avg       0.94      0.51      0.48       880\n",
            "weighted avg       0.89      0.88      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.3019\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.2834\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.2668\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.2525\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.2077\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.2513\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.2616\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.2226\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.2668\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.2147\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.2171\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 769 / 880 correct (87.39)\n",
            "[[767   1]\n",
            " [110   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93       768\n",
            "           1       0.67      0.02      0.03       112\n",
            "\n",
            "   micro avg       0.87      0.87      0.87       880\n",
            "   macro avg       0.77      0.51      0.48       880\n",
            "weighted avg       0.85      0.87      0.82       880\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AiLub0TBVF_i",
        "colab_type": "code",
        "outputId": "896774e5-5393-41b7-b873-d833d18b764e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl4VPXd///nmTXLZE8meyCEsIVN\ndgTBBSzgQqtVaS201WptpVp729byraJVqW3Vtm6/1ruulbtCFZWK1l1RtrAvYU2ALGTfF7Jnfn8k\nxCCEBEmYyeT1uC6umTkzZ+b9ZpTXnM9ZPobL5XIhIiIiHsPk7gJERETkZApnERERD6NwFhER8TAK\nZxEREQ+jcBYREfEwCmcREREPo3AW6aOGDh1Kfn6+u8sQkV6gcBYREfEwFncXICI9q76+nocffphN\nmzZhMpmYOXMmv/zlLzGbzbzyyissX74cl8uFw+Hg97//PcnJyZ0uT09P5/7776eoqAibzcayZcsY\nNWoUNTU1/OpXv+Lw4cM0NDQwdepUli5ditVqdXf7Il5B4SziZV566SXy8/NZs2YNTU1NfO973+Pt\nt9/msssu469//SuffPIJDoeDd999l08//ZTo6OjTLk9KSuL222/nRz/6Eddddx1bt27lpz/9KZ98\n8glvvvkmgYGBvPvuuzQ1NfHggw+Snp7O8OHD3d2+iFdQOIt4mU8//ZSbbroJi8WCxWLhqquuYt26\ndcybNw/DMHjttde48sormTt3LgCNjY2nXZ6enk5JSQnf/va3ARg/fjyhoaFs3769/faLL75g0qRJ\nPPDAA27rV8QbaZ+ziJcpLS0lKCio/XFQUBAlJSVYrVZefPFFtm3bxje+8Q2++93vcuDAgU6XV1ZW\nUldXx9y5c5kzZw5z5syhpKSE8vJy5s6dyw9+8AP++te/MnXqVB544AEaGhrc2LWId9GWs4iXCQ8P\np7y8vP1xeXk54eHhAIwYMYInnniChoYG/vGPf7B06VJeffXV0y5/9NFH8ff357///e9pP2fBggUs\nWLCAgoICfvazn/Hmm29y/fXXn5ceRbydtpxFvMzFF1/Ma6+9RnNzM8ePH+ett95i5syZHDhwgDvu\nuIOGhgZsNhsjR47EMIxOl8fGxhIVFdUezqWlpfziF7/g+PHjPP3007z22msAREZGEhcXh2EY7mxb\nxKtoy1mkD1u4cCFms7n98UMPPcTChQvJzs7miiuuwDAM5syZ074fOS4ujiuvvBKr1Yq/vz/33Xcf\nQ4YMOe1ywzB4/PHHuf/++/nLX/6CyWTihz/8IX5+fsyfP5/f/OY3/O///i+GYTBmzBjmz5/vrr8G\nEa9jaD5nERERz6JhbREREQ+jcBYREfEwCmcREREPo3AWERHxMApnERERD+Mxp1IVFVX16PuFhPhR\nVna8R9/TE3hjX+qp7/DGvtRT3+FtfUVEBHT6nNduOVss5q5f1Ad5Y1/qqe/wxr7UU9/hrX2djteG\ns4iISF+lcBYREfEwCmcREREPo3AWERHxMApnERERD6NwFhER8TAKZxEREQ/jMRchEREROZNHHnmE\n7dt3UlpaQl1dHTExsQQGBrFs2Z/OuN477/wHf38HM2dectrn//rXx7juugXExMT2Rtlfi8JZRET6\nhHvuuYeioireeec/HD6cweLFP+/WevPmXXXG5++88396orwepXAWEZE+a9u2Lbz66iscP36cxYvv\nYvv2rXz66Ue0tLQwdeo0brrpVp577u8EBweTmJjEqlUrMQwTmZlHuPjiy7jppltZvPhWfvGLX/HJ\nJx9RU1NNVlYmx47lcMcd/8PUqdN45ZUX+fDD94mJiaWpqYkFC25k3LgJvdqXV4ZzTlE1uWV1xIT4\nuLsUERGvs/LjdDbvL+zR95w4zMn1lw7+WutmZKTzr3+twmazsX37Vp555h+YTCauv34+N9zw3ZNe\nu3dvGv/3f6/T0tLCddddxU033XrS84WFBTz66BNs3Liet956nZSUkaxa9W/+9a/XqampYcGCa1iw\n4Mav3Wd3eWU4r/rsMHuOlPDXOy7C1+6VLYqISJvBg5Ox2WwA+Pj4sHjxrZjNZsrLy6msrDzptUOH\nDsPHp/MNt9GjxwLgdDqprq4mJyebQYOSsNt9sNt9GD48pfca6cArkys2wp8d6cVkHKtg5KAwd5cj\nIuJVrr908Nfeyu0NVqsVgPz8PFasWM7zzy/Hz8+PhQuvP+W1ZvOZJ8/o+LzL5cLlApPpyxObDKOH\niu6CV55KNTQ+GIAD2eVurkRERM6X8vJyQkJC8PPz48CB/eTn59PY2HhO7xkdHc3hwxk0NTVRVlbG\n/v37eqjaM/PKLeek2CBMhsJZRKQ/SU4egq+vHz/5yU2MGjWW+fOv4bHH/sDo0WO+9nuGhoYxe/Yc\nbrllEQMGJDJiREqXW989wXC5XK5e/5RuKCqq6tH3W7Z8G0eOVfD0XTOwWb1nDtCIiIAe/7tyN/XU\nd3hjX+qp73BXX++88x9mz56D2Wxm0aIFPP74kzidkef8vhERAZ0+55VbzgAjB4WRnl1ORm4lwweE\nuLscERHpo0pKSrj11u9jtdq4/PI5PRLMXfHqcH7zswwOZpcrnEVE5GtbuPAHLFz4g/P6mV55QBjA\niLajtA9qv7OIiPQxXhvOAX424iL8yThWQVNzi7vLERER6TavDWeAofEhNDS1cDTP+w6MEBER7+XV\n4Twk4cT5zmVurkRERKT7vDuc44IAOJhd4eZKRETkXN1www2nXATkb397in/965VTXrtt2xZ++9tf\nAXDPPb845fnXX1/Bc8/9vdPPSk8/RFZWJgBLl/6G+vq6cyn9rHl1OAc57ESG+nEop5yWFo84nVtE\nRL6mK6+8ko8//uCkZZ9++jGzZl1+xvUeeeTxs/6szz77mOzsLAAeeOD32O3ndyIlrz2V6oSh8cGs\n3ZlLVmEVA6MC3V2OiIh8TfPmzeP662/gpz+9A4D9+/cRERHB0aNH+O1vf43VaiUgIIDf/e6Rk9a7\n4orLWLPmI7ZsSeWJJx4jNDSMsLDw9ikgH374foqKCqmtreWmm24lKiqat95axWeffUxISAj33fcb\nXn55BdXVVfz+97+jsbERk8nEPffci2EYPPzw/cTExJKefoghQ4Zyzz33nnOv/SacD2aVK5xFRHrA\nqvS32V64u0ff8wLnKK4ZfOUZXxMWFkZMTCx79+5hxIiRfPzxB8yePYeqqiqWLn2ImJhYHnzwPjZt\n2oCfn98p6//9709x770Pkpw8hLvvvoOYmFiqqiqZNGkKc+deybFjOdx77z08//wrTJ48lYsvvowR\nI0a2r/+Pf/yNK6+cz2WXXc4nn3zI888/y803/5gDB/bxwAPLCAkJ5VvfmkdVVRUBAZ1f/as7vHpY\nG2CIJsEQEfEas2fP4aOPWoe2161by8UXX0ZwcDB/+MNDLF58K9u3b6Wy8vTHGeXl5ZGcPASAsWPH\nARAQEMi+fWn85Cc38fDD93e6LsCBA/u44ILxAIwbN4FDhw4AEBsbT1hYOCaTifDwCGpqqs+5T6/f\ncg4L8iEs0IeD2eW0uFyYztd8XyIiXuqawVd2uZXbW2bOvISXX36e2bO/QXx8AoGBgfz+9w/ypz/9\nhYEDE3n88T90um7HqR9PTCvxwQf/pbKykqef/geVlZX86EcLz/DpRvt6jY1NGEbr+311IoyemLLC\n67ecAYYmBFNT10RucY27SxERkXPg5+dPUlIyL7/8ArNnzwGgpqaayMgoqqqq2LZta6fTRIaHR5CV\ndRSXy8X27VuB1mkmo6NjMJlMfPbZx+3rGoZBc3PzSesPHz6Cbdu2ALBjx1aGDRveW232j3A+MbSt\nS3mKiPR9s2fPYfPmTUyfPgOAa665jp/85Gb++MeHufHGRbzyyouUlBSfst6tt/6U3/721/z613e1\nT15x8cWXsn7959x550/w9fXF6XTywgv/y5gxF/CXv/yJLVtS29f/0Y9u47//fYc77riNd955m5tv\n/nGv9ei1U0Z2nFqsoPQ4v3l2I5OGO7lt/sgu1vRs3jgVnHrqO7yxL/XUd3hbX2eaMrJfbDk7Q3wJ\nctg4kFXeI/sCREREelO/CGfDMBgaH0xFTQOFZbXuLkdEROSM+kU4g06pEhGRvqPfhbMOChMREU/X\nb8I5Jtwfh6+VA1kKZxER8Wz9JpxNhkFyXBAllXUUV2i/s4iIeK5+E87Qep1tgEOaQlJERDxYvwrn\nIQknDgorc3MlIiIinetX4ZzgDMDHZuaAtpxFRMSD9atwNpkMkuOCKSg9TkV1vbvLEREROa1+Fc4A\nQ+KDADiYo61nERHxTN0K52XLlnHDDTewYMECdu3addrXPPbYYyxc2DrV1qZNm5gyZQoLFy5k4cKF\nPPjggz1X8TkamhACwIEs7XcWERHP1OV8zqmpqWRmZrJixQoyMjJYsmQJK1asOOk16enpbN68GavV\n2r5s0qRJPPHEEz1f8TkaGBWAzWLSxUhERMRjdbnlvGHDBmbNmgVAUlISFRUVVFdXn/SaRx55hLvu\nuqt3KuxhFrOJpNggcopqqK49/ZyfIiIi7tTllnNxcTEpKSntj0NDQykqKsLhcACwatUqJk2aRGxs\n7Enrpaenc9ttt1FRUcHixYuZNm3aGT8nJMQPi8X8dXroVGfTcV0w1Mm+zDIKKutJTAjt0c88H840\nzVhfpZ76Dm/sSz31Hd7a11d1Gc5f1XHKxfLyclatWsULL7xAQUFB+/KBAweyePFi5s6dS3Z2NosW\nLeL999/HZrN1+r5lZcfPtpQzOtO8n3FhfgBs3pNHUqSjRz+3t3nbfKagnvoSb+xLPfUd3tbXOc3n\n7HQ6KS4ubn9cWFhIREQEABs3bqS0tJQbb7yRxYsXk5aWxrJly4iMjGTevHkYhkFCQgLh4eEnhbe7\nDYoJxGwytN9ZREQ8UpfhPG3aNN577z0A0tLScDqd7UPac+bM4Z133mHlypU89dRTpKSksGTJElav\nXs1zzz0HQFFRESUlJURGRvZiG2fHZjWTGBNIZkEVtfVN7i5HRETkJF0Oa48bN46UlBQWLFiAYRgs\nXbqUVatWERAQwOzZs0+7zqWXXsrdd9/NRx99RGNjI/fff/8Zh7TdYWh8MOk5FaQfq2DUoDB3lyMi\nItKuW/uc77777pMeDxs27JTXxMXF8c9//hMAh8PB3/72tx4or/cMjQ9mzYZMDmaXK5xFRMSj9Lsr\nhJ2QFBuEYcAB7XcWEREP02/D2dduYUBkAEdyK2lobHZ3OSIiIu36bTgDDE0IprnFRUZupbtLERER\nadevw3lIfOv8zjqlSkREPEm/DufkOIWziIh4nn4dzg5fK3ER/mQcq6CpucXd5YiIiAD9PJwBhsaH\n0NDUwtE877kknIiI9G39PpyHJLQObR/I1vzOIiLiGRTOcUEAHMyucHMlIiIirfp9OAc57ESF+nEo\np5zmFu13FhER9+v34Qytp1TVNTSTXVjt7lJEREQUztB6nW2Ag1k6pUpERNxP4cyXFyPRdbZFRMQT\nKJyBsCAfwoN8OJhdTovL5e5yRESkn1M4txkSH0xNXRO5xTXuLkVERPo5hXMbXWdbREQ8hcK5zYmD\nwg7ooDAREXEzhXMbZ4gvQQ4bB7PLcWm/s4iIuJHCuY1hGAyND6aipoHCslp3lyMiIv2YwrkDnVIl\nIiKeQOHcgfY7i4iIJ1A4dxAd7o/D16ojtkVExK0Uzh2YDIPkuCBKKusortB+ZxERcQ+F81cM1fnO\nIiLiZgrnrxiaEAIonEVExH0Uzl8R73TgYzNzILvC3aWIiEg/pXD+CpPJIDkumILS41RU17u7HBER\n6YcUzqcxJD4I0PnOIiLiHgrn09B+ZxERcSeF82kMjArAZjEpnEVExC0UzqdhMZtIig0ip6iG6tpG\nd5cjIiL9jMK5EyfOdz6krWcRETnPFM6d0CQYIiLiLgrnTgyKCcRsMrTfWUREzjuFcydsVjOJMYFk\nFlRRW9/k7nJERKQfUTifwdD4YFwuSD+mq4WJiMj5o3A+A02CISIi7qBwPoOk2CAMQweFiYjI+aVw\nPgNfu4UBkQEcya2kvrHZ3eWIiEg/oXDuwtCEYJpbXBzOrXR3KSIi0k8onLswRPudRUTkPFM4dyE5\nLhgDhbOIiJw/CucuOHytxEY4yDhWQVNzi7vLERGRfkDh3A1D44NpaGrhaF6Vu0sREZF+oFvhvGzZ\nMm644QYWLFjArl27Tvuaxx57jIULF57VOn3FkIQT19kuc3MlIiLSH3QZzqmpqWRmZrJixQoefvhh\nHn744VNek56ezubNm89qnb5kSFwQoPOdRUTk/OgynDds2MCsWbMASEpKoqKigurq6pNe88gjj3DX\nXXed1Tp9SZDDTlSoH+k5FTS3aL+ziIj0ri7Dubi4mJCQkPbHoaGhFBUVtT9etWoVkyZNIjY2ttvr\n9EVD4oOpa2jWfmcREel1lrNdweVytd8vLy9n1apVvPDCCxQUFHRrnc6EhPhhsZjPtpwziogI6LH3\nmjk+nrU7c3n+nf38/vZphAX59th7n62e7MtTqKe+wxv7Uk99h7f29VVdhrPT6aS4uLj9cWFhIRER\nEQBs3LiR0tJSbrzxRhoaGsjKymLZsmVnXKczZWXHv24PpxUREUBRUc9t5SY6/bnywoG8vf4ov3n6\nC3793XEE+tt67P27q6f78gTqqe/wxr7UU9/hbX2d6YdGl8Pa06ZN47333gMgLS0Np9OJw+EAYM6c\nObzzzjusXLmSp556ipSUFJYsWXLGdfqyb12UyOUT48krOc5jK3ZQXdvo7pJERMQLdbnlPG7cOFJS\nUliwYAGGYbB06VJWrVpFQEAAs2fP7vY63sAwDG64dDANTS18uv0Yf165k7sXjMXXftZ7B0RERDpl\nuLqzQ/g86Omhit4c/mhxuXhhzT7W7clnSFwQd10/FrutZ/eXd8bbhnVAPfUl3tiXeuo7vK2vcxrW\nllOZDIMfzhvOxGFODuZU8OSqXTQ2aUpJERHpGQrnr8lkMrjlqhGMHRzO3qNlPPPGHl17W0REeoTC\n+RxYzCZ+8s0UUhJD2ZlRwrP/2auLlIiIyDlTOJ8jq8XM4mtGMSQ+mC37C3l+zX5aPGM3voiI9FEK\n5x5gt5q589ujGRQTyIa0fP753oFuXXhFRETkdBTOPcTXbuGu68eQ4HTw2Y5cXv0oXQEtIiJfi8K5\nB/n7WPnFgrHEhPvzwZZs3vj8sLtLEhGRPkjh3MMC/WzcvWAszhBf3l6fyX/WH3V3SSIi0sconHtB\nsMPOLxdcQFignTfWHub9zdnuLklERPoQhXMvCQvy4ZffuYAgh41XPzrEp9uPubskERHpIxTOvcgZ\n4scvF1xAgJ+Vf753gHW789xdkoiI9AFeGc77Sg7y1r73aWhucHcpxIT78z83jMXPx8Lz7+xj8/5C\nd5ckIiIezivDeWvhTpbveoOHU//MgdJ0d5dDQmQAv7hhLHarmWdXp7HjUHHXK4mISL/lleF8/ZD5\nXD1sNiW1pTyx41le2fdvahqPu7WmxOhAfn7dGMxmg2fe3E3akVK31iMiIp7LK8PZZrbxvTHX8KsJ\nPyPOEcOGvM08uOlRthXucuuFQYbEB/Oza0cDBk++vosDWWVuq0VERDyXV4bzCQmBcfxqws+YnzSX\nuqY6ntvzCn/f/RJldeVuqyllYCi3f2skzS0u/vLaLg7nVrqtFhER8UxeHc4AZpOZywdcwpJJd5Ec\nPIjdxXt5aNNjrM3ZQIvLPTNIjRkczo+vTqGhsZnHV+wgq8B7Jg8XEZFz5/XhfILTL4I7L/gxNw77\nNoZhsOLgG/xl29/Ir3HP0dMThjn50RUjqK1v4vGVOykqr3VLHSIi4nn6TTgDGIbBhTGTuHfy3YyN\nGEVGxVF+n/pn3j3yEU0tTee9nqkjo/jOrGQqaxr488qdVNc2nvcaRETE8/SrcD4hyB7ILaMWcsuo\nRfhb/Xj7yHv8YfMTHK3MOu+1zJoQz9zJCeSXHuevr+2kobH5vNcgIiKepV+G8wljI0by28l3Mz1m\nMrk1+Ty65WleO7Sauqb681rHtRcnMSUlkoxjlfx9dRotLZpqUkSkP+vX4QzgZ/XlO8Ou5ecX3EaE\nXxifZH/Bw6mPk1Zy4LzVYDIMbpo3nOEDQth+qJjlHx7UXNAiIv1Yvw/nE5JDBrFk4l3MGXAp5fUV\nPLPzOV5Me5Xqhprz8vkWs4nbvzWKuAgHn2w7xjsbM8/L54qIiOdROHdgNVu5KmkOv55wBwkBcWwu\n2MaDmx5lc/7287Il6+dj4a7rxxAaaOf1zw6zfo8myhAR6Y8UzqcRFxDDLycs5trBV9LQ3MCLe//F\nM7uep6S296/oFRJg567rxuBnt/DCO/tJO6rLfIqI9DcK506YDBOXJszg/03+H4aHDmFvyQEeSn2M\nVelv9/oVxmIjHPzs2lEYBjy9arcuUiIi0s8onLsQ7hvK7WNuZtHwG/Ax2/koay33bXiEl/a+Sk5V\nbq997tCEEG65KoX6hmb+/O+dFFfoIiUiIv2FwrkbDMNgcvR4fnfhb/jesOtw+kWQmr+N32/+C09u\n/1/2lfbO0dUThzm54bJkKqp1kRIRkf7E4u4C+hKrycLUmIlMjh7P3pIDfJS1lv1lh9hfdohYRzSX\nxc9gQuRYzCZzj33m5RPjKa2s4/3N2Tz5+i4eWXxRj723iIh4JvP9999/v7uLADh+vKFH38/f397j\n73mCYRg4/SKYEj2BkWHDqGuq51D5YXYU7WFD3hZcuIj2j8Jq6pnfPiMSQ8kvPc7uw6XkFFYxNikc\nwzB65L09QW9+V+7ijT2Bd/alnvoOb+vL39/e6XPacj5HAwLjuWnkjZTUlvJJzhesy03ljfQ1vHvk\nI6bFTuKSuOmE+ASf02eYDIObrxhBRXUD63fl4Wc1851ZyV4V0CIi8iVtOfcQP6svI8KGMiN2Cn4W\nX7Krj7G/9BCf5qyj8Hgx4b6hBNoDvvb7m00G44aEs+doGdsPFeNjszA4LqgHO3Afb/s1DN7ZE3hn\nX+qp7/C2vrTlfB75Wf24fOAlXJJwEVvyt/Nh9lo2F2xjc8E2hoUkM2vATIaFfL2tXj8fK/f/aCr/\n89fPWPlJOsEBNqaMiOqFLkRExJ0Uzr2ktw4eiwjx5a7rxvD75Vt57u19BPnZGD4wtJe6EBERd9Cw\ndi/rePDYqLDh1DXVnXLwWIg9GB+zvVtb0/7+diwGDIoJYuPefLYeLGJ0UjhB/rbz0E3v8JTvqid5\nY0/gnX2pp77D2/o607C24fKQ6Y+Kinr2KlgREQE9/p49pePBYw3Nrf+hOaz+xDliiA2IJs4RQ5wj\nhki/iFO2rDv2tWlvAX9fnUZIgJ3/t3A8oYE+572XnuDJ39XX5Y09gXf2pZ76Dm/rKyKi8+OQNKzt\nBmG+oXw7+WrmDZzFhrwtHK7IJKc6t33Y+wSLyUKMf1RrWAe0BrYjOLn9+ckjIimrqmflJ+n8eeVO\nfvO9cfj5WN3RkoiI9CCFsxv5Wf24LGEGl7U9rm2q41h1HjnVuRyryiWnOpfc6jyyqnLgxARV2yDC\nN6w9sGMHRXNRZQifby3lydd384sbxmK16MJvIiJ9mcLZg/hafBgcnMjg4MT2Zc0tzRQcLyKnOpec\nqlwKGwo4XJLN9qLdbC/a3foiMzgm2DlS5eChD3Yxb+woovyd2M02rCYbNrMVu9mGxWTBZCi4RUQ8\nncLZw5lNZmIcUcQ4opgUNY6IiAAKCyspr69oC+y8tttjFJtKKKaEl/ft7fT9rCZrW2hbsZlbg9vW\nFuA2s63D/RPLT7ym9XmzYcZsMmM2TJiM1tuOy05/v8Pr29fVjwQRkc4onPsgwzAI8QkmxCeYUeEj\n2pcXV1Xxpzc/o7SxiGHJdmKcPjQ0N9DQ3EhDS0OH+400NDdQ01hDWX0jjc2NuDi/xwUaGO1B7bD7\nE2gJIMgeRLA9kGB7EEFttyce28x992h0EZGzpXD2IuEBAfzq6lk89M8tpK1rIGFyAjfMTMJkOvMp\nWi6Xi8aWJhpaGmhsbqS+uaEtzFtD/ESYNzY30uRqptnVTHNLM82uFppdzbR0uN/xuZYTyzo+39L2\nmg6P61rqyKzKoaUyq9MafS2+nQb3iT/+Vj9tkYuIV1A4e5mwIB9+9Z0LeOK1Xby7KYvswmp+PD8F\n/zMcxW0YRvtQNm442DsiIoCCwgqqGmqoqK+gvL6C8vrKtvutQ/jlDa23eTUFnb6P2TC3BXcgQfYg\nQu3B7SMMIfYgQnyCCbA6dE1yEfF4CmcvFB3mz73fn8Cz/9nLrowSHnxxCz+7dhSxEQ53l9Ypk2Ei\nyB5AkD2ABOI6fV19cwPl9RUnB3eH+xX1lRytzKbFlXna9S0mC8GnDe6Q9gD3tfTN88VFxHsonL2U\nn4+VO64dzRufH2bNhkwe+udWfnTFCMYPjXB3aefEbrYR6RdBpF/nfbS4WqhsqKKsrpyy+gpK68oo\nr6ugtL68bVk5B8szOl3f1+JDiP30we1jsWMzWduPgm89sM6q4XQR6VHdCudly5axc+dODMNgyZIl\njB49uv25lStX8tprr2EymRg2bBhLly4lNTWVO++8k+Tk1gtmDBkyhHvvvbd3OpBOmUwG185MIiEy\ngOfW7OXpN3Zz9bSBXD09EZMXD+2aDFP7fujETl7T2NxIeX0lZfVllNVVUFZfTmlbcJfVtd7Prcnv\n9mdaDDNWsw2byYLVbMPXZsfkMrcGedvR7q2BbsFmsn25rO2oeLvZht1ix26yYbfYsJvtrcvM9raj\n6K0ajhfpR7oM59TUVDIzM1mxYgUZGRksWbKEFStWAFBbW8uaNWtYvnw5VquVRYsWsX37dgAmTZrE\nE0880bvVS7dMHOYkKtSPJ1/fxep1R8kqqOaWq0bga++/AydWs5UIvzAi/MI6fU1tU+1JwV1eX0F9\ncz2NbUe8n3LbduBcQ3MjtbW11Dc10NTS1CP1Ghht56u3hrbNfHKAt97aTnr+RKh/9XQ462mWactf\nxLN0+a/zhg0bmDVrFgBJSUlUVFRQXV2Nw+HA19eXl156CWgN6urqaiIiIsjNze3dquWsxTsd3PeD\nifztrT3sSC/moZe38LNrRxOopkRAAAAgAElEQVQV6ufu0jyWr8UXX4cvMY6zn5bzxDWAW1wtNLY0\ntQV4w1eC/Muj4eub61uPkm9uoL65ofVxUwP1LV/eb2iub33c1EBVQw31zfU9dgqcxWT5Msg7bNF3\nPOfdarbif9SH+rpGDMOEgYFhGJjabo2v3J663HTy8rbnzIYZq9nS+qPBZO0wAtG62+DErgNb232L\nyaJRBC9R11RHY0sTDqu/vtOv6DKci4uLSUlJaX8cGhpKUVERDseXBxc9++yzvPzyyyxatIj4+Hhy\nc3NJT0/ntttuo6KigsWLFzNt2rTe6UC6zeFr5a7rx/Dapxm8l5rNgy9t5tarUhgzONzdpXktk2Fq\n36oF/x59b5fLRVNL05dh3jHYmxtobD8NrvHLU+NO/EDo5Nz3Ez8UqhqraWhupNnV3KM19wQDo/3H\nRMfdA61Bbjl5V0GHUYSOowsdHx+3hlBzvAm75cuL8JzNSEKLq6XDD6p66tq/i3rqmupbb9ueq29u\naHu+vv35ppZmTB1+rJg6/vBpu28yTB2eN06z7OR1/LPtmJusBNoCCLAFEGhztN+3mc/PKRnNLc1U\nNFS27i5q+9N63EdZ27Eg5dQ21QLgZ/El2j+SaP9Iotpuo/2jCLT137Mrznpc83STWN16660sWrSI\nW265hfHjxzNw4EAWL17M3Llzyc7OZtGiRbz//vvYbJ1fSCIkxA+L5ezmNu7KmWb86MvOta/FN4wj\nZXAET63cwROv7+J7c4Zz3WXJbv2fwBu/K2/oqamluXVrvqk1+FtcLbhcLlwuV+t9Ttx3dbh/uuUt\nX3nNl8tbP6Ox/XMamjuMKpxyv+226eTna+prqG9u7LHdCK3HANjwsdixW+z4WOz4WGw0tTRT21hH\nXVM9tU311DXWUd98blMYmg0TLW1/L+eDr8WHIJ8Agn0CCfIJbLsfRLBPQOtjewDBvkEE2wOwWU7/\nb7bL5aKm8TjFNWUUHy+l+HgpJcdP3G+9La0t77QnX4sP4f6hhPslYTaZOVaZx+HKTDIqjp70OofN\nn/igaOICo4kPiiGuJYq4oBiC7AFeH9pdhrPT6aS4uLj9cWFhIRERrUfKlpeXc+jQISZOnIiPjw8z\nZsxg27ZtjB8/nnnz5gGQkJBAeHg4BQUFxMfHd/o5ZWXHz7WXk3jb1GIn9FRfIxOCued743hq1W7+\n+e4+9h0u5qYrhuNjO//7ob3xu/K+nkyY8SHqbPsyvnLby07sRmjosIugoW1XQOtt266BDs+bbC7K\nq6u/fH376EMj9U31VNcfp765oX0UwW624WNuDe1Av4DW+237+n0sJ+7bO9xvff2pz7VuxXfcSm//\n8cOXP2BOXtZymmVtP3j4cllgkJ2swkKqGqqpbKiisqGq9X59FVWNrcsKqou73C3iY7a3bXE7CLAF\n0NDc0L7129mPEpNhIsgWyKDAAYT4BBPqE0KIPZjQtlMXQ32C8bX4nrJeY3MjBceLyKspIL+mgLy2\nP/uLMthXlH7Sa/2tfu1b19HtW9qRBNi6f7poc0szdc311DXVtY9m1LWNfLSPeLTd1jbXUd/UwNiI\nFMY6R3X7M7pyTlNGTps2jSeffJIFCxaQlpaG0+lsH9JuamrinnvuYfXq1fj7+7N7926uvvpqVq9e\nTVFRETfffDNFRUWUlJQQGRnZYw1JzxgYFch935/IM2/uYcuBIvJLj7P42tE4g0/9H0ekLzh5N0L3\ndPeHVHNLc/uwcW8xGaYe+SETERKAf1PwGV/T4mqhurGmPcC/GuQdHxdVlLQHuZ/Fl3DfsNawtYcQ\n4nPiugEhhPoEE2gLOGUe+u6wmq2tU+MGxJy0vKE9tPOpcJVxuCiHvJp8MsqPkl5+5KTXOqz+RPtH\n4vSLwOVyUddc175Loe4ruxm+ziiLi5YeDeczMVzdGEt59NFH2bJlC4ZhsHTpUvbu3UtAQACzZ89m\n1apVLF++HIvFwtChQ3nggQeoqanh7rvvprKyksbGRhYvXszMmTPP+Bk9vZXhfVsurXqjr6bmFlZ8\nlM5H23Lw97Fw2/yRpCSG9uhnnIk3flfe2BN4Z1/qqWstrhZqGo9jNVnwceNFejr21Rrahe1b2Cf+\nlNSWnjIiYGCcNJpxYuTDt+3Wp8OIho/Zp32ZT4fnfSx2gu1BPfrj7Exbzt0K5/NB4dw9vdnX5ztz\n+ef7B2hucXHdxYP5xqT4Ht+v43K5KCyrJf1YBRm5lRzNq2TowFDmXzjALUPqvUX//fUd6qnv6E5f\nDc0NFNeWYjaZ20PXUy8UdE7D2tJ/XDQmhphwf556YzcrP0knq7CKH8wZhs369Q/Uq2to4kheFRnH\nKlr/5FZSXdvY/rwBHM2vYtehIn76rVHEhvfsEc0i0r/YzLavdfqjp1E4y0mSYoNY+oOJPP3Gbjam\nFZBXfJzF14wiLKjroayOW8WHcyvJOFZBdlE1HcdmwgJ9GDEwhKTYIAbHBhET5s+7W7JZvfYwD720\nhe/PHcqUEX3/fywRkXOhcJZTBDvs/Oo741j+wQHW7szjdy9t5qffHMnQhJCTXtfVVrHVYmJwbBBJ\nsUEkxQSSFBtEsMN+yufdMn8UsaF+PP/OPp5dvZf0nApuuDQZq8XzhqFERM4HhbOcltVi4vtzhjEg\nMoD/+/AQj766g2tnJhHobyXjWPe2iuOdDizm7gXsxGFO4iL8eeaNPXy87RhH8qr46TdHdmuLXUTE\n2yicpVOGYXDJuDhiIxw807Yf+oSTt4qDSIoNPO1W8dmIDvPnt4sm8PJ7+9mQVsADL27m1qtGMHJQ\n59e/FhHxRgpn6dKQ+GDu+8FEPt52jCCH7ay3is+G3WbmR1eOYHBcMP/68CB/XrmTq6cnctW0gV49\nk5aISEcKZ+mW0EAfvn1x0nn5LMMwuOSCWAZGBfDMG7t564sjZByr4JarRhDg1/2LS4iI9FU64kY8\nVmJ0IEt/OIlRg8LYc6SUB17cTEZuhbvLEhHpdQpn8WgOXyt3Xjeab12USFllPY+8so2Ptuact0kC\nRETcQeEsHs9kGFw1LZFf3DAWX7uF5R8c5Nn/7KWuoWdmIBIR8TQKZ+kzUhJDuf+HE0mKCWTT3gIe\nfGkLucU17i5LRKTHKZylTwkN9OHXN45j1vg48kqO8+BLW0jdV+DuskREepTCWfoci9nEd2cP4bb5\nKWDA395KY/kHB2lqbnF3aSIiPULhLH3WpOGR3Pf9CcSE+/PR1hz+sHwbpZV17i5LROScKZylT2u9\nqth4poyIJCO3kvtf2EzakVJ3lyUick4UztLn+dgs3HLVCL53+RBq65t4fMUO3vz8MI1NGuYWkb5J\n4SxewTAMLh0Xx2++N57QQDur1x1lybMbWbc7j5YWnRMtIn2Lwlm8yqCY1quKXT4xnoqaep5bs4+l\nz6ey/VCRLlwiIn2Grq0tXsfha2XBZcnMnhDPW+uOsG53Hk++vpuk2EC+PTPplHmpRUQ8jbacxWuF\nBflw07zhPHjzZMYPiSDjWCV/+L/t/HnlTrIKqtxdnohIp7TlLF4vJtyf268ZRUZuBa9/msHuwyXs\nPlzC5BGRfOuiRJwhfu4uUUTkJApn6TeSYoL45XcuIO1oKa9/ephNewvYsr+QGWNjuPrCgQQ57O4u\nUUQEUDhLP2MYBiMTwxgxMJQt+wt5Y+1hPtl2jHW785g9IZ65kxPw87G6u0wR6ecUztIvmQyDScMj\nGTckgi9257H6iyOs2ZDJp9uPMW/qAC4bF4fNanZ3mSLSTymcpV+zmE1cPDaWqSlRfLw1hzUbMvn3\nJxl8uCWH+dMTmTYqCrNJx02KyPmlf3VEALvVzNwpA/jDT6ZyxdQB1NQ28uK7+/ntP1LZsr9Q50iL\nyHmlLWeRDvx9rFw7M4lLx8Xxn/VHWbsjl2fe3MPAqACuvTiJlIGh7i5RRPoBbTmLnEZIgJ1F3xjK\nw7dMZtJwJ0fzq3js1R08uzqNuoYmd5cnIl5O4SxyBpGhftw2fyRLfzCRQTGBbNxbwIMvbeFYcY27\nSxMRL6ZwFumGAVEB3HPjOGZPiCev5DgPvrSZDXvy3V2WiHgphbNIN1nMJr4zK5mffnMkJsPgf9/e\ny8v/3U9jU7O7SxMRL6MDwkTO0oRhTuKdDp5+Yw+f7sjlSF4VP/nWSJzBvu4uTUS8hLacRb6GyFA/\nfrtoPBeNjiazoIoHXtjM9oNF7i5LRLyEwlnka7JZzfxw3nBumjec5uYWnly1m5Ufp9PU3OLu0kSk\nj1M4i5yj6aOj+e2iCUSG+vHf1Cz+9K/tlFTUurssEenDFM4iPSDO6eC+709g4jAnh3IquPPxT0k7\nWuruskSkj1I4i/QQX7uF2+an8N1ZydTUNvL4qztY/cURWnTpTxE5SwpnkR5kGAazJsTzyO3TCQ20\n8+YXR/jzyp1UHm9wd2ki0oconEV6wdABoSz94SRGJ4WRdqSUB17YTHpOhbvLEpE+QuEs0kscvlbu\n+PZorpkxiPLqev7wf9t4PzVLM1yJSJcUziK9yGQYXHnhQO5ecAH+vlZe/TidZ97Yw/E6TZ4hIp1T\nOIucB8MHhHD/DycyJD6YrQeL+N1Lm8kqqHJ3WSLioRTOIudJsMPOL78zlnlTBlBYVstDL29l7c5c\nDXOLyCkUziLnkdlk4tsXJ3HHt0djt5p48d39PPn6bvYcLqGlRSEtIq008YWIG4wdHM7SH0zk76vT\n2JFezI70YkIC7EwbFcX0UdE4Q/zcXaKIuFG3wnnZsmXs3LkTwzBYsmQJo0ePbn9u5cqVvPbaa5hM\nJoYNG8bSpUsxDOOM64gIhAf7smTheA7nVfLFrjw27S3g7fWZvL0+k6HxwUwfHc2EoU7sNrO7SxWR\n86zLcE5NTSUzM5MVK1aQkZHBkiVLWLFiBQC1tbWsWbOG5cuXY7VaWbRoEdu3b6epqanTdUTkS4Zh\nkBQTRFJMEAsuS2bbgSI+35XL/qxyDmSXs/yDg0wa7mT6qBiSYgMxDMPdJYvIedBlOG/YsIFZs2YB\nkJSUREVFBdXV1TgcDnx9fXnppZeA1qCurq4mIiKCVatWdbqOiJye3Wpm6sgopo6MorC8lvW78/hi\ndx5rd7b+iQr146LR0UwdGUWww+7uckWkF3V5QFhxcTEhISHtj0NDQykqOnne2meffZbZs2czZ84c\n4uPju7WOiHTOGezLNy8axB9vu5D/uWEsk0dEUlxRx78/zeDup9fz13/vZOuBIk1PKeKlzvqAsNOd\n9nHrrbeyaNEibrnlFsaPH9+tdb4qJMQPi6Vn961FRAT06Pt5Cm/sSz11LjIykIsnDaD6eAOfbT/G\nh5uz2JlRws6MEoIcNi4eF8/sSQkMiA7skc/rir6rvsEbewLv7eurugxnp9NJcXFx++PCwkIiIiIA\nKC8v59ChQ0ycOBEfHx9mzJjBtm3bzrhOZ8rKjn/dHk4rIiKAoiLvu8iDN/alnrpv0pBwJg0JJ7uw\nmi925bEhLZ+31mbw1toMEqMDmD4qmskjIvHzsfb4Z4O+q77CG3sC7+vrTD80uhzWnjZtGu+99x4A\naWlpOJ3O9n3HTU1N3HPPPdTU1ACwe/duEhMTz7iOiJy7eKeD78xK5vHF07j9WyMZnRTG0fwq/vn+\nQe56ah3/35t7+GhrDkfyKjX0LdIHdbnlPG7cOFJSUliwYAGGYbB06VJWrVpFQEAAs2fP5vbbb2fR\nokVYLBaGDh3KZZddhmEYp6wjIj3PYjYxfqiT8UOdlFXVsyEtn8935bF5fyGb9xe2vcYgITKAQdGB\nJMYEMigmEGewr478FvFghstDrh3Y00MV3jb8cYI39qWeepbL5SKv5DiHcys5klfJ4dxKcoqqae5w\nBTJ/H0trUEe3hnVidCABfrYu31vfVd/gjT2B9/V1pmFtXSFMxMsYhkFMuD8x4f5MHx0NQENjM1kF\n1RzOq+RwbgVH8irZc7iUPYdL29eLCPZhUEwQiW2BneB0YLPqAigi7qBwFukHbFYzg+OCGBwXBMQD\nUHm8gaNtW9aH8yo5klvJpr0FbNpbAIDZZBDndJy0dR0ermNHRM4HhbNIPxXoZ2N0Ujijk8KB1uHw\nwvLa1uHwtsDOKqgiM7+KT7YfAyAqzI+JQ51MSYkkOszfneWLeDWFs4gArcPhkSF+RIb4MTUlCoCm\n5hayC6s5nFvJoZxydmaU8J/1R/nP+qMkRgcwJSWKScMjCfLven+1iHSfwllEOmUxm0iMbh3Svmx8\nHI5AXz7YcISNaQWkHSnlSN4hVnyUzojEEKamRDEuOUITdYj0AIWziHSbr93C1JQopqZEUVHTQOq+\nAjam5bcfXGa3mhk3JJypKVEMHxiC2aQp40W+DoWziHwtQf42Zk+IZ/aEePJLj7MxLZ8NaflsSCtg\nQ1oBgf42Jg13MjUlioFRATqvWuQsKJxF5JxFhfrxzYsGMX96Ihm5lWxMyyd1XyEfbsnhwy05RIX6\nMTUlkskpUTiDfd1drojHUziLSI8xDIPBsUEMjm2dn3rPkVI2puWz/VAxb3x+hDc+P8Lg2CCmpkQy\ncXgkDt/euQa4SF+ncBaRXmExmxg7OJyxg8OprW9i28EiNqTls+9oGenHKvi/Dw8xalAY00ZFc0Fy\nOCaThr1FTlA4i0iv87VbmDYqmmmjoimrqmfT3gI27s1nR3oxO9KLcQb7MntiPNNHRetobxEUziJy\nnoUE2JkzOYE5kxPIKarmo605rNudz/IPDvLm54e5ZFwcl42P07nT0q8pnEXEbeIiHHx/zjC+ddEg\nPt6Ww8fbjvH2+qP8d1MWF46M5PKJCcSE60pk0v8onEXE7QL9bXzzokHMnTKA9XvyeS81i7U781i7\nM48xSWHMmZzAkPhgnY4l/YbCWUQ8ht1q5pILYpk5JoYd6cX8NzWLnRkl7MwoYWBUAHMmJzB+aIQu\nbiJeT+EsIh7HZDIYNySCcUMiSD9WwXupWWw7UMTf3kojLNCH2RPjuWh0NL52/RMm3kn/ZYuIRxsc\nG8Tgb42ioOw4H2zO5otdebz60SHe+uIIF18Qw6zx8YQE2N1dpkiPUjiLSJ8QGeLH9y4fyjcvGsQn\n23L4aGsO727M4v3UbKaMiOQbkxKIc2q+afEOCmcR6VMcvlaumpbInMkJbEgr4L3ULNbtyWfdnnxG\nJobyjckJjBgQooPHpE9TOItIn2S1mJkxJobpo6PZlVHCe5uy2HOklD1HSklwOvjmRYMYMzhMIS19\nksJZRPo0k2G0Xyb0SF4l76VmsXl/IU+8vovkuCCuu3gwg+OC3F2myFnR+Qgi4jUSowO5bf5Ifnfz\nZC5IDudQTgXLXtnKk6/vIre4xt3liXSbtpxFxOvEhvvzs2tHcyinnH9/msH2Q63X8J4+Kpr50xMJ\nDfRxd4kiZ6RwFhGvlRwXzG9uHMeO9GJe/+wwn+/KY+PeAmZNiGPelAH4+2jKSvFMCmcR8WqGYXBB\ncgRjksJZtyePNz8/wrsbs1i7I5crpg7khm8Mc3eJIqdQOItIv2AyGVw0OobJwyP5aFsOa9ZnsvKT\ndD7efoyrLxzIhSOjNKe0eAwdECYi/YrNambu5AH84SdTmTslgcrqep5/Zx9Ln09lx6FiXC6Xu0sU\nUTiLSP/k72PluosH8/ffzOKi0dHkltTwxOu7eGT5NtJzKtxdnvRzCmcR6dfCg3354bzhOv1KPIr2\nOYuIoNOvxLMonEVEOjjT6VdzJw/A4avTr6T3KZxFRL7ixOlXo5PCWL87nze/aD396oPN2YwbEsFF\nY2IYPiAEk67bLb1E4Swi0gmzycRFY2KYPCKSz3bk8umOY6TuKyR1XyHhQT5cNDqaaaOiNeQtPU7h\nLCLSBZvVzOyJ8cyaEEfGsUrW7swldX8Bb3x+hDe/OMKoQWFcNDqGMYPDsJh1nK2cO4WziEg3GYbB\n4LggBscF8Z1ZyaTuK2Dtzjx2ZZSwK6OEQH8b00ZGcdGYGKJC/dxdrvRhCmcRka/B125h5thYZo6N\nJbuwms935rIhLZ93N2Xx7qYshsQHM2NMNOOHOrFbze4uV/oYhbOIyDmKdzr47uwhXHdJEtsOFrN2\nZy77Mss4mF3O8g8OMmVEFDPGxDAgKsDdpUofoXAWEekhVouZySMimTwiksLyWr7YlccXu3L5ZPsx\nPtl+jIRIBzPGxDBlRCR+mhFLzkDhLCLSC5zBvlwzYxDzpw9kz+FS1u7MZVdGCa+8f5AVH6czYWgE\nM8bEMCQ+GEOnZMlXKJxFRHqR2WRizOBwxgwOp6K6nvV78lm7M5cNaQVsSCsgNtyfBbOSSRkY6u5S\nxYMonEVEzpMgh525UwYwZ3ICB7PLWbszl417C3js1R2MHxrBgkuTCQvSOdOicBYROe8Mw2BoQghD\nE0K4fGICyz84yNYDRezOKOGKCwcyZ1ICVovOl+7P9O2LiLjRgKgAfvO9cdx8xXB87BbeWHuYe5/b\nxK6MYneXJm6kcBYRcTPDMJg2Kpplt0xh9oR4isvr+Mu/d/HEa7soLK91d3niBhrWFhHxEH4+Fr4z\nK5mLxkSz/P2D7EgvZs+RUuZNSWDelAHYdDGTfqNb4bxs2TJ27tyJYRgsWbKE0aNHtz+3ceNGHn/8\ncUwmE4mJiTz88MNs3ryZO++8k+TkZACGDBnCvffe2zsdiIh4mbgIB7/67gWk7itkxceHWL3uKOv3\n5LPgsmQuSA7XqVf9QJfhnJqaSmZmJitWrCAjI4MlS5awYsWK9ufvu+8+Xn75ZaKiorjjjjv4/PPP\n8fHxYdKkSTzxxBO9WryIiLcyDIPJIyIZMziM/6w7yvubs3lq1W5GDgrlu7OG6NrdXq7Lfc4bNmxg\n1qxZACQlJVFRUUF1dXX786tWrSIqKgqA0NBQysrKeqlUEZH+x8dm4bpLBvO7myeRMjCEPYdLufcf\nm3jt0wzqGprcXZ70ki63nIuLi0lJSWl/HBoaSlFREQ6HA6D9trCwkHXr1nHnnXdy8OBB0tPTue22\n26ioqGDx4sVMmzbtjJ8TEuKHxdKz+1MiIrzzOrbe2Jd66ju8sa++0FNERACjhkayYXce/1i9h3c2\nZpK6r4Cbrh7J9DExpwx194Wevg5v7eurzvqAMJfLdcqykpISbrvtNpYuXUpISAgDBw5k8eLFzJ07\nl+zsbBYtWsT777+PzWbr9H3Lyo6fbSlnFBERQFFRVY++pyfwxr7UU9/hjX31tZ6SowP43U2TWLMh\nk/9uyuSP/9zC6s+CuXH2EGIjWjeW+lpP3eVtfZ3ph0aXw9pOp5Pi4i/PtyssLCQiIqL9cXV1Nbfc\ncgs///nPmT59OgCRkZHMmzcPwzBISEggPDycgoKCc+lBRETa2K1mrpkxiAd/NJnRSWHszyrn/hc2\n8+pHh6it11C3N+gynKdNm8Z7770HQFpaGk6ns30oG+CRRx7h+9//PjNmzGhftnr1ap577jkAioqK\nKCkpITIysqdrFxHp1yJD/Pj5dWO449ujCQ208/7mbJY8u5GPt2RR39Ds7vLkHBiu041Tf8Wjjz7K\nli1bMAyDpUuXsnfvXgICApg+fToTJ07kggsuaH/tlVdeyRVXXMHdd99NZWUljY2NLF68mJkzZ57x\nM3p6qMLbhj9O8Ma+1FPf4Y19eUtPjU3NvLspizUbMmlsasEwIDbcwaCYAAbFBJEYHUhMuB9mU9+9\n9pS3fFcnnGlYu1vhfD4onLvHG/tST32HN/blbT0Vl9eyfl8hezKKycqvoqGppf05m9XEwMgAEmMC\nSYwOZFB0IGFBPn3mvGlv+67OFM66QpiIiBcJD/bl5qtHUlRURVNzC7nFNRzOq+RIbiVH8io5dKyC\ngzkV7a8P8LO2B/WJ0Hb4Wt3YgYDCWUTEa1nMJhIiA0iIDODisbEA1DU0kZlfxZG8qvbQ3pVRwq6M\nkvb1nMG+DGoL6sSYQBKcjh65dGhLi4vmlhaaW1ytf5pdWC0mfO2Koq/S34iISD/iY7O0T1d5QkV1\n/Zdh3RbYG/cWsHFv61k2ZpNBbIQ/gX62tlBtodnVGq7NLS5aWlw0tS1v6bC8+UQYN7e+prN9qM4Q\nXwZGBTAgKoCBUYEMiAzAz6d/x1P/7l5ERAhy2BmbbGdscjjQej2LwrLak4bDMwuqyWr+8uqQZpOB\n2WRgars1m03ty6w2U9tyE2az0b7c/JXXmkwGx+tat+RT9xWSuq+w/f0jQ3zbw/pEcPcnCmcRETmJ\nYRhEhvoRGerH1JTWyzOf2AI2mw1MhtGjB5G5XC6KKuo4mldJZn4VR/OrThvYsRH+xEU4GBAZQGJ0\n63C9tw6Je2dXIiLSo8wmE+ZeOgvLMAycwb44g32ZNLz1mhgul4ui8lqOdgjrrIIqjhXVsGnvlxe1\nigr16zAk7j2B3fc7EBERr2MYBs4QP5whfu2BHR7uIO1Q4Ulb10fzq07aP24AUWF+TBsVzSUXxPbZ\noO6bVYuISL9jGAaRIX5EdgjslrYt7Mz8Ko7mVXE0v5IjeVW89mkG72zI5NLxccyaEEegX+dzO3gi\nhbOIiPRZptME9vG6Jj7ZnsP7m7N5e/1R3k/NYsbYGOZMSiA00MfNFXePwllERLyKn4+FK6YOZNaE\neL7Ylce7mzL5cEsOn2w7xtSRUcybMoCoUD93l3lGCmcREfFKdquZy8bHMXNsDBvTCnhnYyZf7Mpj\n3a48xg9zcsWUAR57ipbCWUREvJrFbGL66GguHBnFtoNFrNmYyZb9hWzZX8jIQaFcOXUgQ+KD3V3m\nSRTOIiLSL5hMBhOGORk/NIK0o6WsWZ/JnsOl7DlcyuC4IK6cOoBRg8I8YiIQhbOIiPQrhmEwMjGM\nkYlhpOdUsGbDUXZmlPCXf+8i3ulg3pQBTBzmxGRyX0grnEVEpN8aHBfEndeNIbuwmnc2ZpK6r4C/\nr07jjc8PM2/KAKamRGG1nP85sPvurNsiIiI9JN7p4MdXp7Ds1inMHBtDaWUdL767n1//bT3vp2ZR\n19B0XutROIuIiLSJDIxoP24AAAhMSURBVPHj+3OG8YfbLuQbk+KprW/m1Y/T+eUz69mYln/e6lA4\ni4iIfEVIgJ0bLk3mTz+9kPnTEwHYfbiki7V6jvY5i4iIdMLha2X+9ESumjbwvH6uwllERKQLpvN8\nepWGtUVERDyMwllERMTDKJxFREQ8jMJZRETEwyicRUREPIzCWURExMMonEVERDyMwllERMTDKJxF\nREQ8jMJZRETEwyicRUREPIzhcrlc7i5CREREvqQtZxEREQ+jcBYREfEwCmcREREPo3AWERHxMApn\nERERD6NwFhER8TAWdxdwrpYtW8bOnTsxDIMlS5YwevTo9ufWr1/P448/jtlsZsaMGdx+++1urPTs\n/PGPf2Tr1q00NTXx4x//mMsvv7z9uUsvvZSoqCjMZjMAjz76KJGRke4qtVs2bdrEnXfeSXJyMsD/\n396dhUQZtQEc/6vj0pi5pWKEFUJlEWVlueBWWSm03UQDgwVGpKkglgtkCl1YOUFiUWl7FkQWYQso\nURcRalZSqRcm3thmLllOWOZwvgtpPqcZzfq+mveN87t7zzMvPA/POZ2ZM+8Ys2fPpqCgwBxXa6+u\nXr1KdXW1+bq5uZmmpibz9fz581m8eLH5+ty5c+a+KVFbWxtpaWls27YNvV7P27dvycnJwWQy4efn\nR0lJCS4uLhb3jLcGlcBWTfn5+QwPD6PRaCgpKcHPz8/8+p/NVSX4saa8vDxaWlrw8vICICUlhbi4\nOIt7lN4nsK4rMzOTDx8+ANDf38+iRYvYv3+/+fXXr1+ntLSUoKAgACIjI0lNTbVL7v93QsUaGhrE\njh07hBBCtLe3i82bN1vEExMTxZs3b4TJZBI6nU68fPnSHmn+srq6OrF9+3YhhBB9fX0iNjbWIh4f\nHy+MRqMdMvt99fX1IiMjY8y4Wns1WkNDgygqKrIYW7ZsmZ2y+XWfP38Wer1e7N27V1y8eFEIIURe\nXp64c+eOEEKIw4cPi0uXLlnc87M1aG+2asrJyRG3b98WQghRWVkpDh48aHHPz+aqvdmqKTc3V9y7\nd2/Me5TeJyFs1zVaXl6eePbsmcXYtWvXxIEDB/5Win+Vqo+16+rqWLVqFQDBwcF8/PgRo9EIQGdn\nJ56engQGBuLo6EhsbCx1dXX2THfCwsLCKC0tBWDKlCkMDg5iMpnsnNWfo+ZejXbs2DHS0tLsncZv\nc3FxoaKiAn9/f/NYQ0MDK1euBCA+Pt6qL+OtQSWwVVNhYSFr1qwBwNvbm/7+fnul91ts1fQzSu8T\njF9XR0cHAwMDivy0/6eoenPu6enB29vbfO3j40N3dzcA3d3d+Pj42IwpnZOTE1qtFoCqqipiYmKs\njkILCwvR6XQYDAaESv7IW3t7Ozt37kSn0/Hw4UPzuJp79d3z588JDAy0OB4FGBoaIjs7my1btnD2\n7Fk7ZTcxGo0GNzc3i7HBwUHzMbavr69VX8Zbg0pgqyatVouTkxMmk4nLly+zbt06q/vGmqtKYKsm\ngMrKSpKTk8nKyqKvr88ipvQ+wdh1AVy4cAG9Xm8z9ujRI1JSUti6dSutra1/MsW/SvXfOY+mlk1q\nou7evUtVVRVnzpyxGM/MzCQ6OhpPT0927dpFTU0Na9eutVOWEzNz5kzS09NJTEyks7OT5ORkamtr\nrb6/VKuqqio2bdpkNZ6Tk8P69etxcHBAr9ezdOlSFixYYIcM/3cTWV9qWYMmk4mcnBzCw8OJiIiw\niKlxrm7YsAEvLy9CQkIoLy/n6NGj7Nu3b8zXq6VPMPIG98mTJxQVFVnFFi5ciI+PD3FxcTQ1NZGb\nm8vNmzf/fpJ/gKo/Ofv7+9PT02O+fv/+vfmTy4+xrq6uXzoGsrcHDx5w4sQJKioq8PDwsIht3LgR\nX19fNBoNMTExtLW12SnLiQsICCApKQkHBweCgoKYOnUqXV1dgPp7BSPHv6GhoVbjOp0Od3d3tFot\n4eHhqujVaFqtli9fvgC2+zLeGlSy/Px8ZsyYQXp6ulVsvLmqVBEREYSEhAAjD4z+OM/U2ieAxsbG\nMY+zg4ODzQ++hYaG0tfX9898BajqzTkqKoqamhoAWlpa8Pf3Z/LkyQBMnz4do9HIq1evGB4e5v79\n+0RFRdkz3QkbGBjg0KFDnDx50vz05ehYSkoKQ0NDwMjE/f5UqZJVV1dz+vRpYOQYu7e31/yEuZp7\nBSOblru7u9Unq46ODrKzsxFCMDw8zNOnT1XRq9EiIyPNa6y2tpbo6GiL+HhrUKmqq6txdnYmMzNz\nzPhYc1WpMjIy6OzsBEbeKP44z9TYp+9evHjB3LlzbcYqKiq4desWMPKkt4+Pj6J/DfErVP+/UhkM\nBh4/foyDgwOFhYW0trbi4eFBQkICjY2NGAwGAFavXk1KSoqds52YK1euUFZWxqxZs8xjy5cvZ86c\nOSQkJHD+/Hlu3LiBq6sr8+bNo6CgAAcHBztm/HNGo5Hdu3fz6dMnvn37Rnp6Or29varvFYz8fOrI\nkSOcOnUKgPLycsLCwggNDaWkpIT6+nocHR1ZsWKFon/m0dzczMGDB3n9+jUajYaAgAAMBgN5eXl8\n/fqVadOmUVxcjLOzM1lZWRQXF+Pm5ma1Bsf6h9QebNXU29uLq6ureXMKDg6mqKjIXNPw8LDVXI2N\njbVzJf9lqya9Xk95eTmTJk1Cq9VSXFyMr6+vavoEtusqKyujrKyMJUuWkJSUZH5tamoqx48f5927\nd+zZs8f8BlipPxH7HarfnCVJkiTpX6PqY21JkiRJ+hfJzVmSJEmSFEZuzpIkSZKkMHJzliRJkiSF\nkZuzJEmSJCmM3JwlSZIkSWHk5ixJkiRJCiM3Z0mSJElSmP8APVrblhvzxIoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HzDUdTT8Agxo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task C"
      ]
    },
    {
      "metadata": {
        "id": "Wf47-PIDAlIw",
        "colab_type": "code",
        "outputId": "f36f0207-1ae5-478a-d078-d48a950a2edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a', LABEL),\n",
        "               ('subtask_b',LABEL),\n",
        "               ('subtask_c', LABEL)\n",
        "              ]\n",
        "\n",
        "train = data.TabularDataset(train_fp,\n",
        "                            format='TSV',\n",
        "                            fields=data_fields,\n",
        "                            skip_header=True,\n",
        "                            filter_pred=lambda d: d.subtask_a == 'OFF' and d.subtask_b == 'TIN')\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d')\n",
        "\n",
        "LABEL.build_vocab(train.subtask_c)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "print(LABEL.vocab.stoi)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 3101\n",
            "Validation size: 775\n",
            "defaultdict(<function _default_unk_index at 0x7fee2eecb6a8>, {'IND': 0, 'GRP': 1, 'OTH': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UTUbzJZBBBMr",
        "colab_type": "code",
        "outputId": "4c2fc30e-8351-423a-b499-e483a78e25e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9646
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab,\n",
        "                              embedding_dim,\n",
        "                              window_size,\n",
        "                              out_channels,\n",
        "                              dropout,\n",
        "                              num_classes=3)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper('subtask_c',\n",
        "                                  model, optimizer,\n",
        "                                  loss_fn = loss_fn,\n",
        "                                  epochs = 30,\n",
        "                                  train_loader=train_iterator,\n",
        "                                  valid_loader=valid_iterator)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 1.8731\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 477 / 775 correct (61.55)\n",
            "[[469   7   0]\n",
            " [199   8   0]\n",
            " [ 87   5   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.99      0.76       476\n",
            "           1       0.40      0.04      0.07       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.62      0.62      0.62       775\n",
            "   macro avg       0.34      0.34      0.28       775\n",
            "weighted avg       0.49      0.62      0.49       775\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 1.5259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Accuracy:\n",
            "Got 497 / 775 correct (64.13)\n",
            "[[458  18   0]\n",
            " [168  39   0]\n",
            " [ 78  14   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.96      0.78       476\n",
            "           1       0.55      0.19      0.28       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.64      0.64      0.64       775\n",
            "   macro avg       0.40      0.38      0.35       775\n",
            "weighted avg       0.55      0.64      0.55       775\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 1.1229\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 512 / 775 correct (66.06)\n",
            "[[457  19   0]\n",
            " [152  55   0]\n",
            " [ 76  16   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.96      0.79       476\n",
            "           1       0.61      0.27      0.37       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.66      0.66      0.66       775\n",
            "   macro avg       0.43      0.41      0.39       775\n",
            "weighted avg       0.57      0.66      0.58       775\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 1.0748\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 530 / 775 correct (68.39)\n",
            "[[451  25   0]\n",
            " [128  79   0]\n",
            " [ 70  22   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.95      0.80       476\n",
            "           1       0.63      0.38      0.47       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.44      0.44      0.43       775\n",
            "weighted avg       0.59      0.68      0.62       775\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.9831\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 530 / 775 correct (68.39)\n",
            "[[436  40   0]\n",
            " [113  94   0]\n",
            " [ 65  27   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.92      0.80       476\n",
            "           1       0.58      0.45      0.51       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.43      0.46      0.44       775\n",
            "weighted avg       0.59      0.68      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.7903\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 536 / 775 correct (69.16)\n",
            "[[444  32   0]\n",
            " [115  92   0]\n",
            " [ 66  26   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.93      0.81       476\n",
            "           1       0.61      0.44      0.52       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.44      0.46      0.44       775\n",
            "weighted avg       0.60      0.69      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.8825\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 537 / 775 correct (69.29)\n",
            "[[443  33   0]\n",
            " [113  94   0]\n",
            " [ 66  26   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.93      0.81       476\n",
            "           1       0.61      0.45      0.52       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.44      0.46      0.44       775\n",
            "weighted avg       0.60      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.6639\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 526 / 775 correct (67.87)\n",
            "[[422  54   0]\n",
            " [103 104   0]\n",
            " [ 58  34   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.89      0.80       476\n",
            "           1       0.54      0.50      0.52       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.42      0.46      0.44       775\n",
            "weighted avg       0.59      0.68      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.7605\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 532 / 775 correct (68.65)\n",
            "[[439  37   0]\n",
            " [114  93   0]\n",
            " [ 67  25   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.92      0.80       476\n",
            "           1       0.60      0.45      0.51       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.44      0.46      0.44       775\n",
            "weighted avg       0.60      0.69      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.6761\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 531 / 775 correct (68.52)\n",
            "[[422  54   0]\n",
            " [ 98 109   0]\n",
            " [ 56  36   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.89      0.80       476\n",
            "           1       0.55      0.53      0.54       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.43      0.47      0.45       775\n",
            "weighted avg       0.60      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.7704\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 534 / 775 correct (68.90)\n",
            "[[428  48   0]\n",
            " [101 106   0]\n",
            " [ 60  32   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.90      0.80       476\n",
            "           1       0.57      0.51      0.54       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.43      0.47      0.45       775\n",
            "weighted avg       0.60      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.6288\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 529 / 775 correct (68.26)\n",
            "[[422  54   0]\n",
            " [100 107   0]\n",
            " [ 55  37   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.89      0.80       476\n",
            "           1       0.54      0.52      0.53       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.42      0.47      0.44       775\n",
            "weighted avg       0.59      0.68      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.5706\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 527 / 775 correct (68.00)\n",
            "[[419  57   0]\n",
            " [ 99 108   0]\n",
            " [ 53  39   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.88      0.80       476\n",
            "           1       0.53      0.52      0.53       207\n",
            "           2       0.00      0.00      0.00        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.42      0.47      0.44       775\n",
            "weighted avg       0.59      0.68      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.7139\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 532 / 775 correct (68.65)\n",
            "[[425  51   0]\n",
            " [101 106   0]\n",
            " [ 56  35   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.89      0.80       476\n",
            "           1       0.55      0.51      0.53       207\n",
            "           2       1.00      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.76      0.47      0.45       775\n",
            "weighted avg       0.71      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.5958\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 532 / 775 correct (68.65)\n",
            "[[417  59   0]\n",
            " [ 93 114   0]\n",
            " [ 54  37   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.88      0.80       476\n",
            "           1       0.54      0.55      0.55       207\n",
            "           2       1.00      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.76      0.48      0.46       775\n",
            "weighted avg       0.72      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.5124\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 529 / 775 correct (68.26)\n",
            "[[424  52   0]\n",
            " [103 104   0]\n",
            " [ 58  33   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.89      0.80       476\n",
            "           1       0.55      0.50      0.53       207\n",
            "           2       1.00      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.76      0.47      0.45       775\n",
            "weighted avg       0.71      0.68      0.63       775\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.5390\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 535 / 775 correct (69.03)\n",
            "[[423  53   0]\n",
            " [ 96 111   0]\n",
            " [ 55  36   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.89      0.81       476\n",
            "           1       0.56      0.54      0.55       207\n",
            "           2       1.00      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.76      0.48      0.46       775\n",
            "weighted avg       0.72      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.4573\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 527 / 775 correct (68.00)\n",
            "[[412  64   0]\n",
            " [ 93 114   0]\n",
            " [ 51  40   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.87      0.80       476\n",
            "           1       0.52      0.55      0.54       207\n",
            "           2       1.00      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.75      0.48      0.45       775\n",
            "weighted avg       0.71      0.68      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.5537\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 534 / 775 correct (68.90)\n",
            "[[423  53   0]\n",
            " [ 97 110   0]\n",
            " [ 57  34   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.89      0.80       476\n",
            "           1       0.56      0.53      0.54       207\n",
            "           2       1.00      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.76      0.48      0.46       775\n",
            "weighted avg       0.72      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.5972\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 534 / 775 correct (68.90)\n",
            "[[422  54   0]\n",
            " [ 96 111   0]\n",
            " [ 54  37   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.89      0.81       476\n",
            "           1       0.55      0.54      0.54       207\n",
            "           2       1.00      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.76      0.48      0.46       775\n",
            "weighted avg       0.72      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 20\n",
            "Iteration 0, loss = 0.5271\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 533 / 775 correct (68.77)\n",
            "[[420  56   0]\n",
            " [ 95 112   0]\n",
            " [ 54  37   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.88      0.80       476\n",
            "           1       0.55      0.54      0.54       207\n",
            "           2       1.00      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.76      0.48      0.46       775\n",
            "weighted avg       0.72      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 21\n",
            "Iteration 0, loss = 0.5109\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 531 / 775 correct (68.52)\n",
            "[[415  60   1]\n",
            " [ 92 115   0]\n",
            " [ 54  37   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.87      0.80       476\n",
            "           1       0.54      0.56      0.55       207\n",
            "           2       0.50      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.59      0.48      0.46       775\n",
            "weighted avg       0.66      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 22\n",
            "Iteration 0, loss = 0.4669\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 533 / 775 correct (68.77)\n",
            "[[424  51   1]\n",
            " [ 99 108   0]\n",
            " [ 54  37   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.89      0.81       476\n",
            "           1       0.55      0.52      0.54       207\n",
            "           2       0.50      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.60      0.47      0.45       775\n",
            "weighted avg       0.66      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 23\n",
            "Iteration 0, loss = 0.4534\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 535 / 775 correct (69.03)\n",
            "[[422  53   1]\n",
            " [ 95 112   0]\n",
            " [ 54  37   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.89      0.81       476\n",
            "           1       0.55      0.54      0.55       207\n",
            "           2       0.50      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.60      0.48      0.46       775\n",
            "weighted avg       0.66      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 24\n",
            "Iteration 0, loss = 0.4931\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 534 / 775 correct (68.90)\n",
            "[[422  53   1]\n",
            " [ 96 111   0]\n",
            " [ 54  37   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.89      0.81       476\n",
            "           1       0.55      0.54      0.54       207\n",
            "           2       0.50      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.60      0.48      0.46       775\n",
            "weighted avg       0.66      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 25\n",
            "Iteration 0, loss = 0.3289\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 536 / 775 correct (69.16)\n",
            "[[427  47   2]\n",
            " [ 99 108   0]\n",
            " [ 54  37   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.90      0.81       476\n",
            "           1       0.56      0.52      0.54       207\n",
            "           2       0.33      0.01      0.02        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.54      0.48      0.46       775\n",
            "weighted avg       0.64      0.69      0.64       775\n",
            "\n",
            "\n",
            "Epoch: 26\n",
            "Iteration 0, loss = 0.4215\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 534 / 775 correct (68.90)\n",
            "[[415  59   2]\n",
            " [ 90 117   0]\n",
            " [ 52  38   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.87      0.80       476\n",
            "           1       0.55      0.57      0.56       207\n",
            "           2       0.50      0.02      0.04        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.60      0.49      0.47       775\n",
            "weighted avg       0.66      0.69      0.65       775\n",
            "\n",
            "\n",
            "Epoch: 27\n",
            "Iteration 0, loss = 0.3759\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 536 / 775 correct (69.16)\n",
            "[[425  49   2]\n",
            " [ 99 108   0]\n",
            " [ 54  35   3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.89      0.81       476\n",
            "           1       0.56      0.52      0.54       207\n",
            "           2       0.60      0.03      0.06        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.63      0.48      0.47       775\n",
            "weighted avg       0.67      0.69      0.65       775\n",
            "\n",
            "\n",
            "Epoch: 28\n",
            "Iteration 0, loss = 0.4087\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 537 / 775 correct (69.29)\n",
            "[[419  55   2]\n",
            " [ 91 116   0]\n",
            " [ 52  38   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.88      0.81       476\n",
            "           1       0.56      0.56      0.56       207\n",
            "           2       0.50      0.02      0.04        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.60      0.49      0.47       775\n",
            "weighted avg       0.67      0.69      0.65       775\n",
            "\n",
            "\n",
            "Epoch: 29\n",
            "Iteration 0, loss = 0.3949\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 534 / 775 correct (68.90)\n",
            "[[414  60   2]\n",
            " [ 89 118   0]\n",
            " [ 51  39   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.87      0.80       476\n",
            "           1       0.54      0.57      0.56       207\n",
            "           2       0.50      0.02      0.04        92\n",
            "\n",
            "   micro avg       0.69      0.69      0.69       775\n",
            "   macro avg       0.60      0.49      0.47       775\n",
            "weighted avg       0.66      0.69      0.65       775\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TSbEtokDP1Dy",
        "colab_type": "code",
        "outputId": "9586a6d1-a29a-4ccf-fcc3-96f807a03ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "zza6aQ1QnMyy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
        "embedding.weight.data.copy_(TEXT.vocab.vectors) # copies pre-trained word vectors\n",
        "\n",
        "embeddings, training_labels = transfrom_for_scikit('subtask_c', TEXT, LABEL, embedding, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qW-g6VVXgU-B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_embeddings, val_labels = transfrom_for_scikit('subtask_c', TEXT, LABEL, embedding, valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahOuuuoUpZlR",
        "colab_type": "code",
        "outputId": "f9f74d8d-ee95-4684-b12f-d0f82f50dbda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# clf = svm.SVC()\n",
        "# clf = SGDClassifier(loss='hinge', penalty='l1',\n",
        "#                           alpha=1e-3, random_state=42,\n",
        "#                           max_iter=5, tol=None, class_weight={2.0: 1})\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# The decision trees have max_depth 1\n",
        "clf = AdaBoostClassifier(n_estimators=100)\n",
        "\n",
        "clf.fit(embeddings, training_labels)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
              "          learning_rate=1.0, n_estimators=10, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "s_x8Fon_pfsY",
        "colab_type": "code",
        "outputId": "ed8b612b-e926-482c-8d10-c283c3e0fcec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "preds = clf.predict(val_embeddings)\n",
        "\n",
        "print(metrics.confusion_matrix(val_labels, preds))\n",
        "print(metrics.classification_report(val_labels, preds))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(val_labels, preds))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[412  63   1]\n",
            " [ 95 110   2]\n",
            " [ 53  36   3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.87      0.80       476\n",
            "           1       0.53      0.53      0.53       207\n",
            "           2       0.50      0.03      0.06        92\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       775\n",
            "   macro avg       0.59      0.48      0.46       775\n",
            "weighted avg       0.65      0.68      0.64       775\n",
            "\n",
            "Accuracy: 0.6774193548387096\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}