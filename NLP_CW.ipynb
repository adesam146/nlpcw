{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_CW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "xGMVF5KTg-He",
        "t9Zt3py7E1ep",
        "SClCUJp08-zn",
        "u7glEGKc-rNE"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adesam146/nlpcw/blob/rest_of_tasks/NLP_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_i_qSkEMxlkg"
      },
      "cell_type": "markdown",
      "source": [
        "## Check GPU memory"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5-XwNX-831V6",
        "outputId": "31c35359-a798-4dc0-b89b-ca253aaa0849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "cell_type": "code",
      "source": [
        "#Check GPU Memory allocation\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NOXcwqriwFsu",
        "outputId": "1ffa4302-394e-4be6-843f-d19b4c0009d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.9 GB  | Proc size: 143.9 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ecWOCoFgxS_j",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#run this if GPU utilization is not 0%\n",
        "# !kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wTfeo8tcxhwC"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ePuqIHSPf554",
        "outputId": "4829b253-e588-48a1-d61d-b2e932bced25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1180
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U spacy ftfy torchtext\n",
        "!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (2.0.18)\n",
            "Requirement already up-to-date: ftfy in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (5.5.1)\n",
            "Collecting torchtext\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/bc/b28b9efb4653c03e597ed207264eea45862b5260f48e9f010b5068d64db1/torchtext-0.3.1-py3-none-any.whl (62kB)\n",
            "Requirement already satisfied, skipping upgrade: regex==2018.01.10 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (2018.1.10)\n",
            "Requirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3,>=0.2 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (0.2.9)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: ujson>=1.35 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (1.35)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: thinc<6.13.0,>=6.12.1 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (1.16.1)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from ftfy) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: torch in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from torchtext) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from torchtext) (4.31.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.11.29)\n",
            "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
            "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six<2.0.0,>=1.10.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<0.6.0,>=0.5.6 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
            "Installing collected packages: torchtext\n",
            "Successfully installed torchtext-0.3.1\n",
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in c:\\projects\\nlpcw\\myvenv\\lib\\site-packages (2.0.0)\n",
            "\n",
            "    Linking successful\n",
            "    C:\\projects\\nlpcw\\myvenv\\lib\\site-packages\\en_core_web_sm -->\n",
            "    C:\\projects\\nlpcw\\myvenv\\lib\\site-packages\\spacy\\data\\en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "You do not have sufficient privilege to perform this operation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Srpq8hYt4whg",
        "outputId": "96cec12b-3ca8-4ad0-9acb-421d7f39c8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import sampler\n",
        "import spacy\n",
        "import torchvision.datasets as dset\n",
        "from torchtext import data\n",
        "from torchtext import datasets as nlp_dset\n",
        "import random\n",
        "from sklearn.utils import resample\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "nlp_spaCy = spacy.load('en')\n",
        "\n",
        "GPU = True\n",
        "device_idx = 0\n",
        "if GPU and torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:\"+str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "#Fix all seeds\n",
        "SEED = 0\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qtiwRhtm3s87",
        "outputId": "a877d94b-fd59-47c4-ddd3-dcfbf4f0ce2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "# Load datafiles from own google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_fp = \"\"\"/content/drive/My Drive/colab_data/offenseval-training-v1.tsv\"\"\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xGMVF5KTg-He"
      },
      "cell_type": "markdown",
      "source": [
        "## ELMO"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wxCJbS2h4jfG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torchvision torch allennlp\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8iTnEx03ZO2q",
        "outputId": "769b64d4-6d52-4e64-b892-5fe0b5d784fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#Use pretrained ELMO weights. \n",
        "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "\n",
        "elmo = Elmo(options_file, weight_file, 2, dropout=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 336/336 [00:00<00:00, 55516.49B/s]\n",
            "100%|██████████| 374434792/374434792 [00:21<00:00, 17177971.67B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3LeaTI5U7x5N",
        "outputId": "f2496a58-adc5-4b05-d7a5-6ad18dd36f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "#Elmo test\n",
        "sentences = [['First', 'sentence', '.'], ['Another', '.'], \n",
        "             [\"Oh\", \"here\", \"we\", \"Go\", \"now\", \"you\", \"fool\", \".\"], \n",
        "             [\"meaninglesswordnotinvocab\"]]\n",
        "             \n",
        "character_ids = batch_to_ids(sentences)\n",
        "\n",
        "embeddings = elmo(character_ids)\n",
        "\n",
        "print(character_ids.shape)\n",
        "embed = embeddings[\"elmo_representations\"]\n",
        "print(len(embed))\n",
        "print(embed[0].shape)\n",
        "print(embed[1].shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 8, 50])\n",
            "2\n",
            "torch.Size([4, 8, 1024])\n",
            "torch.Size([4, 8, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4N-meDamEjF7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ELMO takes a list of parsed sentences as an input\n",
        "# It generates an embedding of length 1024 per word\n",
        "# We then need to find a good method of combining the word vecs to create \n",
        "# a sentence embedding (this article is good: https://medium.com/huggingface/universal-word-sentence-embeddings-ce48ddc8fc3a). \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "t9Zt3py7E1ep"
      },
      "cell_type": "markdown",
      "source": [
        "## Import and preprocess Data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z9qQiPkQ3cna",
        "outputId": "f44b5c43-aa55-4de6-ed67-b5ac0e0250ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "cell_type": "code",
      "source": [
        "#ONLY RUN THIS CELL IF YOU WANT TO DOWNSAMPLE DATA - everything should work w/o this cell\n",
        "\n",
        "#Select a subset of the data so that the classes are equally balanced\n",
        "#Use downsampling for now. \n",
        "\n",
        "num_NOT = 8840\n",
        "num_OFF = 4400\n",
        "# Separate majority and minority classes\n",
        "df_majority = train_df[train_df[\"subtask_a\"] == 'NOT']\n",
        "df_minority = train_df[train_df[\"subtask_a\"] == 'OFF']\n",
        "\n",
        "# Downsample majority class\n",
        "df_majority_downsampled = resample(df_majority, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=num_OFF,     # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        " \n",
        "# Combine minority class with downsampled majority class\n",
        "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        " \n",
        "# Display new class counts\n",
        "print(df_downsampled.subtask_a.value_counts())\n",
        "\n",
        "df_downsampled = df_downsampled.sample(frac=1) #shuffle df\n",
        "\n",
        "\n",
        "train_df = df_downsampled"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e721546a3980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_OFF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Separate majority and minority classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_majority\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subtask_a\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NOT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf_minority\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subtask_a\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'OFF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aMY0mUyknLDu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tweet_preprocess(tweet_text):\n",
        "  \"\"\"Add tweet specific preprocessing steps here\"\"\"\n",
        "  \n",
        "  #Remove 'USER' (but leave '@')\n",
        "  tweet_text = tweet_text.replace(\"@USER\", \"@\") \n",
        "  \n",
        "  return tweet_text\n",
        "\n",
        "def convert_labels_A(labels):\n",
        "    \"\"\"Preproceses and return labels\"\"\"\n",
        "\n",
        "    final_labels = []\n",
        "    for label in labels:\n",
        "        assert label == \"OFF\" or label == \"NOT\", \"Label should not be: {}\".format(label)\n",
        "    \n",
        "        if label == \"OFF\":\n",
        "            res = 1\n",
        "        elif label == \"NOT\":\n",
        "            res = 0        \n",
        "        label = torch.tensor([res])\n",
        "        final_labels.append(label)\n",
        "    return final_labels\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "n1TwMNFOKRSm"
      },
      "cell_type": "markdown",
      "source": [
        "## GloVe"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6NVQcb0MKUCh",
        "outputId": "f104c245-3896-4e2a-a15e-5858e579c007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "# Use two GloVe trained on two different corpuses for comparison:\n",
        "    # Glove.6B\n",
        "    # glove.twitter.27B\n",
        "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip glove.twitter.27B.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-24 17:33:18--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
            "--2019-02-24 17:33:18--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  17.6MB/s    in 88s     \n",
            "\n",
            "2019-02-24 17:34:47 (16.5 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n",
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bpNZ2KEwMOyM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenizer(text): # create a tokenizer function for gloVe\n",
        "    res = [tok.text for tok in nlp_spaCy.tokenizer(text)]\n",
        "    return res\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WO69uqM3LtBS",
        "outputId": "bb00d48b-2900-4e87-d034-01396eb5a202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#Create fields\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False, use_vocab=True, batch_first = True)\n",
        "ID = data.LabelField(sequential=False, use_vocab=False, batch_first=True)\n",
        "\n",
        "data_fields = [('id', ID), \n",
        "               ('tweet', TEXT),\n",
        "               ('subtask_a',LABEL),\n",
        "               ('subtask_b',LABEL),\n",
        "               ('subtask_c',LABEL)]\n",
        "\n",
        "\n",
        "train = data.TabularDataset(train_fp, format='TSV', fields = \n",
        "                            data_fields, skip_header=True)\n",
        "\n",
        "train, valid = train.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Train size: {len(train)}')\n",
        "print(f'Validation size: {len(valid)}')\n",
        "\n",
        "#Now build vocab (using only the training set)\n",
        "TEXT.build_vocab(train, vectors='glove.twitter.27B.200d') #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
        "\n",
        "LABEL.build_vocab(train.subtask_a)\n",
        "\n",
        "output_dim = len(LABEL.vocab)\n",
        "\n",
        "#Create iterators\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                        batch_sizes=(BATCH_SIZE, len(valid)),  \n",
        "                        sort_key=lambda x: len(x.tweet), device=device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: 10592\n",
            "Validation size: 2648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KkGDZeI-rccB",
        "outputId": "269f87c7-4df6-4802-867b-f4256b393854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "print('first tweet', train[0].tweet)\n",
        "print('first label', train[0].subtask_a)\n",
        "print(\"first tweet id:\", train[0].id)\n",
        "# print(TEXT.vocab.stoi) # word to index\n",
        "# print(LABEL.vocab.stoi) # word to index\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first tweet ['@user', 'really', 'another', 'one', 'holy', 'crap', 'wow', 'all', 'brought', 'to', 'you', 'by', 'the', 'liberals', '.']\n",
            "first label OFF\n",
            "first tweet id: 49396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q9_NCwh3C1Z4",
        "outputId": "0e8a5fac-15dc-48cd-a29b-b6ee24f00283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#check loader\n",
        "for idx, batch in enumerate(train_iterator):\n",
        "    inputs, labels = batch.tweet, batch.subtask_a\n",
        "    print(inputs.shape)\n",
        "    print(labels.shape)\n",
        "    print(len(train_iterator))\n",
        "    break\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 72])\n",
            "torch.Size([128])\n",
            "67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "k4UHz12y6L7m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics \n",
        "\n",
        "PRINT_EVERY = 50\n",
        "\n",
        "def check_accuracy(loader, model, conf=False):\n",
        "    \"\"\"\n",
        "    Note at the moment this function assumes the batch size is equal to the \n",
        "    number of data in the loader when calculating the confusion matrix\n",
        "    \"\"\"\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    TP, TN, FP, FN = 0, 0, 0, 0\n",
        "    \n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(loader):\n",
        "            x, y = batch.tweet, batch.subtask_a\n",
        "            y = y.view(-1, 1)\n",
        "                \n",
        "            x = x.to(device=device, dtype=torch.long)  # move to  GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            pred_prob = torch.sigmoid(model(x))\n",
        "            pred_1 = (pred_prob > 0.5).type(torch.long)\n",
        "            num_correct += (pred_1 == y).sum()\n",
        "            num_samples += pred_prob.size(0)\n",
        "            \n",
        "            # move to CPU to prevent memory overflow and calculate metrics\n",
        "            x = x.to(device=\"cpu\", dtype=torch.long)\n",
        "            y = y.to(device=\"cpu\", dtype=torch.long).numpy()\n",
        "            pred_1 = pred_1.to(device=\"cpu\", dtype=torch.long).numpy()\n",
        "            \n",
        "            if conf:\n",
        "                TP, FP, FN, TN = metrics.confusion_matrix(y, pred_1).ravel()\n",
        "            \n",
        "            \n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "        if conf:\n",
        "            print(\"TP = {}, FN = {}, TN = {}, FN = {}\".format(TP, FP, TN, FN))\n",
        "            print(metrics.classification_report(y, pred_1))\n",
        "            \n",
        "def check_loss(loader, model, loss_fn):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    loss = 0\n",
        "    for idx, batch in enumerate(loader):\n",
        "      x, y = batch.tweet, batch.subtask_a\n",
        "      y = y.view(-1, 1)\n",
        "      \n",
        "      x = x.to(device=device, dtype=torch.long) \n",
        "      y = y.to(device=device, dtype=torch.long)\n",
        "      \n",
        "      output = model(x)\n",
        "      \n",
        "      y = y.type(torch.float)\n",
        "      loss += loss_fn(output, y).item()\n",
        "      \n",
        "    return loss/len(loader)\n",
        "      \n",
        "\n",
        "def train_helper(model, optimizer, epochs=1, loss_fn = F.binary_cross_entropy_with_logits, \n",
        "               print_every=PRINT_EVERY, train_loader=train_iterator, \n",
        "               valid_loader=valid_iterator):\n",
        "    \"\"\"\n",
        "    Train a model\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to GPU\n",
        "    \n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "    try:\n",
        "        for epoch in range(epochs):\n",
        "            print(\"Epoch:\", epoch)\n",
        "            total_loss = 0\n",
        "            for batch_idx, batch in enumerate(train_loader):\n",
        "\n",
        "                model.train()  # put model to training mode\n",
        "                \n",
        "                #Eventually make this more generic so it works for all parts (a, b, c):\n",
        "                inputs, targets = batch.tweet, batch.subtask_a\n",
        "                \n",
        "                x = inputs.to(device=device, dtype=torch.long)  # move to device, e.g. GPU\n",
        "                y = targets.to(device=device, dtype=torch.float) #this should be a float cross entropy\n",
        "                #x = inputs\n",
        "                #y = targets\n",
        "                logits = model(x)\n",
        "                y = y.type(torch.float)\n",
        "                loss = loss_fn(logits.view((-1,)), y)\n",
        "                # Zero out all of the gradients for the variables which the optimizer\n",
        "                # will update.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # This is the backwards pass: compute the gradient of the loss with\n",
        "                # respect to each  parameter of the model.\n",
        "                loss.backward()\n",
        "\n",
        "                # Actually update the parameters of the model using the gradients\n",
        "                # computed by the backwards pass.\n",
        "                optimizer.step()\n",
        "\n",
        "                x = x.to(device=\"cpu\", dtype=torch.long)  # move to CPU to prevent memory overflow\n",
        "                y = y.to(device=\"cpu\", dtype=torch.long)\n",
        "\n",
        "                total_loss += loss.detach().item()\n",
        "                \n",
        "                if batch_idx % print_every == 0:\n",
        "                    print('Iteration %d, loss = %.4f' % (batch_idx, loss.item()))\n",
        "            \n",
        "            training_losses.append(total_loss/len(train_iterator))\n",
        "            print()\n",
        "            print(\"Validation Accuracy:\")\n",
        "            check_accuracy(valid_loader, model, conf=True)\n",
        "            valid_loss = check_loss(valid_loader, model, loss_fn)\n",
        "            validation_losses.append(valid_loss)\n",
        "            print()\n",
        "        return training_losses, validation_losses\n",
        "    except Exception as e:\n",
        "        #Attempt to prevent GPU memory overflow by transferring model back to cpu\n",
        "        #model = model.to(device=\"cpu\")\n",
        "        raise e    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PeisH53s6cfR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#embedding (lookup layer) layer\n",
        "class SimpleClassifierGloVe(nn.Module):\n",
        "    \"\"\"Glove w. 2d conv\"\"\"\n",
        "    \n",
        "    def __init__(self, vocab, embedding_dim, window_size, out_channels, dropout):\n",
        "        \n",
        "        super(SimpleClassifierGloVe, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.vocab = vocab\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "        self.embedding.weight.data.copy_(vocab.vectors) # copies pre-trained word vectors\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(window_size, embedding_dim))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(out_channels, 1)\n",
        "\n",
        "        #Kaming normalization\n",
        "        nn.init.kaiming_normal_(self.conv.weight)\n",
        "        nn.init.kaiming_normal_(self.fc.weight)\n",
        "\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        embedded = self.embedding(x)\n",
        "                \n",
        "        #(batch size, max sent length, embedding dim)\n",
        "        \n",
        "        #images have 3 RGB channels \n",
        "        #for the text we add 1 channel\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        \n",
        "        #(batch size, 1, max sent length, embedding dim)\n",
        "        \n",
        "        feature_maps =  F.relu(self.conv(embedded).squeeze(3))\n",
        "        # (batch size, out_channels, max sent length - window size +1, 1)\n",
        "        # -> (batch size, out_channels, max sent length - window size +1)\n",
        "           \n",
        "        #the max pooling layer\n",
        "        pooled = F.max_pool1d(feature_maps, feature_maps.shape[2]).squeeze(2)\n",
        "        # (batch size, out_channels)      \n",
        "        \n",
        "        # Do batch normalize pooled then at sentiment\n",
        "        \n",
        "        return self.fc( self.dropout(pooled))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "X9LseL5F9n7P",
        "outputId": "7cbd2669-1294-4ee5-c9f8-aeba597e605a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5729
        }
      },
      "cell_type": "code",
      "source": [
        "#CONV with Glove\n",
        "embedding_dim = 200\n",
        "window_size = 3\n",
        "lr = 0.00025\n",
        "out_channels = 100\n",
        "dropout = 0.5\n",
        "\n",
        "model = SimpleClassifierGloVe(TEXT.vocab, embedding_dim, window_size, out_channels, dropout)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "t_losses, v_losses = train_helper(model, optimizer, loss_fn = loss_fn, epochs = 20)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iteration 0, loss = 1.0039\n",
            "Iteration 50, loss = 0.7888\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1412 / 2118 correct (66.67)\n",
            "TP = 1377, FN = 18, TN = 35, FN = 688\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.99      0.80      1395\n",
            "           1       0.66      0.05      0.09       723\n",
            "\n",
            "   micro avg       0.67      0.67      0.67      2118\n",
            "   macro avg       0.66      0.52      0.44      2118\n",
            "weighted avg       0.66      0.67      0.56      2118\n",
            "\n",
            "\n",
            "Epoch: 1\n",
            "Iteration 0, loss = 0.8521\n",
            "Iteration 50, loss = 0.8099\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1448 / 2118 correct (68.37)\n",
            "TP = 1368, FN = 27, TN = 80, FN = 643\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.98      0.80      1395\n",
            "           1       0.75      0.11      0.19       723\n",
            "\n",
            "   micro avg       0.68      0.68      0.68      2118\n",
            "   macro avg       0.71      0.55      0.50      2118\n",
            "weighted avg       0.70      0.68      0.59      2118\n",
            "\n",
            "\n",
            "Epoch: 2\n",
            "Iteration 0, loss = 0.6326\n",
            "Iteration 50, loss = 0.6276\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1486 / 2118 correct (70.16)\n",
            "TP = 1341, FN = 54, TN = 145, FN = 578\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.96      0.81      1395\n",
            "           1       0.73      0.20      0.31       723\n",
            "\n",
            "   micro avg       0.70      0.70      0.70      2118\n",
            "   macro avg       0.71      0.58      0.56      2118\n",
            "weighted avg       0.71      0.70      0.64      2118\n",
            "\n",
            "\n",
            "Epoch: 3\n",
            "Iteration 0, loss = 0.6160\n",
            "Iteration 50, loss = 0.5473\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1521 / 2118 correct (71.81)\n",
            "TP = 1311, FN = 84, TN = 210, FN = 513\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.94      0.81      1395\n",
            "           1       0.71      0.29      0.41       723\n",
            "\n",
            "   micro avg       0.72      0.72      0.72      2118\n",
            "   macro avg       0.72      0.62      0.61      2118\n",
            "weighted avg       0.72      0.72      0.68      2118\n",
            "\n",
            "\n",
            "Epoch: 4\n",
            "Iteration 0, loss = 0.5984\n",
            "Iteration 50, loss = 0.6122\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1516 / 2118 correct (71.58)\n",
            "TP = 1333, FN = 62, TN = 183, FN = 540\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.96      0.82      1395\n",
            "           1       0.75      0.25      0.38       723\n",
            "\n",
            "   micro avg       0.72      0.72      0.72      2118\n",
            "   macro avg       0.73      0.60      0.60      2118\n",
            "weighted avg       0.72      0.72      0.67      2118\n",
            "\n",
            "\n",
            "Epoch: 5\n",
            "Iteration 0, loss = 0.5275\n",
            "Iteration 50, loss = 0.4854\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1559 / 2118 correct (73.61)\n",
            "TP = 1296, FN = 99, TN = 263, FN = 460\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.93      0.82      1395\n",
            "           1       0.73      0.36      0.48       723\n",
            "\n",
            "   micro avg       0.74      0.74      0.74      2118\n",
            "   macro avg       0.73      0.65      0.65      2118\n",
            "weighted avg       0.73      0.74      0.71      2118\n",
            "\n",
            "\n",
            "Epoch: 6\n",
            "Iteration 0, loss = 0.4735\n",
            "Iteration 50, loss = 0.4386\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1598 / 2118 correct (75.45)\n",
            "TP = 1266, FN = 129, TN = 332, FN = 391\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.91      0.83      1395\n",
            "           1       0.72      0.46      0.56       723\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2118\n",
            "   macro avg       0.74      0.68      0.70      2118\n",
            "weighted avg       0.75      0.75      0.74      2118\n",
            "\n",
            "\n",
            "Epoch: 7\n",
            "Iteration 0, loss = 0.4096\n",
            "Iteration 50, loss = 0.4268\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1615 / 2118 correct (76.25)\n",
            "TP = 1271, FN = 124, TN = 344, FN = 379\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.91      0.83      1395\n",
            "           1       0.74      0.48      0.58       723\n",
            "\n",
            "   micro avg       0.76      0.76      0.76      2118\n",
            "   macro avg       0.75      0.69      0.71      2118\n",
            "weighted avg       0.76      0.76      0.75      2118\n",
            "\n",
            "\n",
            "Epoch: 8\n",
            "Iteration 0, loss = 0.3765\n",
            "Iteration 50, loss = 0.4544\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1615 / 2118 correct (76.25)\n",
            "TP = 1270, FN = 125, TN = 345, FN = 378\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.91      0.83      1395\n",
            "           1       0.73      0.48      0.58       723\n",
            "\n",
            "   micro avg       0.76      0.76      0.76      2118\n",
            "   macro avg       0.75      0.69      0.71      2118\n",
            "weighted avg       0.76      0.76      0.75      2118\n",
            "\n",
            "\n",
            "Epoch: 9\n",
            "Iteration 0, loss = 0.4231\n",
            "Iteration 50, loss = 0.4051\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1621 / 2118 correct (76.53)\n",
            "TP = 1261, FN = 134, TN = 360, FN = 363\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.90      0.84      1395\n",
            "           1       0.73      0.50      0.59       723\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2118\n",
            "   macro avg       0.75      0.70      0.71      2118\n",
            "weighted avg       0.76      0.77      0.75      2118\n",
            "\n",
            "\n",
            "Epoch: 10\n",
            "Iteration 0, loss = 0.3762\n",
            "Iteration 50, loss = 0.3322\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1627 / 2118 correct (76.82)\n",
            "TP = 1268, FN = 127, TN = 359, FN = 364\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.91      0.84      1395\n",
            "           1       0.74      0.50      0.59       723\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2118\n",
            "   macro avg       0.76      0.70      0.72      2118\n",
            "weighted avg       0.76      0.77      0.75      2118\n",
            "\n",
            "\n",
            "Epoch: 11\n",
            "Iteration 0, loss = 0.2992\n",
            "Iteration 50, loss = 0.4294\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1639 / 2118 correct (77.38)\n",
            "TP = 1256, FN = 139, TN = 383, FN = 340\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.90      0.84      1395\n",
            "           1       0.73      0.53      0.62       723\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2118\n",
            "   macro avg       0.76      0.72      0.73      2118\n",
            "weighted avg       0.77      0.77      0.76      2118\n",
            "\n",
            "\n",
            "Epoch: 12\n",
            "Iteration 0, loss = 0.4074\n",
            "Iteration 50, loss = 0.3308\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1636 / 2118 correct (77.24)\n",
            "TP = 1259, FN = 136, TN = 377, FN = 346\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.90      0.84      1395\n",
            "           1       0.73      0.52      0.61       723\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2118\n",
            "   macro avg       0.76      0.71      0.72      2118\n",
            "weighted avg       0.77      0.77      0.76      2118\n",
            "\n",
            "\n",
            "Epoch: 13\n",
            "Iteration 0, loss = 0.3284\n",
            "Iteration 50, loss = 0.3754\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1647 / 2118 correct (77.76)\n",
            "TP = 1241, FN = 154, TN = 406, FN = 317\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.89      0.84      1395\n",
            "           1       0.72      0.56      0.63       723\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2118\n",
            "   macro avg       0.76      0.73      0.74      2118\n",
            "weighted avg       0.77      0.78      0.77      2118\n",
            "\n",
            "\n",
            "Epoch: 14\n",
            "Iteration 0, loss = 0.3266\n",
            "Iteration 50, loss = 0.3804\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1643 / 2118 correct (77.57)\n",
            "TP = 1246, FN = 149, TN = 397, FN = 326\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84      1395\n",
            "           1       0.73      0.55      0.63       723\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2118\n",
            "   macro avg       0.76      0.72      0.73      2118\n",
            "weighted avg       0.77      0.78      0.77      2118\n",
            "\n",
            "\n",
            "Epoch: 15\n",
            "Iteration 0, loss = 0.3300\n",
            "Iteration 50, loss = 0.2883\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1647 / 2118 correct (77.76)\n",
            "TP = 1243, FN = 152, TN = 404, FN = 319\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.89      0.84      1395\n",
            "           1       0.73      0.56      0.63       723\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2118\n",
            "   macro avg       0.76      0.72      0.74      2118\n",
            "weighted avg       0.77      0.78      0.77      2118\n",
            "\n",
            "\n",
            "Epoch: 16\n",
            "Iteration 0, loss = 0.3321\n",
            "Iteration 50, loss = 0.3248\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1649 / 2118 correct (77.86)\n",
            "TP = 1246, FN = 149, TN = 403, FN = 320\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.89      0.84      1395\n",
            "           1       0.73      0.56      0.63       723\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2118\n",
            "   macro avg       0.76      0.73      0.74      2118\n",
            "weighted avg       0.77      0.78      0.77      2118\n",
            "\n",
            "\n",
            "Epoch: 17\n",
            "Iteration 0, loss = 0.3405\n",
            "Iteration 50, loss = 0.3579\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1643 / 2118 correct (77.57)\n",
            "TP = 1232, FN = 163, TN = 411, FN = 312\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.88      0.84      1395\n",
            "           1       0.72      0.57      0.63       723\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2118\n",
            "   macro avg       0.76      0.73      0.74      2118\n",
            "weighted avg       0.77      0.78      0.77      2118\n",
            "\n",
            "\n",
            "Epoch: 18\n",
            "Iteration 0, loss = 0.2853\n",
            "Iteration 50, loss = 0.2424\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1644 / 2118 correct (77.62)\n",
            "TP = 1243, FN = 152, TN = 401, FN = 322\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84      1395\n",
            "           1       0.73      0.55      0.63       723\n",
            "\n",
            "   micro avg       0.78      0.78      0.78      2118\n",
            "   macro avg       0.76      0.72      0.73      2118\n",
            "weighted avg       0.77      0.78      0.77      2118\n",
            "\n",
            "\n",
            "Epoch: 19\n",
            "Iteration 0, loss = 0.1877\n",
            "Iteration 50, loss = 0.2638\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 1640 / 2118 correct (77.43)\n",
            "TP = 1240, FN = 155, TN = 400, FN = 323\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84      1395\n",
            "           1       0.72      0.55      0.63       723\n",
            "\n",
            "   micro avg       0.77      0.77      0.77      2118\n",
            "   macro avg       0.76      0.72      0.73      2118\n",
            "weighted avg       0.77      0.77      0.77      2118\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_q8EEjwwLf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "0c4f7105-ff5e-49af-d48e-0930a38fcfb1"
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(t_losses, label='Training')\n",
        "ax1.plot(v_losses, label='Validation')\n",
        "\n",
        "ax1.set_title('Losses')\n",
        "ax1.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TSaz7XNLG2f4"
      },
      "cell_type": "markdown",
      "source": [
        "## Bert Pre-processing"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KlqIs-m8Eq56",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# BERT summary\n",
        "# The first token of every sequence is the classification embedding \"[CLS]\"\n",
        "# There are two types of sentence in the representation: A & B. These are used for\n",
        "# Question-answering systems. For our purposes, all sentences/tweets will be type A. \n",
        "# A and B are seperated with the special token \"[SEP]\". Again, we don't need this here.\n",
        "\n",
        "# We should use the \"bert-large-uncased\" eventually which has 1024 latent features\n",
        "# but for now use \"bert-base-uncased\" which has 768\n",
        "\n",
        "\n",
        "#The model returns the embedded representations in the form:\n",
        "# encoded_layers, pooled_output\n",
        "# encoded_layers: The activations of each of the 12 layers (or 24 layers in BERT-large)\n",
        "#                 list of length 12/24 where each element is a tensor of dimensions:\n",
        "#                 (B, L, F) for Batch size B, sequence length L and number feautures F\n",
        "\n",
        "#if you want the output embeddings per word, use encoded_layers[-1]\n",
        "#if you want to use the BERT sentence embedding use pooled_output\n",
        "# We will use pooled_output for now\n",
        "\n",
        "#encoded_layers, pooled_output = model(tokens_tensor, segments_tensor)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "def convert_tweets_to_features(tweet_list, seq_length, tokenizer):\n",
        "    \"\"\"returns the BERT features\"\"\"\n",
        "\n",
        "    tokenized_tweets = []\n",
        "    input_ids_list = []\n",
        "    input_masks = []\n",
        "    input_type_ids_list= []\n",
        "                \n",
        "    for (index, tweet) in enumerate(tweet_list):\n",
        "       \n",
        "        \n",
        "        # The convention in BERT is:\n",
        "        # (a) For sequence pairs:\n",
        "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        #  type_ids:   0   0  0    0    0     0      0   0    1  1  1   1  1   1\n",
        "        # (b) For single sequences:\n",
        "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        #  type_ids:   0   0   0   0  0     0   0\n",
        "        #\n",
        "        # Where \"type_ids\" are used to indicate whether this is the first\n",
        "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "        # embedding vector (and position vector). This is not *strictly* necessary\n",
        "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "        #\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        \n",
        "        tweet = tweet_preprocess(tweet)\n",
        "        tokens_a = tokenizer.tokenize(tweet)\n",
        "            \n",
        "        tokens = []\n",
        "        input_type_ids = []\n",
        "        tokens.append(\"[CLS]\")\n",
        "        input_type_ids.append(0)\n",
        "        for token in tokens_a:\n",
        "            tokens.append(token)\n",
        "            input_type_ids.append(0)\n",
        "        tokens.append(\"[SEP]\")\n",
        "        input_type_ids.append(0)\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1] * len(input_ids)\n",
        "        #print(\"current length input ids:\", len(input_ids))\n",
        "        \n",
        "        # Zero-pad up to the sequence length.\n",
        "        while len(input_ids) < seq_length:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "            input_type_ids.append(0)\n",
        "\n",
        "        assert len(input_ids) == seq_length, \"{} should = {}\".format(len(input_ids), seq_length)\n",
        "        assert len(input_mask) == seq_length\n",
        "        assert len(input_type_ids) == seq_length\n",
        "        \n",
        "        input_ids_tensor = torch.tensor(input_ids)\n",
        "        input_mask_tensor = torch.tensor(input_mask)\n",
        "        input_type_ids_tensor = torch.tensor(input_type_ids)\n",
        "    \n",
        "        tokenized_tweets.append(tokens)\n",
        "        input_ids_list.append(input_ids_tensor)\n",
        "        input_masks.append(input_mask_tensor)\n",
        "        input_type_ids_list.append(input_type_ids_tensor)\n",
        "        \n",
        "    results = (tokenized_tweets, input_ids_list, input_masks, input_type_ids_list)\n",
        "    return results\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FGXJkLCmL2Ip",
        "outputId": "c8fe9a10-23c1-45c8-b8a6-4ae28c400ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "#Preprocessing BERT\n",
        "\n",
        "tweet_train_list = train_df[\"tweet\"].tolist()\n",
        "tweet_valid_list = valid_df[\"tweet\"].tolist()\n",
        "#find max length of tokens \n",
        "max_len = 0\n",
        "longest_tokens = None\n",
        "for tweet in (tweet_train_list + tweet_valid_list):\n",
        "    tweet = tweet_preprocess(tweet)\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "    tokens_len = len(tokens)\n",
        "    if tokens_len > max_len:\n",
        "        max_len = tokens_len\n",
        "        longest_tokens = tokens \n",
        "        \n",
        "print(\"Max token length is\", max_len)\n",
        "\n",
        "#Add an extra few symbols in case the tweets in the test-set are longer\n",
        "MAX_SEQ = max_len + 4 \n",
        "\n",
        "#preprocess tweets and extract labels\n",
        "LABELS_TRAIN = convert_labels_A(train_df[\"subtask_a\"].tolist())\n",
        "FEATURES_TRAIN = convert_tweets_to_features(tweet_train_list, MAX_SEQ, tokenizer)\n",
        "\n",
        "LABELS_VALID = convert_labels_A(valid_df[\"subtask_a\"].tolist())\n",
        "FEATURES_VALID = convert_tweets_to_features(tweet_valid_list, MAX_SEQ, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max token length is 119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4LYWiFk4IzGx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#BERT Data Loaders \n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def train_loader(batch_size = BATCH_SIZE, labels = LABELS_TRAIN, features = FEATURES_TRAIN):\n",
        "    \"\"\"Training Loader\"\"\"\n",
        "    return loader_gen(batch_size = BATCH_SIZE, labels = LABELS_TRAIN, features = FEATURES_TRAIN)\n",
        "def valid_loader():\n",
        "    \"\"\"Validate set loader\"\"\"\n",
        "    return loader_gen(batch_size = BATCH_SIZE, labels = LABELS_VALID, features = FEATURES_VALID)\n",
        "    \n",
        "def loader_gen(batch_size = BATCH_SIZE, labels = LABELS_TRAIN, features = FEATURES_TRAIN):\n",
        "    \"\"\"Generator - bespoke loader. \n",
        "    yields an output of (data, label).\n",
        "        data is a torch tensor of shape (B, L, 2)\n",
        "            where B is batch size, L is number of tokens per tweet and the final \n",
        "            dimension holds the BERT token indexes and the BERT token masks \n",
        "            in the first and second components respectively\"\"\"\n",
        "    \n",
        "    (tokenized_tweets, tweet_ids_list, input_masks, input_type_ids_list) = features \n",
        "    \n",
        "    batch_id_tensor_list = []\n",
        "    batch_mask_tensor_list = []\n",
        "    batch_labels_tensor_list = []\n",
        "    for (idx, tweet_ids) in enumerate(tweet_ids_list):\n",
        "\n",
        "        batch_id_tensor_list.append(tweet_ids)\n",
        "        batch_mask_tensor_list.append(input_masks[idx])\n",
        "        batch_labels_tensor_list.append(labels[idx])\n",
        "        \n",
        "        if len(batch_id_tensor_list) == BATCH_SIZE:\n",
        "            \n",
        "            #Then produce and yield an output batch tensor and label\n",
        "            batch_id_tensor = torch.stack(batch_id_tensor_list)\n",
        "            batch_mask_tensor = torch.stack(batch_mask_tensor_list)\n",
        "            input_tensor = torch.stack((batch_id_tensor, batch_mask_tensor), dim=2)\n",
        "            batch_labels_tensor = torch.stack(batch_labels_tensor_list)\n",
        "            \n",
        "            assert batch_mask_tensor.shape == (batch_size, MAX_SEQ)\n",
        "            assert batch_id_tensor.shape == (batch_size, MAX_SEQ)\n",
        "            assert input_tensor.shape == (batch_size, MAX_SEQ, 2)\n",
        "            assert batch_labels_tensor.shape == (batch_size, 1)\n",
        "            \n",
        "            \n",
        "            yield (input_tensor, batch_labels_tensor)\n",
        "            batch_id_tensor_list = []\n",
        "            batch_mask_tensor_list = []\n",
        "            batch_labels_tensor_list = []\n",
        "    \n",
        "    #check if there is a small batch left...\n",
        "    if len(batch_id_tensor_list) > 0:\n",
        "        batch_id_tensor = torch.stack(batch_id_tensor_list)\n",
        "        batch_mask_tensor = torch.stack(batch_mask_tensor_list)\n",
        "        input_tensor = torch.stack((batch_id_tensor, batch_mask_tensor), dim=2)\n",
        "        batch_labels_tensor = torch.stack(batch_labels_tensor_list)\n",
        "        \n",
        "        yield (input_tensor, batch_labels_tensor)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YzQKWzPfHGnS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kB-AAEV1I41I"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_nFNFYJhl4cA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PRINT_EVERY = 50\n",
        "\n",
        "def check_accuracy(loader, model, conf=False): \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    TP, TN, FP, FN = 0, 0, 0, 0\n",
        "    \n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for idx, (x, y) in enumerate(loader()):\n",
        "            x = x.to(device=device, dtype=torch.long)  # move to  GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            pred_prob = model(x)\n",
        "            pred_1 = (pred_prob > 0.5).type(torch.long)\n",
        "            num_correct += (pred_1 == y).sum()\n",
        "            num_samples += pred_prob.size(0)\n",
        "            \n",
        "            if conf:\n",
        "                #find confusion matrix\n",
        "                \n",
        "                #find number correct class 1\n",
        "                TP += ((pred_1 == 1) & (y == 1)).sum()\n",
        "                FP += ((pred_1 == 1) & (y == 0)).sum()\n",
        "                TN += ((pred_1 == 0) & (y == 0)).sum()\n",
        "                FN += ((pred_1 == 0) & (y == 1)).sum()\n",
        "            \n",
        "            x = x.to(device=\"cpu\", dtype=torch.long)  # move to CPU to prevent memory overflow\n",
        "            y = y.to(device=\"cpu\", dtype=torch.long)\n",
        "            \n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "        if conf:\n",
        "            print(\"TP = {}, FN = {}, TN = {}, FN = {}\".format(TP, FP, TN, FN))\n",
        "\n",
        "def train_part(model, optimizer, epochs=1, loss_fn = F.binary_cross_entropy, print_every=PRINT_EVERY):\n",
        "    \"\"\"\n",
        "    Train a model\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to GPU\n",
        "    try:\n",
        "        for e in range(epochs):\n",
        "            for batch_idx, (inputs, targets) in enumerate(train_loader()):\n",
        "\n",
        "                model.train()  # put model to training mode\n",
        "\n",
        "                x = inputs.to(device=device, dtype=torch.long)  # move to device, e.g. GPU\n",
        "                y = targets.to(device=device, dtype=torch.float) #this should be a float cross entropy\n",
        "                #x = inputs\n",
        "                #y = targets\n",
        "                prob = model(x)\n",
        "                y = y.type(torch.float)\n",
        "                loss = loss_fn(prob, y)\n",
        "                # Zero out all of the gradients for the variables which the optimizer\n",
        "                # will update.\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # This is the backwards pass: compute the gradient of the loss with\n",
        "                # respect to each  parameter of the model.\n",
        "                loss.backward()\n",
        "\n",
        "                # Actually update the parameters of the model using the gradients\n",
        "                # computed by the backwards pass.\n",
        "                optimizer.step()\n",
        "\n",
        "                x = x.to(device=\"cpu\", dtype=torch.long)  # move to CPU to prevent memory overflow\n",
        "                y = y.to(device=\"cpu\", dtype=torch.long)\n",
        "\n",
        "                if batch_idx % print_every == 0:\n",
        "                    print('Iteration %d, loss = %.4f' % (batch_idx, loss.item()))\n",
        "                    check_accuracy(valid_loader, model, conf=True)\n",
        "            print()\n",
        "            print(\"Validation Accuracy:\")\n",
        "            check_accuracy(valid_loader, model, conf=True)\n",
        "            print()\n",
        "\n",
        "    except Exception as e:\n",
        "        #Attempt to prevent GPU memory overflow by transferring model back to cpu\n",
        "        #model = model.to(device=\"cpu\")\n",
        "        raise e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7ZiirMXp9Dq9"
      },
      "cell_type": "markdown",
      "source": [
        "### Test BERT Loader"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RfabnjsCcUse",
        "outputId": "a33f64ef-cdc1-45bf-b4dc-93679a95d7c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "#Test loader\n",
        "#get first batch from train loader\n",
        "#Now compare with values obtained w/o loader\n",
        "(_, tweet_ids_list, input_masks, _) = FEATURES_TRAIN\n",
        "\n",
        "tweet_ids_tensor = tweet_ids_list[0].view((1, -1)) #use just first value\n",
        "input_masks = input_masks[0].view((1, -1))\n",
        "with torch.no_grad():\n",
        "    bert.eval()\n",
        "    encoded_2, pooled_output_2 = bert(tweet_ids_tensor, output_all_encoded_layers=False,\n",
        "                                               attention_mask=input_masks, )\n",
        "    \n",
        "for idx, (inputs, targets) in enumerate(train_loader()):\n",
        "\n",
        "    input_ids = inputs[:, :, 0] #token IDs\n",
        "    attention_mask = inputs[:, :, 1]  #attention mask (to ignore padding)\n",
        "    with torch.no_grad():\n",
        "        bert.eval()\n",
        "        encoded_layers, pooled_output = bert(input_ids, output_all_encoded_layers=False,\n",
        "                                                       attention_mask=attention_mask, )\n",
        "    assert False #to stop full loop"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sC2CqeyZ888o",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert torch.allclose(attention_mask, input_masks)\n",
        "assert torch.allclose(input_ids, tweet_ids_tensor)\n",
        "\n",
        "with torch.no_grad():\n",
        "    bert.eval()\n",
        "    encoded_3, pooled_output_3 = bert(tweet_ids_tensor, output_all_encoded_layers=False,\n",
        "                                                   attention_mask=input_masks, )\n",
        "    encoded_4, pooled_output_4 = bert(tweet_ids_tensor, output_all_encoded_layers=False,\n",
        "                                                   attention_mask=input_masks, )\n",
        "\n",
        "\n",
        "assert torch.allclose(pooled_output_3, pooled_output_4) \n",
        "print(pooled_output_3[0, 3])\n",
        "print(pooled_output_4[0, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SClCUJp08-zn"
      },
      "cell_type": "markdown",
      "source": [
        "## BERT Models"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hbv8FFf8Ixah",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FcnnBertEmbeddingBinary(nn.Module):\n",
        "    \"Bert with fully connected NN\"\n",
        "    def __init__(self, embedding_dim, hidden_dim_1, hidden_dim_2, hidden_dim_3, max_len):\n",
        "        \n",
        "        super(FcnnBertEmbeddingBinary, self).__init__()\n",
        "        \n",
        "        #embedding (lookup layer) layer\n",
        "        self.embedding = BertModel.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        #hidden layers\n",
        "        self.fc1 = nn.Linear(embedding_dim, hidden_dim_1, bias=True)\n",
        "        self.fc2 = nn.Linear(hidden_dim_1, hidden_dim_2, bias = True) \n",
        "        self.fc3 = nn.Linear(hidden_dim_2, hidden_dim_3, bias = True)\n",
        "        \n",
        "        #output layer\n",
        "        self.fc4 = nn.Linear(hidden_dim_3, 1, bias = True)\n",
        "        \n",
        "        #Kaming normalization\n",
        "        nn.init.kaiming_normal_(self.fc1.weight)\n",
        "        nn.init.kaiming_normal_(self.fc2.weight)\n",
        "        nn.init.kaiming_normal_(self.fc3.weight)\n",
        "        nn.init.kaiming_normal_(self.fc4.weight)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #Put into .eval mode to export exact weights\n",
        "        self.eval()\n",
        "        input_ids = x[:, :, 0] #token IDs\n",
        "        attention_mask = x[:, :, 1]  #attention mask (to ignore padding)\n",
        "        \n",
        "        \n",
        "        encoded_layers, pooled_output = self.embedding(input_ids, \n",
        "                                                     attention_mask=attention_mask)\n",
        "        self.train()\n",
        "        \n",
        "        #Use 'pooled output' as the overall embedding of the sentence.\n",
        "        #This is recommended in the BERT paper for classification tasks\n",
        "        \n",
        "        #A bit of background on what we are doing here:\n",
        "        #BERT creates its vectors by taking context before and context \n",
        "        #after every token in the sequence. The pooled_output is the \n",
        "        #resultant vector for the first token and is (according to the paper)\n",
        "        #the best representation of the sentence as a whole\n",
        "        h = F.relu(pooled_output)\n",
        "        h = F.relu(self.fc1(h))\n",
        "        h = F.relu(self.fc2(h))\n",
        "        h = F.relu(self.fc3(h))\n",
        "        h = torch.sigmoid(self.fc4(h))\n",
        "        \n",
        "        return h\n",
        "\n",
        "class SimpleClassifierWBert(nn.Module):\n",
        "    \"\"\"Bert w. 2d conv\"\"\"\n",
        "    def __init__(self, out_channels, window_size, dropout):\n",
        "        super(SimpleClassifierWBert, self).__init__()\n",
        "        \n",
        "        self.embedding = BertModel.from_pretrained('bert-base-uncased')\n",
        "        embedding_dim = 768\n",
        "        \n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(window_size, embedding_dim))\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(out_channels, 1)\n",
        "        \n",
        "        #Kaming normalization\n",
        "        nn.init.kaiming_normal_(self.conv.weight)\n",
        "        nn.init.kaiming_normal_(self.fc.weight)\n",
        "\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        self.eval()\n",
        "        input_ids = x[:, :, 0] #token IDs\n",
        "        attention_mask = x[:, :, 1]  #attention mask (to ignore padding)\n",
        "        \n",
        "        encoded_layers, pooled_output = self.embedding(input_ids, output_all_encoded_layers=False,\n",
        "                                                       attention_mask=attention_mask )\n",
        "        self.train()\n",
        "        \n",
        "        #Use 'final encoded layer' which is of size:\n",
        "            #[batch_size, sequence_length, embedding_dim]\n",
        "        \n",
        "        embedded = encoded_layers.unsqueeze(1)\n",
        "        \n",
        "        assert embedded.shape == (BATCH_SIZE, 1, MAX_SEQ, 768)\n",
        "        \n",
        "        #(batch size, 1, max sent length, embedding dim)\n",
        "        \n",
        "        feature_maps =  F.relu(self.conv(embedded).squeeze(3))\n",
        "        # (batch size, out_channels, max sent length - window size +1, 1)\n",
        "        # -> (batch size, out_channels, max sent length - window size +1)\n",
        "           \n",
        "        #the max pooling layer\n",
        "        pooled = F.max_pool1d(feature_maps, feature_maps.shape[2]).squeeze(2)\n",
        "        # (batch size, out_channels)      \n",
        " \n",
        "        return self.fc( self.dropout(pooled))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sTt9LkEcNIq9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CONV with bert\n",
        "embedding_dim = 768\n",
        "max_len = MAX_SEQ\n",
        "hidden_dim_1 = 128\n",
        "hidden_dim_2 = 16\n",
        "hidden_dim_3 = 4\n",
        "lr = 0.00025\n",
        "\n",
        "model = SimpleClassifierWBert(out_channels=100, window_size=3, dropout=0.5)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "train_part(model, optimizer, loss_fn = loss_fn, epochs = 5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-MhweQ2jVFT4",
        "outputId": "fcbc1b8d-d282-4c64-f9e4-0bb24acf6e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1065
        }
      },
      "cell_type": "code",
      "source": [
        "#Fully connected w. Bert sentence embeddings\n",
        "embedding_dim = 768\n",
        "max_len = MAX_SEQ\n",
        "hidden_dim_1 = 128\n",
        "hidden_dim_2 = 16\n",
        "hidden_dim_3 = 4\n",
        "lr = 0.00025\n",
        "\n",
        "model = FcnnBertEmbeddingBinary(embedding_dim, hidden_dim_1, hidden_dim_2, hidden_dim_3, max_len)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr)\n",
        "\n",
        "train_part(model, optimizer, epochs = 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, loss = 0.7172\n",
            "Got 77 / 320 correct (24.06)\n",
            "TP = 77, FN = 243, TN = 0, FN = 0\n",
            "Iteration 50, loss = 0.7054\n",
            "Got 243 / 320 correct (75.94)\n",
            "TP = 0, FN = 0, TN = 243, FN = 77\n",
            "Iteration 100, loss = 0.7053\n",
            "Got 243 / 320 correct (75.94)\n",
            "TP = 0, FN = 0, TN = 243, FN = 77\n",
            "Iteration 150, loss = 0.7087\n",
            "Got 77 / 320 correct (24.06)\n",
            "TP = 77, FN = 243, TN = 0, FN = 0\n",
            "Iteration 200, loss = 0.6910\n",
            "Got 243 / 320 correct (75.94)\n",
            "TP = 0, FN = 0, TN = 243, FN = 77\n",
            "Iteration 250, loss = 0.6941\n",
            "Got 243 / 320 correct (75.94)\n",
            "TP = 0, FN = 0, TN = 243, FN = 77\n",
            "\n",
            "Validation Accuracy:\n",
            "Got 243 / 320 correct (75.94)\n",
            "TP = 0, FN = 0, TN = 243, FN = 77\n",
            "\n",
            "Iteration 0, loss = 0.6938\n",
            "Got 77 / 320 correct (24.06)\n",
            "TP = 77, FN = 243, TN = 0, FN = 0\n",
            "Iteration 50, loss = 0.6933\n",
            "Got 243 / 320 correct (75.94)\n",
            "TP = 0, FN = 0, TN = 243, FN = 77\n",
            "Iteration 100, loss = 0.6940\n",
            "Got 243 / 320 correct (75.94)\n",
            "TP = 0, FN = 0, TN = 243, FN = 77\n",
            "Iteration 150, loss = 0.6926\n",
            "Got 243 / 320 correct (75.94)\n",
            "TP = 0, FN = 0, TN = 243, FN = 77\n",
            "Iteration 200, loss = 0.6972\n",
            "Got 77 / 320 correct (24.06)\n",
            "TP = 77, FN = 243, TN = 0, FN = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5064864ed737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-198aeca52898>\u001b[0m in \u001b[0;36mtrain_part\u001b[0;34m(model, optimizer, epochs, loss_fn, print_every)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0;31m# Zero out all of the gradients for the variables which the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;31m# will update.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2027\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "u7glEGKc-rNE"
      },
      "cell_type": "markdown",
      "source": [
        "## Samuel's code (for conv architecture)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2ioG4iCSVVZl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Samuel's code\n",
        "class SimpleClassifierELMO(nn.Module):\n",
        "    def __init__(self, out_channels, window_size, dropout):\n",
        "        super(SimpleClassifierELMO, self).__init__()\n",
        "        self.embeddings = Elmo(options_file, weight_file, 1, dropout=0)\n",
        "        embedding_dim = 1024\n",
        "        \n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(window_size, embedding_dim))\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(out_channels, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x is the output from batch_to_ids\n",
        "        \n",
        "        \n",
        "        # Only looking at one (the first) layer from elmo for now \n",
        "        # which is my I am indexing at 0\n",
        "        #images have 3 RGB channels \n",
        "        #for the text we add 1 channel\n",
        "        embedded = self.embeddings(x.type(torch.long))['elmo_representations'][0].unsqueeze(1)\n",
        "        \n",
        "        #(batch size, 1, max sent length, embedding dim)\n",
        "        \n",
        "        feature_maps =  F.relu(self.conv(embedded).squeeze(3))\n",
        "        # (batch size, out_channels, max sent length - window size +1, 1)\n",
        "        # -> (batch size, out_channels, max sent length - window size +1)\n",
        "           \n",
        "        #the max pooling layer\n",
        "        pooled = F.max_pool1d(feature_maps, feature_maps.shape[2]).squeeze(2)\n",
        "        # (batch size, out_channels)      \n",
        " \n",
        "        return self.fc( self.dropout(pooled))\n",
        "\n",
        "def accuracy(output, target):\n",
        "    with torch.no_grad():\n",
        "        prob_output = torch.sigmoid(output)\n",
        "\n",
        "        prob_output[prob_output > 0.5] = 1.\n",
        "        prob_output[prob_output <= 0.5] = 0.\n",
        "\n",
        "        acc = (prob_output == target).sum(dtype=torch.float) / output.shape[0]\n",
        " \n",
        "    return acc\n",
        "def f_measure(output, gold):\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    prob_output = torch.sigmoid(output)\n",
        "\n",
        "    prob_output[prob_output > 0.5] = 1.\n",
        "    prob_output[prob_output <= 0.5] = 0.\n",
        "\n",
        "    TP = FN = FP = TN = 0\n",
        "\n",
        "    for i in range(gold.shape[0]):\n",
        "      if gold[i] == prob_output[i]:\n",
        "        if gold[i] == 1:\n",
        "          TP += 1.\n",
        "        else:\n",
        "          TN += 1.\n",
        "      else:\n",
        "        if gold[i] == 1:\n",
        "          FN += 1.\n",
        "        else:\n",
        "          FP += 1.\n",
        "          \n",
        "    print(\"TP, FN, FP, TN\", TP, FN, FP, FP)\n",
        "\n",
        "    recall = TP/(TP + FN) if FN else 0\n",
        "    precision = TP/(TP + FP) if FP else 0\n",
        "    fscore = 2 * precision * recall /(precision + recall) if precision and recall else 0\n",
        "  \n",
        "  print(\"Recall: %.2f, Precision: %.2f, F-measure: %.2f\" % (recall, precision, fscore))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fElvhRigWY9J",
        "outputId": "76366a39-d3a2-42c5-b252-68f7c3154674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "cell_type": "code",
      "source": [
        "#Samuel's preprocessing\n",
        "import re\n",
        "\n",
        "def get_tokenised_corpus(corpus):\n",
        "    \"\"\"\n",
        "    This assumes the corpus can be iterated through and\n",
        "    retains the order in which the sentences appeared in the corpus\n",
        "    \"\"\"\n",
        "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
        "    for sentence in corpus:\n",
        "        tokenized_sentence = []\n",
        "        for token in re.split(r'\\s', sentence.lower()): # simplest split is \n",
        "            if token:\n",
        "              # To avoid the empty string\n",
        "              tokenized_sentence.append(token)\n",
        "        tokenized_corpus.append(tokenized_sentence)\n",
        "    \n",
        "    return tokenized_corpus\n",
        "\n",
        "train = train_df \n",
        "\n",
        "total = train['id'].count().item()\n",
        "off_count = train[train['subtask_a'] == \"OFF\"]['id'].count()\n",
        "\n",
        "\n",
        "training_percent = 0.8\n",
        "training_size = int(training_percent * total)\n",
        "validation_size = total - training_size\n",
        "\n",
        "corpus = train['tweet'].values\n",
        "labels = train['subtask_a']\n",
        "labels[labels == 'OFF'] = 1\n",
        "labels[labels == 'NOT'] = 0\n",
        "\n",
        "labels = labels.values\n",
        "labels = labels.astype(np.float).reshape(-1, 1)\n",
        "\n",
        "indices = list(range(total))\n",
        "np.random.shuffle(indices)\n",
        "training_sents = corpus[indices[:training_size]]\n",
        "training_labels = labels[indices[:training_size]]\n",
        "\n",
        "validation_sents = corpus[indices[training_size:]]\n",
        "validation_labels = labels[indices[training_size:]]\n",
        "\n",
        "training_ids = batch_to_ids(get_tokenised_corpus(training_sents))\n",
        "validation_ids = batch_to_ids(get_tokenised_corpus(validation_sents))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SzY0QtUYY1PO",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "dtype = torch.long\n",
        "data_loader = DataLoader(TensorDataset(training_ids, torch.from_numpy(training_labels)), batch_size=BATCH_SIZE, shuffle=True)\n",
        "model = SimpleClassifierELMO(out_channels=100, window_size=3, dropout=0.5)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device)\n",
        "\n",
        "validation_ids = torch.as_tensor(validation_ids).to(device, dtype=dtype)\n",
        "validation_labels = torch.as_tensor(validation_labels).to(device, dtype=torch.float)\n",
        "\n",
        "NUM_EPOCHS = 1\n",
        "training_losses = []\n",
        "training_accs = []\n",
        "validation_losses = []\n",
        "validation_accs = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  \n",
        "  print(\"Epoch\", epoch)\n",
        "  \n",
        "  for sent_ids, target in data_loader:\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    sent_ids = sent_ids.to(device, dtype=dtype)\n",
        "    target = target.to(device, dtype=torch.float)\n",
        "\n",
        "    logits = model(sent_ids).type(torch.cuda.FloatTensor)\n",
        "\n",
        "    loss = loss_fn(logits, target)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.detach().item()\n",
        "    epoch_acc += accuracy(logits, target)\n",
        "  \n",
        "  epoch_loss = epoch_loss/BATCH_SIZE\n",
        "  epoch_acc = epoch_acc/BATCH_SIZE\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = model(validation_ids)\n",
        "    logits = logits.type(torch.cuda.FloatTensor)\n",
        "\n",
        "    validation_loss = loss_fn(logits, validation_labels).item()\n",
        "    validation_acc = accuracy(logits, validation_labels).item()\n",
        "    \n",
        "    print(f'| Epoch: {epoch:02} | Train. Loss: {epoch_loss:.3f} | Train. Acc: {epoch_acc*100:.2f}| Val. Loss: {validation_loss:.3f} | Val. Acc: {validation_acc*100:.2f}% \\n')\n",
        "    f_measure(logits, validation_labels)\n",
        "    \n",
        "  training_losses.append(epoch_loss)\n",
        "  training_accs.append(epoch_acc)\n",
        "  validation_losses.append(validation_loss)\n",
        "  validation_accs.append(validation_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NQ4enEK_-GsZ"
      },
      "cell_type": "markdown",
      "source": [
        "## Misc"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EquNq-KbeEvT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Save intermediate results to CSV so we can use the nice torchtext .TabularDataset loader\n",
        "train_df.to_csv(path_or_buf=PREPROCESSED_FP, sep=',', na_rep='', float_format=None, \n",
        "                header=True, index=True, )\n",
        "\n",
        "#train = pd.read_csv(\"offenseval-training-v1.tsv\", delimiter=\"\\t\")\n",
        "#test = pd.read_csv(\"offenseval-trial (2).txt\", delimiter=\"\\t\")\n",
        "train = None\n",
        "\n",
        "#define our batch size\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "text_field = data.Field(sequential = False, use_vocab = False, dtype = torch.long)\n",
        "label_field = data.LabelField(sequential= False, dtype=torch.float, use_vocab = False)\n",
        "\n",
        "\n",
        "#text_field.build_vocab(train, max_size=25000, vectors=\"glove.6B.100d\")\n",
        "#label_field.build_vocab(train)\n",
        "\n",
        "train = data.TabularDataset(PREPROCESSED_FP, 'CSV', fields = \n",
        "                            [('TWEET_IDS', text_field), ('LABEL_A', label_field)], \n",
        "                            skip_header=False)\n",
        "#train = data.Dataset(examples=tweets_IDs, fields= [(\"tweet\", text_field)])\n",
        "\n",
        "\n",
        "train_iterator = data.Iterator(train, batch_size = BATCH_SIZE, )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BRvWwHbUgkWf",
        "outputId": "3f22e5dc-13a8-4c8c-8c1d-589c73efea4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "#OLD BERT METHOD\n",
        "#train = pd.read_csv(\"offenseval-training-v1.tsv\", delimiter=\"\\t\")\n",
        "#test = pd.read_csv(\"offenseval-trial (2).txt\", delimiter=\"\\t\")\n",
        "train = None\n",
        "test = None\n",
        "\n",
        "#define our batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "text_field = data.Field(tokenize=BERT_tokenize, preprocessing = BERT_retrieve_ID, use_vocab = True, dtype = torch.long)\n",
        "label_field = data.LabelField(sequential= False, preprocessing = section_a_labels, dtype=torch.float, use_vocab = False)\n",
        "\n",
        "\n",
        "#text_field.build_vocab(train, max_size=25000, vectors=\"glove.6B.100d\")\n",
        "#label_field.build_vocab(train)\n",
        "\n",
        "train = data.TabularDataset(\"offenseval-training-v1.tsv\", 'TSV', fields = \n",
        "                            { \"tweet\": (\"tweet\", text_field), \"subtask_a\": (\"LabelA\", label_field),}, skip_header=False)\n",
        "\n",
        "text_field.build_vocab(train, vectors=\"glove.6B.50d\") #USE \"glove.840B.300d\" or glove.twitter.27B.200d\n",
        "label_field.build_vocab(train)\n",
        "\n",
        "glove_dim = 50\n",
        "\n",
        "#define our batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "#define types of data and their preprocessing\n",
        "\n",
        "#get pre-defined split\n",
        "#train = text_field.preprocess(train.iloc[0][\"tweet\"])\n",
        "#print(train)\n",
        "\n",
        "train_iterator = data.Iterator(train, batch_size = BATCH_SIZE, device=\"cuda\")\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fa18f344874d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtext_field\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBERT_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERT_retrieve_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlabel_field\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msection_a_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BERT_tokenize' is not defined"
          ]
        }
      ]
    }
  ]
}