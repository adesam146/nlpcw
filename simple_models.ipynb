{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/adesam146/nlpcw/blob/sam_preprocessing/NLP_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Srpq8hYt4whg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "EquNq-KbeEvT",
    "outputId": "629ad123-ae49-44e3-f4b2-9a95162bf8c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13240, 5)\n",
      "      id                                              tweet subtask_a  \\\n",
      "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
      "1  90194  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...       OFF   \n",
      "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
      "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
      "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
      "\n",
      "  subtask_b subtask_c  \n",
      "0       UNT       NaN  \n",
      "1       TIN       IND  \n",
      "2       NaN       NaN  \n",
      "3       UNT       NaN  \n",
      "4       NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"OffensEval_task_data/start-kit/training-v1/offenseval-training-v1.tsv\", delimiter=\"\\t\")\n",
    "print(train.shape)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "u8yrV9tCWJrT",
    "outputId": "c2bf50c6-c41e-4ddb-9f5c-8a6230544745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           13240\n",
       "tweet        13240\n",
       "subtask_a    13240\n",
       "subtask_b     4400\n",
       "subtask_c     3876\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "af5bww85WJrW",
    "outputId": "21f98d66-7d6f-45bb-cd02-b77c3e1dbc19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of offensive 4400\n",
      "Number of inoffensive 8840\n"
     ]
    }
   ],
   "source": [
    "total = train['id'].count().item()\n",
    "off_count = train[train['subtask_a'] == \"OFF\"]['id'].count()\n",
    "\n",
    "print(\"Number of offensive\", off_count)\n",
    "print(\"Number of inoffensive\", total - off_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxJeNqSbWJrZ"
   },
   "source": [
    "**The above shows that the training dataset is not very balanced (in offensive is about twice as much). How could this be addressed. Get more data? Augment offensive comments by adding neutral words to create more data or concat offensive and inoffensive comments to make new offensive comments?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "OkVNhZ3hWJra",
    "outputId": "d184b6cd-550f-42c3-c5bf-ede676d5a5f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\nlpcw\\myvenv\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "c:\\projects\\nlpcw\\myvenv\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "training_percent = 0.8\n",
    "training_size = int(training_percent * total)\n",
    "validation_size = total - training_size\n",
    "\n",
    "corpus = train['tweet'].to_numpy()\n",
    "labels = train['subtask_a']\n",
    "labels[labels == 'OFF'] = 1\n",
    "labels[labels == 'NOT'] = 0\n",
    "labels = labels.to_numpy(dtype=np.float)\n",
    "\n",
    "indices = list(range(total))\n",
    "np.random.shuffle(indices)\n",
    "training_sents = corpus[indices[:training_size]]\n",
    "training_labels = labels[indices[:training_size]]\n",
    "\n",
    "validation_sents = corpus[indices[training_size:]]\n",
    "validation_labels = labels[indices[training_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ji6AkNbLWJrf"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_tokenised_corpus(corpus):\n",
    "    \"\"\"\n",
    "    This assumes the corpus can be iterated through and\n",
    "    retains the order in which the sentences appeared in the corpus\n",
    "    \"\"\"\n",
    "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
    "    for sentence in corpus:\n",
    "        tokenized_sentence = []\n",
    "        for token in re.split(r'\\s', sentence.lower()): # simplest split is \n",
    "            if token:\n",
    "              # To avoid the empty string\n",
    "              tokenized_sentence.append(token)\n",
    "        tokenized_corpus.append(tokenized_sentence)\n",
    "    \n",
    "    return tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vec_training = vectorizer.fit_transform(training_sents)\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "vec_training = tf_transformer.fit_transform(vec_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\nlpcw\\myvenv\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight={1.0: 2},\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None, class_weight={1.0: 2})\n",
    "\n",
    "clf.fit(vec_training, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_valid = tf_transformer.transform(vectorizer.transform(validation_sents))\n",
    "predictions = clf.predict(vec_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.93      0.82      1757\n",
      "         1.0       0.71      0.35      0.47       891\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      2648\n",
      "   macro avg       0.73      0.64      0.65      2648\n",
      "weighted avg       0.73      0.73      0.70      2648\n",
      "\n",
      "Accuracy: 0.7337613293051359\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(validation_labels, predictions))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "train_pos_sents = []\n",
    "train_pos_labels = []\n",
    "train_neg_sents = []\n",
    "train_neg_labels = []\n",
    "\n",
    "for sent, label in zip(training_sents, training_labels):\n",
    "    if TextBlob(sent).sentiment.polarity > -0.2:\n",
    "        train_pos_sents.append(sent)\n",
    "        train_pos_labels.append(label)\n",
    "    else:\n",
    "        train_neg_sents.append(sent)\n",
    "        train_neg_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight={1.0: 2},\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None, class_weight={1.0: 2})\n",
    "clf1.fit(tf_transformer.transform(vectorizer.transform(train_pos_sents)), train_pos_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight={0.0: 1.15},\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
       "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = SGDClassifier(loss='hinge', penalty='l1',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None, class_weight={0.0: 1.15})\n",
    "clf2.fit(tf_transformer.transform(vectorizer.transform(train_neg_sents)), train_neg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pos_sents = []\n",
    "valid_pos_labels = []\n",
    "valid_neg_sents = []\n",
    "valid_neg_labels = []\n",
    "\n",
    "for sent, label in zip(validation_sents, validation_labels):\n",
    "    if TextBlob(sent).sentiment.polarity > -0.2:\n",
    "        valid_pos_sents.append(sent)\n",
    "        valid_pos_labels.append(label)\n",
    "    else:\n",
    "        valid_neg_sents.append(sent)\n",
    "        valid_neg_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = clf1.predict(tf_transformer.transform(vectorizer.transform(valid_pos_sents)))\n",
    "preds2 = clf2.predict(tf_transformer.transform(vectorizer.transform(valid_neg_sents)))\n",
    "\n",
    "predictions_joined = np.concatenate((preds1, preds2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier for positive sentiments\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.97      0.85      1604\n",
      "         1.0       0.75      0.21      0.32       648\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      2252\n",
      "   macro avg       0.75      0.59      0.59      2252\n",
      "weighted avg       0.75      0.75      0.70      2252\n",
      "\n",
      "Accuracy: 0.7517761989342806\n",
      "\n",
      "Classifier for negative sentiments\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.79      0.67       153\n",
      "         1.0       0.83      0.64      0.72       243\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       396\n",
      "   macro avg       0.71      0.72      0.70       396\n",
      "weighted avg       0.73      0.70      0.70       396\n",
      "\n",
      "Accuracy: 0.6994949494949495\n",
      "\n",
      "Overall classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.87      0.75      1757\n",
      "         1.0       0.36      0.15      0.21       891\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      2648\n",
      "   macro avg       0.51      0.51      0.48      2648\n",
      "weighted avg       0.56      0.62      0.57      2648\n",
      "\n",
      "Accuracy: 0.6238670694864048\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier for positive sentiments\")\n",
    "print(metrics.classification_report(valid_pos_labels, preds1))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(valid_pos_labels, preds1))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Classifier for negative sentiments\")\n",
    "print(metrics.classification_report(valid_neg_labels, preds2))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(valid_neg_labels, preds2))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Overall classifier\")\n",
    "print(metrics.classification_report(validation_labels, predictions_joined))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions_joined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "NLP_CW.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
