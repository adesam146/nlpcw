{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_CW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adesam146/nlpcw/blob/rest_of_tasks/simple_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xOFNCl_A8xX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "07e6ef4a-2f84-4cc5-d28e-ff7aa8b91277"
      },
      "cell_type": "code",
      "source": [
        "!pip install -U pandas"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/de/a0d3defd8f338eaf53ef716e40ef6d6c277c35d50e09b586e170169cdf0d/pandas-0.24.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 10.1MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
            "\u001b[31mpymc3 3.6 has requirement joblib<0.13.0, but you'll have joblib 0.13.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 0.22.0\n",
            "    Uninstalling pandas-0.22.0:\n",
            "      Successfully uninstalled pandas-0.22.0\n",
            "Successfully installed pandas-0.24.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Srpq8hYt4whg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EquNq-KbeEvT",
        "outputId": "bd58e2eb-551f-42d4-e9ee-f2e14b7245e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"./offenseval-training-v1.tsv\", delimiter=\"\\t\")\n",
        "print(train.shape)\n",
        "print(train.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13240, 5)\n",
            "      id                                              tweet subtask_a  \\\n",
            "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
            "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
            "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
            "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
            "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
            "\n",
            "  subtask_b subtask_c  \n",
            "0       UNT       NaN  \n",
            "1       TIN       IND  \n",
            "2       NaN       NaN  \n",
            "3       UNT       NaN  \n",
            "4       NaN       NaN  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "u8yrV9tCWJrT",
        "outputId": "744f24f1-2c93-49f8-9e47-14cc004b34ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "train.count()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id           13240\n",
              "tweet        13240\n",
              "subtask_a    13240\n",
              "subtask_b     4400\n",
              "subtask_c     3876\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "af5bww85WJrW",
        "outputId": "a3856070-9669-4e22-c6ce-a8592af9e237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "total = train['id'].count().item()\n",
        "off_count = train[train['subtask_a'] == \"OFF\"]['id'].count()\n",
        "\n",
        "print(\"Number of offensive\", off_count)\n",
        "print(\"Number of inoffensive\", total - off_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of offensive 4400\n",
            "Number of inoffensive 8840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K8qdnuP2C5Zb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TASK A"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "XxJeNqSbWJrZ"
      },
      "cell_type": "markdown",
      "source": [
        "**The above shows that the training dataset is not very balanced (in offensive is about twice as much). How could this be addressed. Get more data? Augment offensive comments by adding neutral words to create more data or concat offensive and inoffensive comments to make new offensive comments?**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OkVNhZ3hWJra",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_percent = 0.8\n",
        "training_size = int(training_percent * total)\n",
        "validation_size = total - training_size\n",
        "\n",
        "corpus = train['tweet'].to_numpy()\n",
        "labels = train['subtask_a'].to_numpy()\n",
        "labels[labels == 'OFF'] = 1\n",
        "labels[labels == 'NOT'] = 0\n",
        "\n",
        "labels = labels.astype(float)\n",
        "\n",
        "indices = list(range(total))\n",
        "np.random.shuffle(indices)\n",
        "training_sents = corpus[indices[:training_size]]\n",
        "training_labels = labels[indices[:training_size]]\n",
        "\n",
        "validation_sents = corpus[indices[training_size:]]\n",
        "validation_labels = labels[indices[training_size:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ji6AkNbLWJrf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def get_tokenised_corpus(corpus):\n",
        "    \"\"\"\n",
        "    This assumes the corpus can be iterated through and\n",
        "    retains the order in which the sentences appeared in the corpus\n",
        "    \"\"\"\n",
        "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
        "    for sentence in corpus:\n",
        "        tokenized_sentence = []\n",
        "        for token in re.split(r'\\s', sentence.lower()): # simplest split is \n",
        "            if token:\n",
        "              # To avoid the empty string\n",
        "              tokenized_sentence.append(token)\n",
        "        tokenized_corpus.append(tokenized_sentence)\n",
        "    \n",
        "    return tokenized_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5NEltnwCkiD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "vec_training = vectorizer.fit_transform(training_sents)\n",
        "\n",
        "tf_transformer = TfidfTransformer(use_idf=False)\n",
        "vec_training = tf_transformer.fit_transform(vec_training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bld3qbEpCkiR",
        "colab_type": "code",
        "outputId": "61488dff-4b46-4055-e5a1-2b8728139e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "cell_type": "code",
      "source": [
        "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None, class_weight={1.0: 2})\n",
        "\n",
        "clf.fit(vec_training, training_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.001, average=False, class_weight={1.0: 2},\n",
              "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
              "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
              "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
              "       validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "3QbVqHdUCkio",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vec_valid = tf_transformer.transform(vectorizer.transform(validation_sents))\n",
        "predictions = clf.predict(vec_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5pn-eu6JCkiw",
        "colab_type": "code",
        "outputId": "dd037b0c-fa2d-4f17-b9b7-bc78e607c681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(validation_labels, predictions))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.88      0.80      1761\n",
            "         1.0       0.62      0.38      0.47       887\n",
            "\n",
            "   micro avg       0.71      0.71      0.71      2648\n",
            "   macro avg       0.68      0.63      0.64      2648\n",
            "weighted avg       0.70      0.71      0.69      2648\n",
            "\n",
            "Accuracy: 0.7137462235649547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B9f0yiTlCki6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "train_pos_sents = []\n",
        "train_pos_labels = []\n",
        "train_neg_sents = []\n",
        "train_neg_labels = []\n",
        "\n",
        "for sent, label in zip(training_sents, training_labels):\n",
        "    if TextBlob(sent).sentiment.polarity > -0.2:\n",
        "        train_pos_sents.append(sent)\n",
        "        train_pos_labels.append(label)\n",
        "    else:\n",
        "        train_neg_sents.append(sent)\n",
        "        train_neg_labels.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1wIJFw6tCkjB",
        "colab_type": "code",
        "outputId": "bb07b64a-4088-4973-eb0b-1fea61b63d81",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf1 = SGDClassifier(loss='hinge', penalty='l1',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None, class_weight={1.0: 2})\n",
        "clf1.fit(tf_transformer.transform(vectorizer.transform(train_pos_sents)), train_pos_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.001, average=False, class_weight={1.0: 2},\n",
              "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
              "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
              "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
              "       validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "88Atez8_CkjG",
        "colab_type": "code",
        "outputId": "e5c1aae3-7184-484c-c319-2188b63050eb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf2 = SGDClassifier(loss='hinge', penalty='l1',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None, class_weight={0.0: 1.15})\n",
        "clf2.fit(tf_transformer.transform(vectorizer.transform(train_neg_sents)), train_neg_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.001, average=False, class_weight={0.0: 1.15},\n",
              "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
              "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
              "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
              "       validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "sxwKzUPkCkjj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_pos_sents = []\n",
        "valid_pos_labels = []\n",
        "valid_neg_sents = []\n",
        "valid_neg_labels = []\n",
        "\n",
        "for sent, label in zip(validation_sents, validation_labels):\n",
        "    if TextBlob(sent).sentiment.polarity > -0.2:\n",
        "        valid_pos_sents.append(sent)\n",
        "        valid_pos_labels.append(label)\n",
        "    else:\n",
        "        valid_neg_sents.append(sent)\n",
        "        valid_neg_labels.append(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QSTPIMEJCkjp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds1 = clf1.predict(tf_transformer.transform(vectorizer.transform(valid_pos_sents)))\n",
        "preds2 = clf2.predict(tf_transformer.transform(vectorizer.transform(valid_neg_sents)))\n",
        "\n",
        "predictions_joined = np.concatenate((preds1, preds2), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NZqJFnueCkjx",
        "colab_type": "code",
        "outputId": "08eff541-428f-4b8d-fa4d-84153022b9db",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Classifier for positive sentiments\")\n",
        "print(metrics.classification_report(valid_pos_labels, preds1))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(valid_pos_labels, preds1))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Classifier for negative sentiments\")\n",
        "print(metrics.classification_report(valid_neg_labels, preds2))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(valid_neg_labels, preds2))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Overall classifier\")\n",
        "print(metrics.classification_report(validation_labels, predictions_joined))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions_joined))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier for positive sentiments\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.97      0.85      1604\n",
            "         1.0       0.75      0.21      0.32       648\n",
            "\n",
            "   micro avg       0.75      0.75      0.75      2252\n",
            "   macro avg       0.75      0.59      0.59      2252\n",
            "weighted avg       0.75      0.75      0.70      2252\n",
            "\n",
            "Accuracy: 0.7517761989342806\n",
            "\n",
            "Classifier for negative sentiments\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.58      0.79      0.67       153\n",
            "         1.0       0.83      0.64      0.72       243\n",
            "\n",
            "   micro avg       0.70      0.70      0.70       396\n",
            "   macro avg       0.71      0.72      0.70       396\n",
            "weighted avg       0.73      0.70      0.70       396\n",
            "\n",
            "Accuracy: 0.6994949494949495\n",
            "\n",
            "Overall classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.87      0.75      1757\n",
            "         1.0       0.36      0.15      0.21       891\n",
            "\n",
            "   micro avg       0.62      0.62      0.62      2648\n",
            "   macro avg       0.51      0.51      0.48      2648\n",
            "weighted avg       0.56      0.62      0.57      2648\n",
            "\n",
            "Accuracy: 0.6238670694864048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AIVC7KehDGU0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TASK B"
      ]
    },
    {
      "metadata": {
        "id": "lRM9EYtxDI6I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total_b = train.count()['subtask_b'].item()\n",
        "training_percent = 0.8\n",
        "training_size = int(training_percent * total_b)\n",
        "validation_size = total_b - training_size\n",
        "\n",
        "train_b = train[train.subtask_a == 'OFF']\n",
        "corpus = train_b['tweet'].to_numpy()\n",
        "labels = train_b['subtask_b'].to_numpy()\n",
        "labels[labels == 'TIN'] = 0\n",
        "labels[labels == 'UNT'] = 1\n",
        "labels = labels.astype(float)\n",
        "\n",
        "indices = list(range(total_b))\n",
        "np.random.shuffle(indices)\n",
        "training_sents = corpus[indices[:training_size]]\n",
        "training_labels = labels[indices[:training_size]]\n",
        "\n",
        "validation_sents = corpus[indices[training_size:]]\n",
        "validation_labels = labels[indices[training_size:]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XBZsUuEdHrYT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "vec_training = vectorizer.fit_transform(training_sents)\n",
        "\n",
        "tf_transformer = TfidfTransformer(use_idf=False)\n",
        "vec_training = tf_transformer.fit_transform(vec_training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qK9oyn2XHstx",
        "colab_type": "code",
        "outputId": "95d7c2ba-9bf2-4675-ce57-f17d08731b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "cell_type": "code",
      "source": [
        "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None, class_weight={1.0: 6.8})\n",
        "\n",
        "clf.fit(vec_training, training_labels)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.001, average=False, class_weight={1.0: 6.8},\n",
              "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
              "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
              "       power_t=0.5, random_state=42, shuffle=True, tol=None,\n",
              "       validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "faReJkFpH1nV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vec_valid = tf_transformer.transform(vectorizer.transform(validation_sents))\n",
        "predictions = clf.predict(vec_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6JeaeTjOH9E7",
        "colab_type": "code",
        "outputId": "b8d2d329-51ec-46a4-d6e4-029cef61c944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "cell_type": "code",
      "source": [
        "print(metrics.confusion_matrix(validation_labels, predictions))\n",
        "print(metrics.classification_report(validation_labels, predictions))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[638 135]\n",
            " [ 65  42]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      0.83      0.86       773\n",
            "         1.0       0.24      0.39      0.30       107\n",
            "\n",
            "   micro avg       0.77      0.77      0.77       880\n",
            "   macro avg       0.57      0.61      0.58       880\n",
            "weighted avg       0.83      0.77      0.80       880\n",
            "\n",
            "Accuracy: 0.7727272727272727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s-xcBWhU-23D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TASK C"
      ]
    },
    {
      "metadata": {
        "id": "ErRboMty-626",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "adfff039-9441-4bfd-b98b-d30cc5dc28f2"
      },
      "cell_type": "code",
      "source": [
        "total_c = train.count()['subtask_c'].item()\n",
        "training_percent = 0.8\n",
        "training_size = int(training_percent * total_c)\n",
        "validation_size = total_c - training_size\n",
        "\n",
        "train_c = train[train.subtask_a == 'OFF'][train.subtask_b == 'TIN']\n",
        "print(\"Size of dataset\", len(train_c))\n",
        "corpus = train_c['tweet'].to_numpy()\n",
        "labels = train_c['subtask_c'].to_numpy()\n",
        "labels[labels == 'IND'] = 0\n",
        "labels[labels == 'GRP'] = 1\n",
        "labels[labels == 'OTH'] = 2\n",
        "labels = labels.astype(float)\n",
        "\n",
        "indices = list(range(total_c))\n",
        "np.random.shuffle(indices)\n",
        "training_sents = corpus[indices[:training_size]]\n",
        "training_labels = labels[indices[:training_size]]\n",
        "\n",
        "validation_sents = corpus[indices[training_size:]]\n",
        "validation_labels = labels[indices[training_size:]]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of dataset 3876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oh_HImFrAQlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a2120a1-77ee-456f-8dbe-c2c9ee106f90"
      },
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "vec_training = vectorizer.fit_transform(training_sents)\n",
        "\n",
        "print(vec_training.shape)\n",
        "\n",
        "tf_transformer = TfidfTransformer(use_idf=False)\n",
        "vec_training = tf_transformer.fit_transform(vec_training)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3100, 8154)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BulnlSp8_Wpt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "815d75ee-e324-466c-dce4-94a520a2b15d"
      },
      "cell_type": "code",
      "source": [
        "clf = SGDClassifier(loss='hinge', penalty='l1',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None, class_weight={0:1.6, 1:3.7, 2:8.4})\n",
        "\n",
        "clf.fit(vec_training, training_labels)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.001, average=False,\n",
              "       class_weight={0: 1.6, 1: 3.7, 2: 8.4}, early_stopping=False,\n",
              "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
              "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
              "       n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
              "       random_state=42, shuffle=True, tol=None, validation_fraction=0.1,\n",
              "       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "Qui5ITnTAiD7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vec_valid = tf_transformer.transform(vectorizer.transform(validation_sents))\n",
        "predictions = clf.predict(vec_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "stttDsG4A1qK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "a98e1f51-9f9e-454d-b5c1-61d25666865d"
      },
      "cell_type": "code",
      "source": [
        "print(metrics.confusion_matrix(validation_labels, predictions))\n",
        "print(metrics.classification_report(validation_labels, predictions))\n",
        "print(\"Accuracy:\", metrics.accuracy_score(validation_labels, predictions))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[399  58  21]\n",
            " [ 91 117  15]\n",
            " [ 50  10  15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.83      0.78       478\n",
            "         1.0       0.63      0.52      0.57       223\n",
            "         2.0       0.29      0.20      0.24        75\n",
            "\n",
            "   micro avg       0.68      0.68      0.68       776\n",
            "   macro avg       0.56      0.52      0.53       776\n",
            "weighted avg       0.67      0.68      0.67       776\n",
            "\n",
            "Accuracy: 0.6842783505154639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dWV6UsjkA4Dc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}